{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b822ac96-5d93-4a55-9174-1eb1dee8adf7",
   "metadata": {},
   "source": [
    "# 1 - Redes neuronales\n",
    "\n",
    "**Sumario**\n",
    "\n",
    "1. Introducción\n",
    "4. Estructura de la red\n",
    "5. Funciones de activación\n",
    "6. Back propagation\n",
    "7. Inicialización de capas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54518392-f04d-4fb0-b0c2-fced8376f2ed",
   "metadata": {},
   "source": [
    "## 1.1 - Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a7a03-a26b-4342-8552-bdb0cc0cbdbc",
   "metadata": {},
   "source": [
    "Una red de neuronas artificial es una red representada de manera espacial mediante un grafo dirigido donde cada uno de los nodos representa neuronas, mientras que los arcos reflejan las sinapsis o conexiones entre estas. Esta estructura intenta imitar la distribución de las neuronas en el cerebro humano con el fin de construir un modelo capaz de simular la capacidad de procesamiento de nuestros cerebros.\n",
    "\n",
    "Las neuronas humanas están formadas por tres elementos:\n",
    "\n",
    "1. El **soma** o cuerpo celular, que es su parte principal\n",
    "2. Las **dendritas**, que son las múltiples prolongaciones que salen de distintas partes del soma, en cuyo extremo se encuentran los **botones sinápticos**, conectados a las dendritas de otras neuronas y cuya función consiste en recibir impulsos eléctricos de estas y transmitirlos al soma.\n",
    "3. El **axón**, que es una prlongación del soma la cual se extiende en dirección opuesta a las dendritas y cuya función consiste en conducir un impulso nerviso desde el soma hasta otra neurona, músculo o glándula del cuerpo humano\n",
    "\n",
    "<img src=\"images_1/neurona.jpg\" width=\"600\" data-align=\"center\">\n",
    "\n",
    "Aparentemente, las neuronas biológicas parecen comportarse de una manera bastante simple a nivel individual, pero, en realidad, se encuentran organizadas en una amplia red de miles de millones de neuronas conectadas entre sí que interactúan de manera conjunta y/o sincronizada. Este tipo de estructura permite, en teoría, que un elevado número de elementos sencillos (neuronas) sean capaces de realizar cálculos de gran complejidad de forma muy rápida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f49d7-9886-4be5-9bb7-7ec628cc9eea",
   "metadata": {},
   "source": [
    "### 1.1.1 - Primer modelo de red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a909e-a2e1-4b3d-a543-e9eab4d3c3b4",
   "metadata": {},
   "source": [
    "En base a esta estructura biológica, en 1943 los investigadores Pitts y McCulloch definieron el que se considera **el primer modelo de red neuronal en 1943**, que pasó a denominarse red de neuronas artificial (ANN, Artificial Neural Network, en inglés). \n",
    "\n",
    "Dicho modelo consistía en una red con dos capas de neuronas conectadas entre sí:\n",
    "1. La primera capa estaba formada por un **conjunto de nodos o neuronas formales**, que representaban la **entrada de la red**.\n",
    "2. La segunda capa estaba formada por un **único nodo o neurona formal**, que representa la **salida de la red**.\n",
    "\n",
    "Una neurona formal consituye una puerta lógica con dos posibles estados internos (encendido o apagado) representados por una variable. Esta red funcionaba como un discriminador del estado de la puerta lógica, de forma que:\n",
    "1. Las neuronas de la primera capa reciben las entradas. Las entradas $x$ podían ser positivas o negativas y las neuronas podían estar activas o no ($w$).\n",
    "2. Se aplica una operación matemática sobre el valor de las entradas\n",
    "3. Se aplica una función de activación con un umbral. De tal tal forma que si el valor supera el umbra la salida es 1 y sino, la salida es 0.\n",
    "\n",
    "<img src=\"images_1/red_neuronal_formal.png\" width=\"500\" data-align=\"center\">\n",
    "\n",
    "En definitiva, si consideramos una red $U$ formada por dos neuronas de entrada y una neurona de salida, tendríamos que calcular la salidad de la red del siguiente modo:\n",
    "\n",
    "$$\n",
    "Y(x) = f(U)\n",
    "$$\n",
    "\n",
    "Donde $f$ se corresponde con una función de activación definida de esta forma:\n",
    "\n",
    "$$\n",
    "f(U) = \\begin{cases}\n",
    "    1,& \\text{si} \\ U > 0\\\\\n",
    "    0,              & \\text{si} \\ U \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Y donde $U$ se calcula de la siguiente manera:\n",
    "\n",
    "$$\n",
    "U = w_{1} x_{1} + w_{2} x_{2} - \\theta\n",
    "$$\n",
    "\n",
    "donde $w_{1}$ y $w_{2}$ son los coeficientes de cada una de las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51691e42-c26f-4c64-ad32-83563ed3aa94",
   "metadata": {},
   "source": [
    "### 1.1.2 - Teoría Hebbiana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862453a8-f637-44a4-b36f-7c9a32fe1d02",
   "metadata": {},
   "source": [
    "El modelo anterior no consideraba la actualización de estos coeficientes, es decir, no consideraba el aspecto de *aprendizaje*. En este sentido, surge la teoría hebbiana en 1949, donde se introduce un proceso genérico de modificación de coeficientes (también conocidos como pesos) de manera muy sencilla.\n",
    "\n",
    "Según la regla de Hebb, el peso entre dos neuronas **se incrementa si las dos neuronas se activan simultáneamente y se reduce si se activan por separado**. Los nodos que tienden a ser positivos o negativos al mismo tiempo tienen fuertes pesos positivos, mientras que aquellos que tienden a ser contrarios tienen fuertes pesos negativos. \n",
    "\n",
    "Dada una red de neuronas con vectores de entrada $X=\\{x_{1}, x_{2}, \\dots, x_{n}\\}$, e $Y=\\{y_{1}, y_{2}, \\dots, y_{m}\\}$, así como una matriz de pesos $W$, y un ritmo de aprendizaje $\\alpha$, se define una función destinada a modificar el valor de la matriz de pesos (según el aprendizaje hebbiano) de la siguiente forma:\n",
    "\n",
    "$$\n",
    "w_{ij}' = w_{ij} + \\alpha x_{i} y_{j}\n",
    "$$\n",
    "\n",
    "Mediante esta representación, se pudo definir un algoritmo que permitiera calcular el valor de los pesos a partir del **error cuadrático medio** de las salidas obtenidas con respecto a las salidas esperadas:\n",
    "\n",
    "$$\n",
    "\\frac{1}{N} || Y - XW^{T}||\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf54ab0-b52d-4a59-9377-7e2e9be2b90d",
   "metadata": {},
   "source": [
    "### 1.1.3 - Perceptrón simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20509f-73e5-4aab-9479-26231781fdf6",
   "metadata": {},
   "source": [
    "A partir de ambos trabajos, se desarolló una versión más compleja de red de neuronas artificiales denominada **perceptrón** (Minsky, 1969) que utilizaba un nuevo tipo de neuronas denominadas unidades de umbral lineal (**LTU, Linear Threshold Unit**). En este caso **las entradas y las salidas eran de tipo numérico**, no de tipo binario, confiriéndose una mayor versatilidad sobre las operaciones que podían ser representadas. De esta forma, el resultado generado por una neurona se calculaba mediante la suma ponderada de las entradas ($X$) combinadas con los pesos $W$:\n",
    "\n",
    "$$\n",
    "U = X W^{T} = (x_{1}, x_{2}, \\dots, x_{n}) \\binom{w_{1}}{w_{n}} = \\sum_{i=1}^{n} x_{i} w_{i} = x_{1}w_{1} + x_{2}w_{2} + \\dots +  x_{n}w_{n}\n",
    "$$\n",
    "\n",
    "Al igual que con la red neuronal formal, se aplicaba un función de umbral $f$ sobre el valor generado por la red con la finalidad de generar un resultado de salida normalizado:\n",
    "\n",
    "$$\n",
    "f(U) = \\begin{cases}\n",
    "    1,& \\text{si} \\ U > 0\\\\\n",
    "    0,              & \\text{si} \\ U \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<img src=\"images_1/perceptron_simple.png\" width=\"500\" data-align=\"center\">\n",
    "\n",
    "La fase de entrenamiento del perceptron se llevaba a cabo mediante **una variación de la regla de Hebb que incorporaba el error cometido por la red**. Así para cada instancia de entrenamiento formada por un vector de entrada $x$ y un valor de salida $y$ en cada una de las neuronas de la red que genera un resultado erróneo, se realizaba una modificación de los pesos de las neuronas de entrada que contribuían a la salida correcta.\n",
    "\n",
    "De esta manera, el proceso definido para la actualización de los pesos sería el siguiente:\n",
    "\n",
    "$$\n",
    "w_{ij}^{t+1} = w_{ij}^{t} + \\alpha (\\hat{y}_{j} - y_{j}) x_{i}\n",
    "$$\n",
    "\n",
    "Donde $w_{ij}^{t}$ es el peso de la conexión entre la neurona de entrada $i$ y la neurona de salida $j$ en el instante de entrenamiento $t$. $x_{i}$ es el valor de entrada de la instancia de entrenamiento, $y_{j}$ es el valor de salida esperado, $\\hat{y}_{j}$ el valor de salidad de la neurona en el estado actual, y $\\alpha$ la tasa de aprendizaje.\n",
    "\n",
    "El perceptrón se diseñó para ser una máquina, en lugar de un programa. Es por ello que se implementó en un hardware especifico denominado como el perceptrón Mark 1. Esta máquina fue diseñada para el reconocimiento de imágenes: tenía una matriz de 400 fotocélulas, conectadas aleatoriamente a las \"neuronas\". Los pesos se codificaron en potenciómetros y las actualizaciones de peso durante el aprendizaje se realizaron mediante motores eléctricos.\n",
    "\n",
    "<img src=\"images_1/Mark_I_perceptron.jpg\" width=\"250\" data-align=\"center\">\n",
    "\n",
    "Aunque inicialmente el perceptrón parecía prometedor, rápidamente se demostró que no podía ser entrenado para reconocer muchas clases de patrones. Sólo era capaz de aprender patrones\n",
    "sencillos, pues el límite de decisión de cada una de las neuronas de salida era lineal.\n",
    "\n",
    "<img src=\"images_1/lineal_no_lineal.png\" width=\"500\" data-align=\"center\">\n",
    "\n",
    "Este y otros muchos problemas fueron identificados en el artículo Perceptrons (Minsky, 1969) donde se destacaba la incapacidad de esta técnica para resolver problemas triviales como el problema de clasificación XOR. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d15aba4-233a-45e4-832d-1bb4049415f3",
   "metadata": {},
   "source": [
    "### 1.1.4 - Perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e81c8-b468-43af-bc33-831976098fca",
   "metadata": {},
   "source": [
    "El artículo de Minsky artículo ocasionó un declive en la investigación sobre redes neuronales hasta la aparición de una nueva técnica que **combinaba múltiples perceptrones** para construir lo que se denominó **perceptrón multicapa**, capaz de resolver muchos de los problemas enunciados por Minsky en su artículo.\n",
    "\n",
    "En el siguiente ejemplo, podemos observar un perceprón multicapa formado por cuatro capas:\n",
    "* Una capa de neuronas de entrada\n",
    "* Dos capas de neuronas ocultas de tipo LTU ($\\mathbb{R}$)\n",
    "* Una capa de neuronas de tipo LTU\n",
    "\n",
    "Cada capa de neuronas LTU tiene definida una **función de activación** y un **bias**. Normalmente, el bias se representa utilizando un tipo especial de neurona denominada neurona de bias que suele devolver siempre un mismo valor, por ejemplo $1$.\n",
    "\n",
    "<img src=\"images_1/perceptron_multicapa.png\" width=\"500\" data-align=\"center\">\n",
    "\n",
    "Esta nueva estructura permitía resolver problemas más complejos (**no estaba limitada a problemas linealmente separables**) mediante la combinación de las capas, pero, según se iba aumentando el número de neuronas, **el proceso de aprendizaje se volvía más complejo a nivel computacional**, hasta que en 1986 se presentó una nueva técnica de actualización de pesos llamada *backpropagation*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b38b2-d75c-4fc7-abfe-9b751b80ad99",
   "metadata": {},
   "source": [
    "## 1.2 - Estructura de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9fe88-2d43-4bab-b632-dcede5e4464e",
   "metadata": {},
   "source": [
    "Desde el punto de vista estructural, una red de neuronas artificial es un **grafo dirigido y ponderado** donde:\n",
    "* Las neuronas son los nodos.\n",
    "* Las conexiones entre ellas constituyen los arcos del grafo.\n",
    "\n",
    "La conectividad entre neuronas viene definida según capas secuenciales conectadas entre si:\n",
    "* En primer lugar, una capa de entrada.\n",
    "* Después, una serie de capas ocultas.\n",
    "* Finalmente, una capa de salida\n",
    "\n",
    "Dependiendo de cómo se produzcan las conexiones entre estas capas, podemos diferenciar dos tipos de redes neuronales:\n",
    "\n",
    "* Las **redes de propagación hacia delante** (*feedforward networks*), donde no existen bucles en el grafo que define la red de neuronas.\n",
    "* Las **redes recurrentes** (*recurrent networks*), donde existen bucles producidos por las conexiones de retroalimentación que poseen algunas neuronas.\n",
    "\n",
    "<img src=\"images_1/fnn_rnn.png\" width=\"700\" data-align=\"center\">\n",
    "\n",
    "Con independencia del tipo de red, cada una de las capas, exceptuando las de entrada, está formada por tres elementos básicos:\n",
    "\n",
    "* **Operación matemática** ($U$). Aplica una operación matemática sobre las entradas para generar una salida\n",
    "* **Bias**. Valor constante que se añade a la operación realizada por cada neurona con el objetivo de introducir un sesgo a la entrada, dotando a la capa de mayor flexibilidad o capacidad de adaptación. Podemos entenderlo como un parámetro extra.**Es análogo a la inclusión de una constante en las funciones lineales**.\n",
    "* **Función de activación**. Transforma el resultado de la operación matemática. Esta función intenta imitar el comportamiento del potencial de carga que modifica la distribución de carga de las neuronas; es decir, modifica el valor para ajustarlo o para asignarle mayor o menor importancia. Son esenciales para **convertir una función lineal en una función no-lineal**.\n",
    "\n",
    "A su vez, distinguimos varios tipos de capas según el tipo de conexión existente entre neuronas. Dos tipos de capas comunes (veremos otras más adelante) son:\n",
    "* **Capa completamente conectada** (*fully connected*). Cada neurona se encuentra conectada a cada una de las neuronas de la siguiente capa. Suele usarse como capa oculta.\n",
    "* **Capa de desactivación** (*dropout*). Variante de la capa anterior donde ciertas conexiones se desactivan de forma probabilística. Cada conexisón tiene una probabilidad (dada por el hiperparametro *dropout rate*) de desactivarse. Se utiliza para **evitar el overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c7bdb-a60d-4ee2-b6d6-10f35cbb51e2",
   "metadata": {},
   "source": [
    "## 1.3 - Funciones de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b93fc2-b9cc-45ea-9beb-2aca2b1802aa",
   "metadata": {},
   "source": [
    "### 1.3.1 - Función lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9faa78a-54b0-4f7e-af2c-4a5b88be6fd3",
   "metadata": {},
   "source": [
    "Produce una activación proporcional a la entrada, que se corresponde con la operación matemática de la neurona (la suma ponderada).\n",
    "\n",
    "**Ventajas**\n",
    "* Genera un valor numérico\n",
    "\n",
    "**Desventajas**\n",
    "* Su derivada es constante, así que el gradiente no poseera ningún relación con el valor de entrada\n",
    "\n",
    "<img src=\"images_1/funcion_lineal.png\" width=\"600\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2975f55-43e9-4f9f-81fa-3e69e743413b",
   "metadata": {},
   "source": [
    "### 1.3.2 - Función ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba5a76-7896-4246-9090-3144777a0111",
   "metadata": {},
   "source": [
    "La función ReLU (Rectifier error Linear Unit) es una de las funciones de activación más utilizadas. Esta acepta como entrada cualquier valor real y genera como salida valores iguales o mayores que cero. Asimismo, **ofrece resultados muy similares a los generados por una función sigmoidea, aunque presenta menor coste**.\n",
    "\n",
    "**Ventajas**\n",
    "* Naturaleza no lineal, lo que implica que sus combinaciones son no lineales\n",
    "* Presenta un coste computacional muy bajo.\n",
    "* Genera salidas *sparse* ya que su rango de valores es $[0, x]$.\n",
    "* Como su gradiente tiene un rango de $[0,1]$, hay **menos probabilidades de que el gradiente se desvanezca** (*vanishing gradient problem*), es decir, que tome un valor muy muy pequeño tras una serie de multiplicaciones (como puede ocurrir con la función sigmoide).\n",
    "\n",
    "**Desventajas**\n",
    "* Solo se puede utilizar con capas ocultas\n",
    "* Quita algo de \"flexibilidad\" a la neurona. **No se producirán actualizaciones sobre neuronas cuya activación se efectúe mediante valores negativos**. Esta limitación puede llevar a que ciertas neuronas no se activen, lo que se denomina como dying ReLU.\n",
    "\n",
    "<img src=\"images_1/funcion_relu.png\" width=\"600\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451b120-4246-4422-ab3d-094c272bcfb2",
   "metadata": {},
   "source": [
    "### 1.3.3 - Función Leaky ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e258226-e7a7-434e-b513-1498f49d668c",
   "metadata": {},
   "source": [
    "Evolución de la función ReLU que intenta paliar el problema de aprendizaje de aquellas neuronas que generan valores de activación negativos. Esta función tomo como entrada cualquier valor real y genere como salida valores mayores e iguales a cero, así como un conjunto de valores negativos muy pequeños en base a un parametro $\\alpha$.\n",
    "\n",
    "**Ventajas**\n",
    "* Naturaleza no lineal, lo que implica que sus combinaciones son no lineales\n",
    "* Resuelve de manera parcial el problema dying ReLU, ya que ahora **las activaciones producidas por valores negativos generarán un valor distinto de cero**.\n",
    "\n",
    "**Desventajas**\n",
    "* Solo se puede usar en capas ocultas.\n",
    "* Introduce complejidad al tener otro parametro más a optimizar.\n",
    "* Mayores probabilidades de sufrir el problema del desvanecimiento de gradiente\n",
    "\n",
    "<img src=\"images_1/funcion_leaky_relu.png\" width=\"600\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe51f0-ceea-4be3-9fd1-7f5850ad6b78",
   "metadata": {},
   "source": [
    "### 1.3.4 - Función Sigmoidea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e8ab7-38a6-4883-9ef1-2c409f3498bf",
   "metadata": {},
   "source": [
    "La función sigmoidea acepta como entrada cualquier valor real y genera como salida un valor comprendido entre 0 y 1.\n",
    "\n",
    "**Ventajas**\n",
    "* Su rango de salida se encuentra entre 0 y 1.\n",
    "* Tiene buenas propiedades matemáticas:\n",
    "    * es monotonica (sigue un una única dirección, creciente o decreciente).\n",
    "    * es diferenciable de manera continua.\n",
    "* Posee un **gradiente muy suave** (por lo general no vamos a tener valores extremos), lo que ayuda al aprendizaje.\n",
    "\n",
    "**Desventajas**\n",
    "* Es **sensible a los valores de entrada muy grandes** (positivos o negativos), lo que puede generar el problema del **desvanecimiento de gradiente**.\n",
    "* Es **computacionalmente costosa** de optimizar.\n",
    "\n",
    "<img src=\"images_1/funcion_sigmoidea.png\" width=\"600\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da997cc-5374-42bd-8ca2-0bdfeb786dcf",
   "metadata": {},
   "source": [
    "### 1.3.5 - Función tangente hiperbólica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcdb4ea-571f-4396-a8af-16910901b5c2",
   "metadata": {},
   "source": [
    "La función tangente hiperbólica (*tanh*) acepta como entrada cualquier valor real y genera como salida un valor comprendido entre -1 y 1. Presenta un comportamiento muy similar a la función sigmoidea, aunque suele ofrecer mejores resultados.\n",
    "\n",
    "**Ventajas**\n",
    "* El rango de salida se encuentra entre -1 y 1.\n",
    "* Posee un gradiente muy similar al de la sigmoidea, aunque **algo más pronunciado**. \n",
    "    * Observamos que el gradiente de la función *tanh* es cuatro veces mayor que el gradiente de la función sigmoidea. Esto significa que el uso de la función de activación de *tanh* da como resultado **valores más altos de gradiente** durante el entrenamiento y actualizaciones más altas en los pesos de la red.\n",
    "\n",
    "**Desventajas**\n",
    "* Es **sensible a los valores de entrada muy grandes** (positivos o negativos), lo que puede generar el problema del **desvanecimiento de gradiente**.\n",
    "* Es **computacionalmente costosa** de optimizar.\n",
    "\n",
    "<img src=\"images_1/funcion_tanh.png\" width=\"600\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52bebf-1fc2-429e-8d2c-581b66024802",
   "metadata": {},
   "source": [
    "### 1.3.6 - Función softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c566d837-b7ff-4399-b2d4-88e7f254073f",
   "metadata": {},
   "source": [
    "La función softmax transforma un vector de números reales en un vector de números reales cuya suma es igual a 1; es decir, cada uno de los valores de entrada se convertirá en un número positivo situado entre 0 y 1 que será interpretado como una probabilidad.\n",
    "\n",
    "$$\n",
    "\\text{softmax}(\\mathbf{x})_{i} = \\frac{e^{x_{i}}}{\\sum_{j=1}^{K}e^{x_{j}}} \\ \\ donde \\ i=\\{1, \\dots, K\\} \\ ; \\ \\mathbf{x} = \\{x_{1}, \\dots, x_{K}\\} \\in \\mathbb{R}^{K}\n",
    "$$\n",
    "\n",
    "**Ventajas**\n",
    "* El rango de salida se encuentra entre 0 y 1.\n",
    "* Tiene interpretación probabilística.\n",
    "* Muy útil como capa final de la red en problemas de clasificación.\n",
    "\n",
    "**Desventajas**\n",
    "* Resultados muy limitados cuando se utiliza en capas ocultas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f296f86-6d8e-466d-b658-d8f58b4e9c47",
   "metadata": {},
   "source": [
    "## 1.4 - Back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d7e681-adb3-4064-b9d8-89c1c872df19",
   "metadata": {},
   "source": [
    "### 1.4.1 - Algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4fce2-a882-41c2-b700-37b33a0bbd48",
   "metadata": {},
   "source": [
    "El algoritmo de propagación hacia atrás (*back propagation*) desarollado por Rumelhart, Hinton y Williams en 1986, permite actualizar los pesos de la red neuronal mediante un proceso basado en cuatro etapas:\n",
    "\n",
    "1. La primera etapa consiste en **propagar la información hacia delante** para una instancia calculando la salida de cada neurona en base al actual peso y bias; es decir, se ejecuta el proceso de inferencia del modelo que implementa la red en ese instante.\n",
    "2. La segunda etapa consiste en **calcular el error de la red** mediante la diferencia entre la salida esperada y la salida obtenida por esa red.\n",
    "3. La tercera etapa consiste en **calcular el gradiente del error de cada uno de los pesos**, propagando dicho erro hacia atrás, capa a capa, hasta que se alcance la capa de entrada.\n",
    "4. La cuarta etapa consiste en **ajustar los pesos para reducir el error** utilizando el algoritmo de optimización (e.g., el algoritmo de gradiente descendiente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8460023-c8ea-406e-ab00-30a7b16b0ec7",
   "metadata": {},
   "source": [
    "### 1.4.2 - Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894e66d-1af4-4d26-ba9f-3245be322717",
   "metadata": {},
   "source": [
    "Para explicar el funcionamiento del algoritmo de *back propagation* de manera sencilla, vamos a construir un perceptrón multicapa que aprenda la operación XOR. Esta red está formada por tres capas:\n",
    "\n",
    "* Una capa de entrada con dos neuronas y una función de activación sigmoidea\n",
    "* Una capa oculta con dos neuronas y una función sigmoidea\n",
    "* Una capa de salida con una neurona (que devuleve el resultado de la activación de la capa oculta)\n",
    "\n",
    "<img src=\"images_1/backpropagation_example.png\" width=\"500\" data-align=\"center\">\n",
    "\n",
    "Esta red de neuronas cuenta con dos matrices de pesos:\n",
    "* La matriz de pesos $w_{1}$, que representa las conexiones de la capa de entrada con la capa oculta.\n",
    "* La matriz de pesos $w_{2}$, que representa las conexiones de la capa oculta con la capa de salida.\n",
    "\n",
    "**Nota:** Si bien no hemos introducido el parámetro de *bias* en este ejemplo, su presencia no cambiaría el proceso de back propagation.\n",
    "\n",
    "A modo de ejemplo, cada una de estas matrices será inicializada mediante un conjunto de valores aleatorios, tal y como se presenta a continuación:\n",
    "\n",
    "$$\n",
    "w^{1} = \\begin{bmatrix}\n",
    "w_{11}^{1} & w_{12}^{1} \\\\\n",
    "w_{21}^{1} & w_{22}^{1}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0.2 & 0.5 \\\\\n",
    "-0.6 & 0.3 \n",
    "\\end{bmatrix} \\ \\ \\ \\ \\  w^{2} = \\begin{bmatrix}\n",
    "w_{11}^{2}  \\\\\n",
    "w_{21}^{2} \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0.3  \\\\\n",
    "0.5 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Además utilizaremos:\n",
    "* Una tasa de aprendizaje $\\alpha$ de $0.25$\n",
    "* Una instancia de entrenamiento con un valor de entrada $\\mathbf{x} = \\{x_{1}, x_{2}\\} = \\{0, 1\\}$ y un valor esperado de salida $y=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88635c79-1f1f-426a-aafe-2775758355ca",
   "metadata": {},
   "source": [
    "### Propagar la información hacia delante\n",
    "\n",
    "El primer paso consiste en calcular los valores generados por cada una de las neuronas con el objetivo de obtener la predicción de la red.\n",
    "\n",
    "----\n",
    "\n",
    "##### <b><span style=\"color:blue\">Capa oculta</span></b>\n",
    "\n",
    "El valor de la neurona $o_{1}$ se calcularía de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Entrada} &= \\begin{bmatrix} 0  & 1 \\end{bmatrix} \\begin{bmatrix} 0.2  \\\\ -0.6 \\end{bmatrix} = 0*0.2 + 1*(-0.6) = -0.6\\\\\n",
    "\\text{Salida} &= \\frac{1}{1+e^{-x}} = \\frac{1}{1+e^{-(-0.6)}} = 0.35\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "El valor de la neurona $o_{2}$ se calcularía de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Entrada} &= \\begin{bmatrix} 0  & 1 \\end{bmatrix} \\begin{bmatrix} 0.5  \\\\ -0.3\\end{bmatrix} = 0*0.5 + 1*0.3 = 0.3\\\\\n",
    "\\text{Salida} &= \\frac{1}{1+e^{-x}} = \\frac{1}{1+e^{-0.3}} = 0.57\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "##### <b><span style=\"color:blue\">Capa de salida</span></b>\n",
    "\n",
    "Finalmente, el valor de la neurona $s_{1}$ se calcularía del siguiente modo:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Entrada} &= \\begin{bmatrix} 0.35  & 0.57 \\end{bmatrix} \\begin{bmatrix} 0.3  \\\\ 0.5 \\end{bmatrix} = 0.35*0.3 + 0.57*0.5 = 0.39\\\\\n",
    "\\text{Salida} &= \\frac{1}{1+e^{-x}} = \\frac{1}{1+e^{-0.39}} = 0.59\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb62d49-c30f-4c24-8d7f-18778bd8984b",
   "metadata": {},
   "source": [
    "#### Calcular el error de la red\n",
    "\n",
    "Una vez obtenida la salida, calculamos el error mediante la siguiente ecuación:\n",
    "\n",
    "$$\n",
    "\\text{error} = y - \\hat{y} = 1 -0.59 = 0.31\n",
    "$$\n",
    "\n",
    "**Nota:** Si considerasemos más de una instancia, sumariamos los errores de cada instancia para obtener el error total. Por ejemplo mediante el error cuadrático medio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a4882-4849-4428-81bd-547c9c711ba7",
   "metadata": {},
   "source": [
    "#### Calcular el gradiente del error y ajustar los pesos\n",
    "\n",
    "Tras el cálculo del error, vamos a recalcular los valores de los pesos en base al error obtenido para el ejemplo de entrenamiento. Para ello, **iteramos por cada una de las capas, empezando por la de salida**, aplicando la siguiente ecuación en cada peso de neurona:\n",
    "\n",
    "$$\n",
    "w_{jk} = w_{jk} + \\alpha s_{j}^{p-1} \\Delta_{k}\n",
    "$$\n",
    "\n",
    "Donde $\\alpha$ es la tasa de aprendizaje, $p$ es el indice de capa, $j$ y $k$ son los índices de conexión, $s^{p-1}_{j}$ es la salida de la capa anterior y $\\Delta_{k}$ (gradiente) el error estimado. El gradiente no es más que **la tasa de cambio**, por lo que su fórmula se corresponde con la multiplicación de **la derivada de la función por el error ponderado de cada neurona de la capa**.\n",
    "\n",
    "<img src=\"images_1/backpropagation_example_2.png\" width=\"800\" data-align=\"center\">\n",
    "\n",
    "----\n",
    "\n",
    "##### <b><span style=\"color:blue\">Capa de salida</span></b>\n",
    "Para la capa de salida, el gradiente toma la siguiente forma:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta_{1} &= s_{k}^{p} * (1- s_{k}^{p}) * \\text{error} = s_{k}^{p} * (1 - s_{k}^{p}) * (y - s_{k}^{p}) \\\\\n",
    "\\Delta_{1} &= 0.59 - (1 - 0.59) * (1-0.59) = 0.056699 \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "De este modo, los nuevos valores de los pesos $w^{2}$ se calcularían de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "w_{11}^{2'} &= w_{11}^{2} + \\alpha s_{1}^{2} \\Delta_{1} = 0.3 + 0.25 * 0.35 * 0.056699 = 0.3042 \\\\\n",
    "w_{21}^{2'} &= w_{21}^{2} + \\alpha s_{2}^{2} \\Delta_{1} = 0.5 + 0.25 * 0.57 * 0.056699 = 0.5080\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "##### <b><span style=\"color:blue\">Capa oculta</span></b>\n",
    "\n",
    "Para la capa oculta, **no tenemos un \"error puro\" como en la capa de salida**. Lo que tenemos es **la propagación del error al pasar por la capa de salida**, siendo esta propagación **ponderada por los pesos** correspondientes a las conexiones con la capa oculta:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta_{k} &= s_{k}^{p} * (1- s_{k}^{p}) * \\text{error} = s_{k}^{p} * (1- s_{k}^{p}) * \\sum_{k=1}^{p} w_{jk}^{p+1} \\Delta_{k} \\\\\n",
    "\\Delta_{11} &= 0.35 * (1 - 0.35) * (0.3 * 0.056699) = 0.003869\\\\\n",
    "\\Delta_{21} &= 0.57 * (1 - 0.57) * (0.5 * 0.056699) = 0.006948\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Nota:** En este caso los sumatorios de $\\Delta_{11}$ y $\\Delta_{21}$ toman un único valor cada uno, ya que sólo hay una neurona en la capa anterior (la de salida). Si hubiera más de una neurona, sumariamos sus correspondientes errores ponderados (asumiendo *fully-connected*).\n",
    "\n",
    "Así, los nuevos valores de los pesos $w^{1}$ se calcularían de la siguiente manera:\n",
    "\n",
    "* Para la primera neurona:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "w_{11}^{1'} &= w_{11}^{1} + \\alpha s_{1}^{1} \\Delta_{11} = 0.2 + 0.25 * (0 * 0.003869) = 0.2\\\\\n",
    "w_{21}^{1'} &= w_{21}^{1} + \\alpha s_{1}^{1} \\Delta_{11} = -0.6 + 0.25 * (1 * 0.003869) = -0.59\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "* Para la segunda neurona:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "w_{12}^{1'} &= w_{12}^{1} + \\alpha s_{2}^{1} \\Delta_{21} = 0.5 + 0.25 * (0 * 0.006948) = 0.5\\\\\n",
    "w_{22}^{1'} &= w_{22}^{1} + \\alpha s_{2}^{1} \\Delta_{21} = 0.3 + 0.25 * (1 * 0.006948) = 0.3017\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "Por lo tanto, tras la ejecución del algoritmo de *back propagation* para un ejemplo de entrenamiento, los pesos de la red quedarían de la siguiente manera:\n",
    "\n",
    "$$\n",
    "w^{1'} = \\begin{bmatrix}\n",
    "w_{11}^{1'} & w_{12}^{1'} \\\\\n",
    "w_{21}^{1'} & w_{22}^{1'}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0.2 & 0.5 \\\\\n",
    "-0.59 & 0.3017 \n",
    "\\end{bmatrix} \\ \\ \\ \\ \\  w^{2'} = \\begin{bmatrix}\n",
    "w_{11}^{2'}  \\\\\n",
    "w_{21}^{2'} \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0.3042  \\\\\n",
    "0.5080\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Nota:** Si repitiésemos este proceso de forma iterativa, veríamos como **el error va decreciendo poco a poco**. Este proceso de optimización sería el **descenso por gradiente**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137a2fb-ffa8-4ce9-978d-29d95d3022ee",
   "metadata": {},
   "source": [
    "## 1.5 - Inicialización de capas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0984d-a68a-4112-b54e-b75f87c1763a",
   "metadata": {},
   "source": [
    "Una vez definida la estructura de la red, es necesario iniciar los valores correspondientes a los pesos $w$ de las conexiones entre neuronas. Este proceso no es trivial, ya que dependiendo del valor inicial de los pesos y la función de activación seleccionada, el proceso de entrenamiento puede resultar más o menos efectivo.\n",
    "\n",
    "Existen diferentes técnicas de inicialización de los pesos de las neuronas:\n",
    "\n",
    "* **Inicialización a cero**. Se inicializan los pesos y el *bias* de la red a $0$.\n",
    "    * Poco común ya que acarrea problemas.\n",
    "    * El bias no contribuye ya que su valor es $0$.\n",
    "    * Si todos los pesos se inicializan a $0$, la derivada con respecto a la función de pérdida es la misma para cada peso, así que todos los pesos presentarán el mismo valor en iteraciones posteriores. Es decir, <span style=\"color:blue\">la red de neuronas se comportaría como un modelo lineal</span>.\n",
    "* **Inicialización aleatoria**. Los pesos y el bias se inicializan aleatoriamente. Aunque dependiendo del tipo de valor que se utilice, puede implicar ciertos problemas:\n",
    "    1. Si los valores asignados son muy elevados, se puede producir una ralentización del aprendizaje. Por ejemplo si tenemos una función de activación sigmoidea, ya que el gradiente cambia muy despacio para valores cercanos a $1$ (ver función).\n",
    "    2. Si los valores asignados son muy pequeños, se producirá el problema del desvanecimiento del gradiente, ya que los valores acabaran por tender a $0$.\n",
    "    * Por ello, es importante utilizar un algoritmo de inicialización que genere valores medios a la hora de inicializar los pesos. Si bien este modo de inicialización es el más común, hay casos donde otros métodos pueden ser mas interesantes. Por ejemplo:\n",
    "* **Inicialización Xavier**. Propuesto por Xavier Glorot y Yoshua Bengio para evitar la aparición del desvanecimiento del gradiente.\n",
    "    * Intenta que la varianza de las salidas de una capa sea igual a la varianza de las entradas, generando un equilibrio, de tal forma que no se computen gradientes iguales o cercanos a $0$.\n",
    "    * Utiliza una distribución normal con media $0$, así como una desviación estándar calculada de la siguiente manera:\n",
    "    $$\n",
    "    \\sigma = \\sqrt{\\frac{2}{n_{c} + n_{c+1}}}\n",
    "    $$\n",
    "    \n",
    "    donde $n_{c}$ representa el número de neuronas de la capa $c$. En Tensorflow se define con `xavier_initializer`.\n",
    "* **Inicialización He**. Evolución del método de inicialización de Xavier que se aplica sobre funciones de activación ReLU ya que el método de Xavier no funciona correctamente con este tipo de función. \n",
    "   * Utiliza una distribución normal con media $0$, así como una desviación estándar calculada de la siguiente manera:\n",
    "    $$\n",
    "    \\sigma = \\sqrt{\\frac{1}{n_{c-1}}}\n",
    "    $$\n",
    "    En Tensorflow, se define mediante la función `variance_scaling_initializer`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
