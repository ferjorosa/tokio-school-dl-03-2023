{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7942e84-3a32-4acf-8500-4ecb96589a94",
   "metadata": {},
   "source": [
    "# 3 - Regresión\n",
    "\n",
    "**Sumario**\n",
    "\n",
    "1. Introducción\n",
    "2. Regresión lineal matemática\n",
    "2. Funciones de pérdida\n",
    "3. Regresión lineal simple con redes neuronales\n",
    "4. Regresión no lineal múltiple con redes neuronales\n",
    "5. Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba2e8f-1ee6-40b8-a503-593d65a3ddee",
   "metadata": {},
   "source": [
    "## 3.1 - Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0096c-fe92-47ae-a2c5-def5244ba995",
   "metadata": {},
   "source": [
    "En tareas de regresión, nuestro objetivo es construir un modelo capaz de **predecir correctamente uno o varios valores numéricos continuos para cada uno de las instancias de entrada**. En este capítulo nos vamos a centrar en predecir un único valor numérico para cada una de las instancias. \n",
    "\n",
    "Por ejemplo, podemos querer predecir el precio de la vivienda en función de ciertos factores como el área de la casa, las habitaciones, el mobiliario, la cercanía a la carretera principal, etc.\n",
    "\n",
    "<img src=\"images_3/vivienda.jpg\" width=\"500\" data-align=\"center\">\n",
    "\n",
    "Dependiendo del número de atributos que contemos para predecir, distinguimos dos tipos principales de regresión:\n",
    "* **Regresión simple.** Contamos con un único atributo para predecir la variable objetivo.\n",
    "* **Regresión múltiple.** Contamos con múltiples atributos para predecir la variable objetivo.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Regresión (lineal) simple</th>\n",
    "        <th>regresión (lineal) múltiple</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/linear_regresion_simple.png\" width=\"400\" data-align=\"center\"></td>\n",
    "        <td><img src=\"images_3/linear_regresion_multiple.png\" width=\"400\" data-align=\"center\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Dado un dataset con forma $(\\mathbf{x}^{(i)}, y^{(i)})$, nuestro objetivo es aprender una función $f(\\mathbf{x})$ con la que predecir $y$ dado $\\mathbf{x}$, donde $y$ es un valor continuo. Dependiendo de la forma de $f(x)$, distinguimos dos tipos principales de regresión:\n",
    "* **Regresión lineal.**\n",
    "* **Regresión no lineal.**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Regresión lineal (simple)</th>\n",
    "        <th>regresión no lineal (simple)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/regresion_lineal.png\" width=\"400\" data-align=\"center\"></td>\n",
    "        <td><img src=\"images_3/regresion_no_lineal.png\" width=\"800\" data-align=\"center\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "En este caso, mostramos un ejemplo de regresión no lineal mediante el uso de un árbol de regresión. Otros métodos comunes de regresión no lineal incluyen: KNN y, por supuesto, **las redes neuronales**. Los métodos de regresión no lineal son **más flexibles**, pero por lo general son **menos interpretables**, ya que el modelo es considerablemente más complejo (e.g., las redes neuronales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69666337-ffd8-4f24-b959-a9403f144655",
   "metadata": {},
   "source": [
    "## 3.2 - Regresión lineal matemática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a1a85-8356-4e24-bb68-8e1b53614e33",
   "metadata": {},
   "source": [
    "La regresión linal simple consiste en calcular un modelo de regresión que se corresponde con la ecuación de una recta:\n",
    "    \n",
    "$$\n",
    "y = \\beta_{0} + \\beta_{1}x + \\epsilon\n",
    "$$\n",
    "\n",
    "Donde $\\beta_{0}$ se corresponde con la **ordenada de la recta**, $\\beta_{1}$ con la **pendiente de la recta**, y $\\epsilon$ con un **error aleatorio** o **residuo**. El proceso de estimación de los parámetros $\\beta_{0}$ y $\\beta_{1}$ (conocidos como los coeficientes de regresión) se suele realizar mediante el método de los mínimos cuadrados, cuya fórmula es la siguiente:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_{1} &= \\frac{\\sum_{i=1}^{n}(x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum_{i=1}^{n}} = \\frac{S_{y}}{S_{x}}R\\\\\n",
    "\\hat{\\beta}_{0} &= \\bar{y} - \\beta_{1}x\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Donde $S_{x}$ y $S_{y}$ son las desviaciones típicas de cada variable y $R$ es el coeficiente de correlación. Por su parte, $\\beta_{0}$ se corresponde con el valor esperado de $y$ cuando $x=0$. La siguiente figura muestra la recta resultante de aplicar el método de minimoso cuadrados:\n",
    "\n",
    "<img src=\"images_3/minimos_cuadrados.png\" width=\"400\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b26598-f450-4404-b0dc-af1290200e7f",
   "metadata": {},
   "source": [
    "### 3.2.1 - Condiciones para aplicar exitosamente la regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a78f8-f61b-47dd-8076-15e85db5352f",
   "metadata": {},
   "source": [
    "A la hora de construir un modelo basado en una regresión lineal, deben cumplirse una serie de criteriors para poder calcular los parámetros de la recta:\n",
    "    \n",
    "* **Linealidad.** La relación entre la variable predictora y la variable a predecir debe ser lineal.\n",
    "* **Distribución normal de los residuos.** Los residuos han de distribuirse de forma normal, con una media igual a 0. Esto se puede comprobar mediante un histograma o un test de hipótesis de normalidad. **Los valores extremos suelen ser una causa frecuente por la que se infringe la condición de normalidad**.\n",
    "* **Varianza de residuos constante (homocedasticidad).** varianza de los residuos ha de ser prácticamente constante a lo largo del eje $x$.\n",
    "\n",
    "Para comprobar si se cumplen estas condiciones, es necesario calcular los residuos y, a continuación validar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae6e9b-0b29-4dc3-85ad-1dd08b0f26d7",
   "metadata": {},
   "source": [
    "### 3.2.1 Implementación de una regresión lineal simple con Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6d283-6533-4b92-b2f5-e98f44b065f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Carga de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f072d6-b67e-4904-9dff-9af121f763e2",
   "metadata": {},
   "source": [
    "En primer lugar tenemos que cargar los datos y generar los splits de entrenamiento, validación y test. Utilizaremos el [Ames Housing dataset de Kaggle](https://www.kaggle.com/datasets/prevek18/ames-housing-dataset) para ello. \n",
    "\n",
    "----\n",
    "\n",
    "**Nota:** Por simplicidad, he descargado los datos de antemano y los he colocado en la carpeta \"data\" del directorio actual.\n",
    "\n",
    "-----\n",
    "\n",
    "<details>\n",
    "    <summary><b>Explicación de las variables</b> (Hacer click)</summary>\n",
    "  \n",
    "* Feature variables:\n",
    "    * **MSSubClass** : The building class\n",
    "    * **MSZoning** : The general zoning classification\n",
    "    * **LotFrontage** : Linear feet of street connected to property\n",
    "    * **LotArea** : Lot size in square feet\n",
    "    * **Street** : Type of road access\n",
    "    * **Alley** : Type of alley access\n",
    "    * **LotShape** : General shape of property\n",
    "    * **LandContour** : Flatness of the property\n",
    "    * **Utilities** : Type of utilities available\n",
    "    * **LotConfig** : Lot configuration\n",
    "    * **LandSlope** : Slope of property\n",
    "    * **Neighborhood** : Physical locations within Ames city limits\n",
    "    * **Condition1** : Proximity to main road or railroad\n",
    "    * **Condition2** : Proximity to main road or railroad (if a second is present)\n",
    "    * **BldgType** : Type of dwelling\n",
    "    * **HouseStyle** : Style of dwelling\n",
    "    * **OverallQual** : Overall material and finish quality\n",
    "    * **OverallCond** : Overall condition rating\n",
    "    * **YearBuilt** : Original construction date\n",
    "    * **YearRemodAdd** : Remodel date\n",
    "    * **RoofStyle** : Type of roof\n",
    "    * **RoofMatl** : Roof material\n",
    "    * **Exterior1st** : Exterior covering on house\n",
    "    * **Exterior2nd** : Exterior covering on house (if more than one material)\n",
    "    * **MasVnrType** : Masonry veneer type\n",
    "    * **MasVnrArea** : Masonry veneer area in square feet\n",
    "    * **ExterQual** : Exterior material quality\n",
    "    * **ExterCond** : Present condition of the material on the exterior\n",
    "    * **Foundation** : Type of foundation\n",
    "    * **BsmtQual** : Height of the basement\n",
    "    * **BsmtCond** : General condition of the basement\n",
    "    * **BsmtExposure** : Walkout or garden level basement walls\n",
    "    * **BsmtFinType1** : Quality of basement finished area\n",
    "    * **BsmtFinSF1** : Type 1 finished square feet\n",
    "    * **BsmtFinType2** : Quality of second finished area (if present)\n",
    "    * **BsmtFinSF2** : Type 2 finished square feet\n",
    "    * **BsmtUnfSF** : Unfinished square feet of basement area\n",
    "    * **TotalBsmtSF** : Total square feet of basement area\n",
    "    * **Heating** : Type of heating\n",
    "    * **HeatingQC** : Heating quality and condition\n",
    "    * **CentralAir** : Central air conditioning\n",
    "    * **Electrical** : Electrical system\n",
    "    * **1stFlrSF** : First Floor square feet\n",
    "    * **2ndFlrSF** : Second floor square feet\n",
    "    * **LowQualFinSF** : Low quality finished square feet (all floors)\n",
    "    * **GrLivArea** : Above grade (ground) living area square feet\n",
    "    * **BsmtFullBath** : Basement full bathrooms\n",
    "    * **BsmtHalfBath** : Basement half bathrooms\n",
    "    * **FullBath** : Full bathrooms above grade\n",
    "    * **HalfBath** : Half baths above grade\n",
    "    * **Bedroom** : Number of bedrooms above basement level\n",
    "    * **Kitchen** : Number of kitchens\n",
    "    * **KitchenQual** : Kitchen quality\n",
    "    * **TotRmsAbvGrd** : Total rooms above grade (does not include bathrooms)\n",
    "    * **Functional** : Home functionality rating\n",
    "    * **Fireplaces** : Number of fireplaces\n",
    "    * **FireplaceQu** : Fireplace quality\n",
    "    * **GarageType** : Garage location\n",
    "    * **GarageYrBlt** : Year garage was built\n",
    "    * **GarageFinish** : Interior finish of the garage\n",
    "    * **GarageCars** : Size of garage in car capacity\n",
    "    * **GarageArea** : Size of garage in square feet\n",
    "    * **GarageQual** : Garage quality\n",
    "    * **GarageCond** : Garage condition\n",
    "    * **PavedDrive** : Paved driveway\n",
    "    * **WoodDeckSF** : Wood deck area in square feet\n",
    "    * **OpenPorchSF** : Open porch area in square feet\n",
    "    * **EnclosedPorch** : Enclosed porch area in square feet\n",
    "    * **3SsnPorch** : Three season porch area in square feet\n",
    "    * **ScreenPorch** : Screen porch area in square feet\n",
    "    * **PoolArea** : Pool area in square feet\n",
    "    * **PoolQC** : Pool quality\n",
    "    * **Fence** : Fence quality\n",
    "    * **MiscFeature** : Miscellaneous feature not covered in other categories\n",
    "    * **MiscVal** : Value of miscellaneous feature in \\$\n",
    "    * **MoSold** : Month Sold\n",
    "    * **YrSold** : Year Sold\n",
    "    * **SaleType** : Type of sale\n",
    "    * **SaleCondition** : Condition of sale\n",
    "\n",
    "\n",
    "* Predictive variable:\n",
    "    * **SalePrice** - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "Para este ejemplo, vamos a utilizar como variable predictora el número de habitaciones en la casa (excluyendo las del sótano) `TotRms AbvGrd` y como variable a predecir el precio de la vivienda `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d13972e-9e2a-409d-92dd-b80b00e58268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances: 2373\n",
      "Validation instances: 264\n",
      "Test instances: 293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"./data/AmesHousing.csv\")\n",
    "\n",
    "# Seleccionamos la columna que nos interesa como predictora y le aplicamos normalización estándar\n",
    "data_x = data[\"TotRms AbvGrd\"] / data[\"TotRms AbvGrd\"].max()\n",
    "\n",
    "# Seleccionamos la variabla predecir y le aplicamos normalización estándar\n",
    "data_y = data[\"SalePrice\"] / data[\"SalePrice\"].max()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data_x,\n",
    "    data_y,\n",
    "    test_size=0.10,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    test_size=0.10,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"Training instances: {x_train.shape[0]}\")\n",
    "print(f\"Validation instances: {x_val.shape[0]}\")\n",
    "print(f\"Test instances: {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a967a-ca24-45df-a8f5-ac18019d0ed8",
   "metadata": {},
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Para el entrenamiento, vamos a definir el modelo a mano y utilizar el método del descenso por gradiente para su optimización. \n",
    "\n",
    "<img src=\"images_3/linear_Regression_gradient_descent.gif\" width=\"400\" data-align=\"center\">\n",
    "\n",
    "Con este propósito en mente, vamos a utilizar la API de diferenciación automatica de Tensorflow `tf.GradientTape`. [Para más información acerca de ella, recomiendo echar un ojo a la documentación original, especialmente su tutorial](https://www.tensorflow.org/api_docs/python/tf/GradientTape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c105ba59-d241-4439-8613-a62746879689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Loss: 0.06843797862529755 - val_loss 0.0429266095161438\n",
      "Epoch: 2\n",
      "Loss: 0.04415927454829216 - val_loss 0.02915279194712639\n",
      "Epoch: 3\n",
      "Loss: 0.03002299927175045 - val_loss 0.021184256300330162\n",
      "Epoch: 4\n",
      "Loss: 0.021791117265820503 - val_loss 0.01658261939883232\n",
      "Epoch: 5\n",
      "Loss: 0.01699644699692726 - val_loss 0.01393139734864235\n",
      "Epoch: 6\n",
      "Loss: 0.014202751219272614 - val_loss 0.01240827701985836\n",
      "Epoch: 7\n",
      "Loss: 0.012573916465044022 - val_loss 0.011536307632923126\n",
      "Epoch: 8\n",
      "Loss: 0.01162321213632822 - val_loss 0.011039153672754765\n",
      "Epoch: 9\n",
      "Loss: 0.011067281477153301 - val_loss 0.010756966657936573\n",
      "Epoch: 10\n",
      "Loss: 0.010741183534264565 - val_loss 0.010597459971904755\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "b0 = tf.Variable(0., dtype=tf.float32)\n",
    "b1 = tf.Variable(0., dtype=tf.float32)\n",
    "\n",
    "# Si disminuimos el lr, el modelo aprenderá mas lento pero será \"más preciso\" en su optimización. \n",
    "# En tal caso deberiamos aumentar el numero de epochs\n",
    "lr = 0.1 \n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        with tf.GradientTape() as t:\n",
    "            y_pred = b1 * x_train + b0\n",
    "            current_loss = tf.reduce_mean(tf.square(y_pred - y_train))\n",
    "        \n",
    "        lr_b1, lr_b0 = tape.gradient(current_loss, [b1, b0])\n",
    "        b1.assign_sub(lr * lr_b1)\n",
    "        b0.assign_sub(lr * lr_b0)\n",
    "        \n",
    "        y_val_pred = b1 * x_val + b0\n",
    "        val_loss = tf.reduce_mean(tf.square(y_val_pred - y_val))\n",
    "        \n",
    "        tf.print(f\"Epoch: {epoch+1}\")\n",
    "        tf.print(f\"Loss: {current_loss} - val_loss {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426763b-2648-438b-be36-0e2bccff403a",
   "metadata": {},
   "source": [
    "#### Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4645ad0f-25fe-4072-bc81-75b286b1ec81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def model(b0, b1, x_train):\n",
    "    return b1 * x_train + b0\n",
    "\n",
    "def print_regression_line(b0, b1, X_print, X, Y):\n",
    "    plt.rcParams[\"figure.figsize\"] = (14,6)\n",
    "    plt.rcParams[\"lines.linewidth\"] = 3\n",
    "    plt.rcParams[\"axes.labelsize\"] = 20\n",
    "    plt.scatter(X_print, Y, label=\"Real\")\n",
    "    plt.scatter(X_print, model(b0, b1, X), label=\"Predecido\")\n",
    "    plt.legend([\"Real\", \"Predecido\"])\n",
    "    plt.show()\n",
    "\n",
    "print_regression_line(b0, b1, x_train, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec950ff-0276-41a8-a527-b8fcf26d3602",
   "metadata": {},
   "source": [
    "## 3.3 - Funciones de pérdida (*loss*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b70f7-f089-4487-a31b-af15d717edfc",
   "metadata": {},
   "source": [
    "En el tema anterior, hemos descrito las diferentes funciones de pérdida que se aplica cuando construimos redes neuronales para clasificación. Sin embargo, estas funciones no pueden aplicarse a modelos de regresión dada la naturaleza de su salida, ya que el resultado de este tipo de modelos **es un valor numérico de tipo decimal y no un conjunto de clases y/o etiquetas**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cc16b-a0ec-41b1-a991-96cfbaac7c99",
   "metadata": {},
   "source": [
    "### 3.3.1 - Error cuadrático medio (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d694a5-7541-4051-b9f7-db1201db5a1a",
   "metadata": {},
   "source": [
    "El error cuadrático medio (**Mean Square Error**, MSE por sus siglas en inglés) es, probablemente, **la métrica más sencilla y la más utilizada** para evaluar la pérdida de un modelo de regresión. Se calcula mediante la siguiente formula:\n",
    "\n",
    "$$\n",
    "MSE(\\mathbf{y}, \\mathbf{\\hat{y}}) = \\frac{1}{n} \\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}\n",
    "$$\n",
    "\n",
    "Donde $n$ es el número de instancias de entrenamiento que se utilizará para calcular el valor de pérdida, $y_{i}$ el valor de salida esperado e $\\hat{y}_{i}$ el valor de salida predecido. Esta métrica nos devuelve siempre valores positivos, de forma que **cuanto más se aproximen a cero mejor será el modelo que hemos construido**. \n",
    "\n",
    "Uno de sus grandes problemas es que **aumenta muy rápido con valores extremos** debido al cuadrado de la diferencia de los valores. Esto nos puede causar un problema si no hemos normalizado la variable objetivo y esta trabaja con valores muy grandes/muy pequeños. Por otro lado, es positivo que eleve al cuadrado la diferencia ya que **penaliza fuertemente los valores atípicos**.\n",
    "\n",
    "Otro problema del MSE es su interpretabilidad, ya que nos está indicando la diferencia cuadrática promedio. **Seria interesante que el error trabajase en la misma \"escala\" que las predicciones, no en su versión cuadrática**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfbd2b4-13fa-4659-a767-f26da2a0ef71",
   "metadata": {},
   "source": [
    "### 3.3.2 - Raíz cuadrada del error cuadrático medio (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b7b2a-ad74-41ce-8688-e4b4e3c8e8fb",
   "metadata": {},
   "source": [
    "Para solventar las limitaciones del MSE, podemos aplicar la raiz cuadrada al resultado. Con ello, tendriamos el **Root Mean Square Error** (RMSE). Esta función se calcula por tanto mediante la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "RMSE(\\mathbf{y}, \\mathbf{\\hat{y}}) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}} = \\sqrt{MSE(y, \\hat{y})}\n",
    "$$\n",
    "\n",
    "Donde $n$ es el número de instancias de entrenamiento que se utilizará para calcular el valor de pérdida, $y_{i}$ el valor de salida esperado e $\\hat{y}_{i}$ el valor de salida predecido. Esta métrica nos devuelve siempre valores positivos, de forma que **cuanto más se aproximen a cero mejor será el modelo que hemos construido**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6ffbe-8dad-420a-8e2f-ac46c5d0d39d",
   "metadata": {},
   "source": [
    "### 3.3.3 - Error absoluto medio (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415be7b-570a-4a8e-bd4c-0e4dbd1675b5",
   "metadata": {},
   "source": [
    "El error absoluto medio (**Mean Absolute Error**, MAE por sus siglas en inglés) es una función que permite evaluar un modelo calculando **el error promedio de las diferencias aboslutas** entre las predicciones y los valores reales. Se calcula mediante la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "MAE(\\mathbf{y}, \\mathbf{\\hat{y}}) = \\frac{\\sum_{i=1}^{n}|y_{i} - \\hat{y}_{i}|}{n}\n",
    "$$\n",
    "\n",
    "Donde $n$ es el número de instancias de entrenamiento que se utilizará para clacular el valor de pérdida, $y_{i}$ el valor de salida esperado e $\\hat{y}_{i}$ el valor de salida predecido. Se trata de una función que devuelve siempre valores positivos.\n",
    "\n",
    "Similar a RMSE, trabaja en la misma escala que las predicciones. Sin embargo, **a diferencia de MSE/RMSE no penaliza tanto los valores atípicos ya que no eleva al cuadrado la diferencia**.\n",
    "\n",
    "Este tipo de función de pérdida se suele utilizar en elos procesos de análisis de series temporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc050b-da85-4678-9d55-a62ad6abd64b",
   "metadata": {},
   "source": [
    "### 3.3.4 - Coeficiente de determinación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f2306-7b7c-4266-9773-eec5955049e8",
   "metadata": {},
   "source": [
    "El coeficiente de determinación o $R^{2}$ se calcula a partir del MSE pero cuenta con la enorme ventaja de estar libre de escala. Por tanto, no importa si los valores de salida son muy grandes o muy pequeños, el $R^{2}$ siempre se situará en $[-\\infty, 1]$. Se calcula de la siguiente forma:\n",
    "\n",
    "$$\n",
    "R^{2}(\\mathbf{y}, \\mathbf{\\hat{y}}) = \\frac{MSE(y, \\hat{y})}{MSE_{\\text{baseline}}(y, \\hat{y})}\n",
    "$$\n",
    "\n",
    "Donde $MSE_{\\text{baseline}}$ se calcula por medio de la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "MSE(\\mathbf{y}, \\mathbf{\\hat{y}}) = \\frac{1}{n} \\sum_{i=1}^{n}(y_{i} - \\bar{y}_{i})^{2}\n",
    "$$\n",
    "\n",
    "Donde  $n$ es el número de instancias de entrenamiento que se utilizará para calcular el valor de pérdida, $y_{i}$ el valor de salida esperado e $\\hat{y}$ la **media aritmética** de los valores de $\\mathbf{y}$. El valor generado por $MSE_{\\text{baseline}}$ **se corresponde con el modelo más simple posible para predecir los valores de** $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1312114-bb36-496f-a631-477eb72e3897",
   "metadata": {},
   "source": [
    "## 3.4 - Regresión lineal simple con redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792406c-403c-449b-9883-eab2471faa75",
   "metadata": {},
   "source": [
    "Como ya hemos comentado anteriormente, la regresión lineal simple es el modelo de regresión más sencillo y considera dos variables numéricas: (1) una variable independiente, normalmente identificada como $x$, y (2) una variable dependiente, normalmente identificada como $y$. El objetivo es identificar los coeficientes de la recta de regresión que mejor aproxime los valores de $y$.\n",
    "\n",
    "En este caso vamos a ver como podemos utilizar una red neuronal para construir un modelo de regresión lineal. Para ello utilizaremos **una única capa oculta con un número de neuronas igual al número de variables de entrada**. Dado que este caso se centra en regresión simple, contaremos con una única neurona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02149a22-571b-4bf7-8bde-c8bb32aff4d7",
   "metadata": {},
   "source": [
    "### 3.4.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f69bde6-fb8a-46a0-ad5f-582ed0adf881",
   "metadata": {},
   "source": [
    "Con respecto a los datos de entrenamiento, vamos a utilizar el [Ames Housing dataset de Kaggle](https://www.kaggle.com/datasets/prevek18/ames-housing-dataset).\n",
    "\n",
    "En este caso, vamos a utilizar el mismo split que en la sección 3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "563d54ba-4892-442b-8eb8-4b053ae5764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances: 2373\n",
      "Validation instances: 264\n",
      "Test instances: 293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"./data/AmesHousing.csv\")\n",
    "\n",
    "# Seleccionamos la columna que nos interesa como predictora y le aplicamos normalización estándar\n",
    "data_x = data[\"TotRms AbvGrd\"] / data[\"TotRms AbvGrd\"].max()\n",
    "\n",
    "# Seleccionamos la variabla predecir y le aplicamos normalización estándar\n",
    "data_y = data[\"SalePrice\"] / data[\"SalePrice\"].max()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data_x,\n",
    "    data_y,\n",
    "    test_size=0.10,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    test_size=0.10,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"Training instances: {x_train.shape[0]}\")\n",
    "print(f\"Validation instances: {x_val.shape[0]}\")\n",
    "print(f\"Test instances: {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06627d-9952-47c5-a537-c700cbaf64fd",
   "metadata": {},
   "source": [
    "### 3.4.2 - Construcción de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e045f-9052-4b09-8a2d-439af4ad174e",
   "metadata": {},
   "source": [
    "Una vez preparados nuestros datos, ya podemos construir nuestra red neuronal. Para ello, vamos a crear una red formada por una única capa mediante Keras:\n",
    "* Una capa densa de una neurona con una función de activación de tipo lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a7d8096-a1c5-44b9-a704-b727a543ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"linear_regression_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Creación de las capas que forman la estructura de la red\n",
    "layers = [keras.layers.Dense(1,\n",
    "                             input_shape=(1,),\n",
    "                             activation=tf.keras.activations.linear)\n",
    "         ]\n",
    "\n",
    "# Compilación de la red neuronal\n",
    "model = keras.Sequential(layers, name=\"linear_regression_model\")\n",
    "          \n",
    "# Configuración del algoritmo de optimización y función de loss\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss=\"mse\",\n",
    "    metrics=[keras.metrics.RootMeanSquaredError(), \"mse\", \"mae\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd012a-1c54-4096-bd0e-f2ded48d7083",
   "metadata": {},
   "source": [
    "Como podemos ver el modelo solo cuenta con dos parámetros que equivalen a $\\beta_{0}$ (bias) y $\\beta_{1}$ (el paramétro propio de la neurona)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90738235-14a8-481c-a3e6-6370cca4dd5d",
   "metadata": {},
   "source": [
    "### 3.4.3 - Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c57942-7010-490d-84ab-eae7d2a8fc6f",
   "metadata": {},
   "source": [
    "Una vez compilada nuestra red, podemos iniciar el proceso de entrenamiento mediante la función `fit()`. En este caso hemos seleccionado las siguientes opciones:\n",
    "* Número de epochs: 25\n",
    "* Tamaño del batch de entrenamiento: 250 instancias\n",
    "\n",
    "En este caso no seleccionamos un porcentaje del conjunto de entrenamiento como validación ya que vamos a utilizar el anteriormente definido (simplemente para demostrar como se hace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b62fa7d-4a1b-4a1d-9bd7-5c778af88e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 1s 43ms/step - loss: 0.0718 - root_mean_squared_error: 0.2680 - mse: 0.0718 - mae: 0.2443 - val_loss: 0.0552 - val_root_mean_squared_error: 0.2350 - val_mse: 0.0552 - val_mae: 0.2074\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0486 - root_mean_squared_error: 0.2204 - mse: 0.0486 - mae: 0.1918 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1955 - val_mse: 0.0382 - val_mae: 0.1622\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - mse: 0.0342 - mae: 0.1514 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1665 - val_mse: 0.0277 - val_mae: 0.1281\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0253 - root_mean_squared_error: 0.1592 - mse: 0.0253 - mae: 0.1211 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1456 - val_mse: 0.0212 - val_mae: 0.1041\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0198 - root_mean_squared_error: 0.1407 - mse: 0.0198 - mae: 0.0997 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1314 - val_mse: 0.0173 - val_mae: 0.0892\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0164 - root_mean_squared_error: 0.1281 - mse: 0.0164 - mae: 0.0861 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1218 - val_mse: 0.0148 - val_mae: 0.0806\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0143 - root_mean_squared_error: 0.1195 - mse: 0.0143 - mae: 0.0787 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155 - val_mse: 0.0133 - val_mae: 0.0759\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0130 - root_mean_squared_error: 0.1139 - mse: 0.0130 - mae: 0.0750 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114 - val_mse: 0.0124 - val_mae: 0.0740\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - mse: 0.0121 - mae: 0.0735 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090 - val_mse: 0.0119 - val_mae: 0.0735\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0116 - root_mean_squared_error: 0.1079 - mse: 0.0116 - mae: 0.0730 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074 - val_mse: 0.0115 - val_mae: 0.0736\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0113 - root_mean_squared_error: 0.1064 - mse: 0.0113 - mae: 0.0731 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065 - val_mse: 0.0113 - val_mae: 0.0740\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0111 - root_mean_squared_error: 0.1055 - mse: 0.0111 - mae: 0.0733 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059 - val_mse: 0.0112 - val_mae: 0.0744\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0110 - root_mean_squared_error: 0.1049 - mse: 0.0110 - mae: 0.0736 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1056 - val_mse: 0.0112 - val_mae: 0.0748\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0109 - root_mean_squared_error: 0.1045 - mse: 0.0109 - mae: 0.0740 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054 - val_mse: 0.0111 - val_mae: 0.0751\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0109 - root_mean_squared_error: 0.1042 - mse: 0.0109 - mae: 0.0743 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052 - val_mse: 0.0111 - val_mae: 0.0754\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0108 - root_mean_squared_error: 0.1041 - mse: 0.0108 - mae: 0.0745 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1051 - val_mse: 0.0111 - val_mae: 0.0757\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0108 - root_mean_squared_error: 0.1040 - mse: 0.0108 - mae: 0.0747 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051 - val_mse: 0.0110 - val_mae: 0.0759\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0108 - root_mean_squared_error: 0.1039 - mse: 0.0108 - mae: 0.0749 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050 - val_mse: 0.0110 - val_mae: 0.0761\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0108 - root_mean_squared_error: 0.1038 - mse: 0.0108 - mae: 0.0750 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050 - val_mse: 0.0110 - val_mae: 0.0762\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0108 - root_mean_squared_error: 0.1037 - mse: 0.0108 - mae: 0.0752 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050 - val_mse: 0.0110 - val_mae: 0.0763\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0108 - root_mean_squared_error: 0.1037 - mse: 0.0108 - mae: 0.0753 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049 - val_mse: 0.0110 - val_mae: 0.0764\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - root_mean_squared_error: 0.1037 - mse: 0.0107 - mae: 0.0754 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049 - val_mse: 0.0110 - val_mae: 0.0764\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0107 - root_mean_squared_error: 0.1036 - mse: 0.0107 - mae: 0.0754 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048 - val_mse: 0.0110 - val_mae: 0.0765\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - root_mean_squared_error: 0.1036 - mse: 0.0107 - mae: 0.0754 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048 - val_mse: 0.0110 - val_mae: 0.0765\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0107 - root_mean_squared_error: 0.1035 - mse: 0.0107 - mae: 0.0755 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048 - val_mse: 0.0110 - val_mae: 0.0765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2013883cf40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Definición de los callback de TF Board\n",
    "tensorboard_callback = TensorBoard(log_dir=\"logs_linear_regression_simple\")\n",
    "\n",
    "# Ejecución del proceso de aprendizaje\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=25, # Numero de iteraciones\n",
    "    batch_size=250, # Tamaño de los batches\n",
    "    validation_data=(x_val, y_val),  # conjunto de validación\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668a12b-4847-4e78-bb3a-632edd8888ad",
   "metadata": {},
   "source": [
    "### 3.4.4 - Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb09ee5-53ff-4a01-bddc-e79b783d255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_regression_line(model, X_print, X, Y):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61de60-4cca-479f-b51a-fe29794a75a7",
   "metadata": {},
   "source": [
    "## 3.5 - Regresión no lineal múltiple con redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ace4a1-677e-437c-b316-1025c75765e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e173bd70-b5ea-41c2-acb3-bae7bf14ed26",
   "metadata": {},
   "source": [
    "### 3.5.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad58350-2efb-4080-aa08-8a06eae51009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf947543-1dfb-4c2f-864f-a8e3a2b0917e",
   "metadata": {},
   "source": [
    "### 3.5.2 - Construcción de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851a69d-3e6d-466f-80af-a3ae7c080269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3f53975-477f-486d-9229-b3378e2a81e1",
   "metadata": {},
   "source": [
    "### 3.5.3 - Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc36519-a13b-4913-a31d-db18bc617859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c5eae0-29ed-425f-8965-80d2e6cc37ae",
   "metadata": {},
   "source": [
    "### 3.5.4 - Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c51322-1ef0-4e2b-956d-d0c842f436df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85a8b22-1a83-4398-9f74-5753c18bde84",
   "metadata": {},
   "source": [
    "## 3.6 - Regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f092359-e93f-4929-9d3c-cac9c1a9f00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c96ec4-66a7-4b06-a876-8f6e8f495c44",
   "metadata": {},
   "source": [
    "### 3.6.1 - Regularización L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278b8d1-0317-4c6c-91e6-2ba1c59ff8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b62175-7acb-4bf5-bb19-5aa6f25ddca6",
   "metadata": {},
   "source": [
    "### 3.6.2 - Regularización L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527cf1e8-8016-4d10-aaf3-b50775226689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c037af28-85f6-4cba-9f28-fa7bffeabe71",
   "metadata": {},
   "source": [
    "### 3.6.3 - Regularización *Elastic Net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc61b7-b601-4fed-ba6a-57bc51d3fde2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
