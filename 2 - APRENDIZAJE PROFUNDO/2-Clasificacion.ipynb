{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afaf5b26-0145-461b-912e-d2f86ddfc46d",
   "metadata": {},
   "source": [
    "# 2 - Clasificación\n",
    "\n",
    "**Sumario**\n",
    "\n",
    "1. Introducción\n",
    "2. Funciones de pérdida\n",
    "3. Métricas\n",
    "4. Clasificación binaria\n",
    "5. Clasificación multiclase\n",
    "6. Clasificación multietiqueta\n",
    "7. Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cd507-ca85-4d75-9f22-5849325174f1",
   "metadata": {},
   "source": [
    "## 2.1 - Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261fd17-4a73-4db0-ad46-d4992c1e4666",
   "metadata": {},
   "source": [
    "En tareas de clasificación, nuestro objetivo es construir un modelo capaz de **predecir correctamente una o varias etiquetas para cada uno de las instancias de entrada**. \n",
    "\n",
    "En la siguiente figura se presenta uno de los problemas más comunes de clasificación: se quiere construir un modelo capaz de clasificar un conjunto de *emails* cuya clase está formada por dos etiquetas: \n",
    "1. correo válido\n",
    "2. correo spam\n",
    "\n",
    "El tipo de comportamiento del modelo vendrá definido por la estructura de la clase mediante la que están definidos los diferentes ejemplos. En función del tipo de clase que hayamos definido, podemos diferenciar tres tipos de modelos:\n",
    "* **Clasificación binaria** (una etiqueta, dos clases).\n",
    "* **Clasificación multiclase** (una etiqueta, múltiples clases).\n",
    "* **Clasificación multietiqueta** (múltiples etiquetas, dos clases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ac598-f503-42ea-bdf3-168b029ae134",
   "metadata": {},
   "source": [
    "## 2.2 - Funciones de pérdida (*loss*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb83f8b-84bc-42b9-9673-40320da9a920",
   "metadata": {},
   "source": [
    "A la hora de efectuar un proceso de clasficación, podemos aplicar diferentes funciones de pérdida dependiendo del tipo de salida que queramos obtener. Asi pues:\n",
    "* **Clasificación binaria**\n",
    "    * Binary crossentropy loss\n",
    "* **Clasificación multiclase**\n",
    "    * Multiclass crossentropy loss\n",
    "    * Sparse multiclass crossentropy loss\n",
    "* **Clasificación multietiqueta**\n",
    "    * Binary crossentropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0226872d-19f1-4a0e-aece-4910d6e4d362",
   "metadata": {},
   "source": [
    "### 2.2.1 - Binary crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4867784-0f2f-47fa-88b4-bd882f498546",
   "metadata": {},
   "source": [
    "La **entropía cruzada binaria** (binary crossentropy) es un tipo de función de pérdida utilizada para la construcción de modelos de **clasificación binaria**. Se calcula mediante la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "f(y_{i}, \\hat{y}_{i}) = -\\frac{1}{n} \\sum_{i=1}^{n} y_{i} \\log(\\hat{y}_{i}) + (1 - y_{i}) \\log(1 - \\hat{y}_{i})\n",
    "$$\n",
    "\n",
    "donde\n",
    "* $n$ es el número de instancias de entrenamiento utilizadas para calcular el valor de pérdida.\n",
    "* $y_{i}$ es el valor de salida esperado\n",
    "* $\\hat{y}_{i}$ es el valor de salida real\n",
    "\n",
    "Para poder utilizar este tipo de función de pérdida es necesario recurrir a la **función sigmoidea como función de activación de la última capa de la red**, ya que es la única compatible con esta función de pérdida. Esto se debe a que la función de pérdida debe calcular el logaritmo de $y_{i}$, que solo existe cuando el valor de $\\hat{y}_{i}$ se sitúa entre $0$\n",
    "y $1$.\n",
    "\n",
    "<img src=\"images_2/binary_crossentropy.png\" width=\"700\" data-align=\"center\">\n",
    "\n",
    "**Nota:** La función softmax (con 2 valores) también valdría en este caso ya que al fin y al cabo **la función sigmoidea no es más que una versión binaria de la función softmax**.\n",
    "\n",
    "**Extra:** [**Derivación de la función de pérdida para su aplicación con el descenso por gradiente**](https://www.python-unleashed.com/post/derivation-of-the-binary-cross-entropy-loss-gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0b2be-9126-4951-81bc-1348397b859c",
   "metadata": {},
   "source": [
    "### 2.2.2 - Multiclass crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6a495-9064-4362-a8c1-d9a9f6fc5e65",
   "metadata": {},
   "source": [
    "La **entropía cruzada multiclase o categórica**  (multiclass crossentropy or categorical crossentropy) es un tipo de función de pérdida utilizada para la construcción de modelos de **clasificación multiclase**. Se calcula mediante la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "f(y_{i}, \\hat{y}_{i}) = - \\sum_{i}^{n} y_{i} \\log \\hat{y}_{i}\n",
    "$$\n",
    "\n",
    "donde\n",
    "* $n$ es el número de instancias de entrenamiento utilizadas para calcular el valor de pérdida.\n",
    "* $y_{i}$ es el valor de salida esperado\n",
    "* $\\hat{y}_{i}$ es el valor de salida real\n",
    "\n",
    "Para poder utilizar este tipo de función de pérdida, se recomienda usar la **función softmax como función de activación de la última capa de la red**, pues esta solo **necesita que la salida del modelo sea positiva** (por el logaritmo). Por tanto, la función softmax se adapta perfectamente, ya que efectúa una reescalada de la salida, de manera que todos los valores son expresados entre $0$ y $1$.\n",
    "\n",
    "<img src=\"images_2/multiclass_crossentropy.png\" width=\"700\" data-align=\"center\">\n",
    "\n",
    "**Extra:** [**Derivación de la función de multiclass crossentropy loss para su aplicación con el descenso por gradiente**](https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a85168b-19a3-4513-9ed0-4196098a5ea1",
   "metadata": {},
   "source": [
    "### 2.2.3 - Sparse multiclass crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc10e2-dbb7-4341-8e6e-b28c30b7163e",
   "metadata": {},
   "source": [
    "La **entropía cruzada multiclase dispersa** (sparse multiclass crossentropy) es un tipo de función de pérdida utilizada para la construcción de modelos de **clasificación multiclase cuando el número de clases es muy elevado**. \n",
    "\n",
    "Existen situaciones donde el número posible de clases es muy grande,. or ejemplo, si tenemos que clasificar marcas a partir de una descripción de producto (hay millones de marcas en el mundo). Esta función de pérdida **realiza el mismo cálculo que la función de entropía cruzada multiclase**, pero **sin necesidad de que el vector de entrada sea una codificación de tipo one-hot**. Por tanto, se calcula mediante la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "f(y_{i}, \\hat{y}_{i}) = - \\sum_{i}^{n} y_{i} \\log \\hat{y}_{i}\n",
    "$$\n",
    "\n",
    "\n",
    "<img src=\"images_2/sparse_multiclass_crossentropy.png\" width=\"700\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122688f-51e4-4bb8-abbd-ca5dd5442fe9",
   "metadata": {},
   "source": [
    "## 2.3 - Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c581b-c324-48c5-8e6e-d289653b94d0",
   "metadata": {},
   "source": [
    "Para evaluar los modelos de clasificación, existen diferentes tipos de métricas de \"bondad\".\n",
    "\n",
    "La **matriz de confusión** (confusion matrix) es un procedimiento para extraer la información necesaria y calcular las diferentes métricas de \"bondad\" utilizadas por los algoritmos de clasificación. Consiste en una matriz $n \\times n$, donde $n$ es el número de clases, que describe el rendimiento del modelo a partir de los datos del conjunto de\n",
    "test. Su denominación alude a su finalidad: **identificar dónde está confundiendo las clases el modelo**.\n",
    "\n",
    "En el caso más básico, se aplica a una clasificación binaria una matriz de confusión formada por cuatro características:\n",
    "* **Verdaderos positivos (VP)**. Aquellos ejemplos del conjunto de test cuya clase esperada es 1 (verdadero) y el resultado generado por el modelo de aprendizaje es 1 (verdadero).\n",
    "* **Verdaderos negativos (VN)**. Aquellos ejemplos del conjunto de test cuya clase esperada es 0 (negativo) y el resultado generado por el modelo de aprendizaje es 0 (negativo).\n",
    "* **Falsos positivos (FP)**. Aquellos ejemplos del conjunto de test cuya clase esperada es 0 (falso) y el resultado generado por el modelo de aprendizaje es 1 (verdadero).\n",
    "* **Falsos negativos (FN)**. Aquellos ejemplos del conjunto de test cuya clase esperada es 1 (Verdadero) y el resultado generado por el modelo de aprendizaje es 0 (Falso).\n",
    "\n",
    "A continuación, vamos a definir las diferentes métricas de bondad que se obtienen a través de la matriz de confusión a partir del siguiente ejemplo:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Matriz de confusión binaria</th>\n",
    "        <th>Ejemplo</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images_2/matriz_confusion_1.png\" width=\"500\" data-align=\"center\"></td>\n",
    "        <td><img src=\"images_2/matriz_confusion_3.png\" width=\"500\" data-align=\"center\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**Nota:** Esta representación también se puede aplicar a modelos de clasificación no binaria como, por ejemplo, aquellos que presentan tres clases:\n",
    "\n",
    "<img src=\"images_2/matriz_confusion_2.png\" width=\"500\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2977aa-218f-40cd-84aa-64c62c7ccc46",
   "metadata": {},
   "source": [
    "### 2.3.1 - Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91f0df-f5e2-4f0f-92fb-c4e24fdbcece",
   "metadata": {},
   "source": [
    "La **exactitud** (**accuracy** en inglés) se define como **el grado de concordancia entre el resultado generado por el modelo y el resultado real**. Se obtiene a través de la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "A = \\frac{VN + VP}{VP + VN +FP + FN}\n",
    "$$\n",
    "\n",
    "Con respecto a los datos del ejemplo definido anteriormente, obtendríamos un accuracy de $0.92$:\n",
    "\n",
    "$$\n",
    "A = \\frac{87 + 5}{87 + 5 + 2 + 6} = 0.92\n",
    "$$\n",
    "\n",
    "El accuracy **no es una métrica adecuada para situaciones donde las clases (labels) del conjunto de datos se encuentran desbalanceadas**. En estos casos, resulta mucho más conveniente usar las métricas de precision, recall o F1-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c7f80-b35a-4e0f-b4e5-700c0a58f348",
   "metadata": {},
   "source": [
    "### 2.3.2 - Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52feb24-ae42-4d8a-8b78-b2da7c2bf6f7",
   "metadata": {},
   "source": [
    "La **precisión** (**precision** en ingles) es una medida centrada en el modelo porque nos indica **el grado de precision del modelo cuando predice una determinada clase**. Por ejemplo, en el caso de las imagenes de animales, cuando nuestro modelo que una imagen es un perro, cual es la probabilidad de que sea esto cierto. Se obtiene a través de la siguiente fórmula (ejemplo para 2 clases, centrándonos en la clase \"positivo\"):\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{VP}{VP + FP}\n",
    "$$\n",
    "\n",
    "Con respecto a los datos del ejemplo definido anteriormente, obtendríamos una precision de $0.45$:\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{5}{5 + 6} = 0.45\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94f1e3-4f33-48f7-b919-0e10465166e1",
   "metadata": {},
   "source": [
    "### 2.3.3 - Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba262341-1510-4829-b7fe-4b3480bc41af",
   "metadata": {},
   "source": [
    "La **exhaustividad** (**recall** en inglés) es una medida centrada en los datos porque nos indica **como de bien se predice una clase de los datos**. Por ejemplo, en el caso de las imagenes de animales, cómo de bien identifica nuestro modelo a los perros. Se obtiene a través de la siguiente fórmula ejemplo para 2 clases, centrándonos en la clase \"positivo\"):\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{VP}{VP + FN}\n",
    "$$\n",
    "\n",
    "Con respecto a los datos del ejemplo definido anteriormente, obtendríamos una precision de $0.62$:\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{5}{2 + 6} = 0.62\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fed9bc-4c08-46ce-9041-a87618df8f62",
   "metadata": {},
   "source": [
    "### 2.3.4 - F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e9df6-4cc0-41be-875e-2867989c1002",
   "metadata": {},
   "source": [
    "La **puntuación F1** (**F1-score**) es la **media harmónica de la precisón y de la exhaustividad (recall)**. Así esta métrica es útil ya que nos permite combinar ambas métricas:\n",
    "\n",
    "$$\n",
    "\\text{F1-score} = 2 * \\frac{P * R}{P + R}\n",
    "$$\n",
    "\n",
    "Con respecto a los datos del ejemplo definido anteriormente, obtendríamos una F1-score de $0.52$:\n",
    "\n",
    "$$\n",
    "\\text{F1-score} = 2 * \\frac{0.45 * 0.62}{0.45 + 0.62} = 0.52\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceabea26-266f-4057-b3ea-214a524c4dfe",
   "metadata": {},
   "source": [
    "### 2.3.5 - F$\\beta$ score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af35ac2-2ea1-4503-9d26-a57fe8194063",
   "metadata": {},
   "source": [
    "La puntuación F$\\beta$ (**F$\\beta$ score**) es una métrica que **combina la precisión y la exhaustividad (recall) con un factor de variación** $\\beta$ que permite modificar el grado de importancia que deseamos asigna a cada una de estas métricas. **Cuanto más elevado el valor de $\\beta$, mayor es la importancia que concedemos al *recall***:\n",
    "\n",
    "$$\n",
    "\\text{F1-score} = (1 + \\beta^{2}) * \\frac{P * R}{(\\beta * P) + R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26e327-38c8-4004-bb60-0361084660c4",
   "metadata": {},
   "source": [
    "## 2.4 - Clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03f3af-b920-4133-ac24-d693097c6fc9",
   "metadata": {},
   "source": [
    "A continuación vamos a describir cómo construir una red neuronal para un problema de clasificación binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c540d25-c21a-4da0-8f43-e2bd5800b36e",
   "metadata": {},
   "source": [
    "### 2.4.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971af680-9a51-418f-809c-451037362abc",
   "metadata": {},
   "source": [
    "La primera fase de todo proceso de ML es la preparación de los datos. En este caso, vamos a utilizar el conjunto de datos sobre pruebas diagnósticas para la detección del cáncer de mama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b052da20-bd68-4e40-bd22-4bfdab959719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)\n",
    "data.columns = [\n",
    "    \"Sample_code_number\",\n",
    "    \"Clump_Thickness\",\n",
    "    \"Uniformity_of_Cell_Size\",\n",
    "    \"Uniformity_of_Cell_Shape\",\n",
    "    \"Marginal_Adhesion\",\n",
    "    \"Single_Epithelial_Cell_Size\",\n",
    "    \"Bare_Nuclei\",\n",
    "    \"Bland_Chromatin\",\n",
    "    \"Normal_Nucleoli\",\n",
    "    \"Mitoses\",\n",
    "    \"Class\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f9745-3ecc-4485-812d-def7142dd8d9",
   "metadata": {},
   "source": [
    "Una vez realizada la carga de los datos, debemos llevar a cabo una serie de transformaciones y modificaciones en la información del conjunto de datos con el objetivo de adecuarlos y poder construir nuestra red de neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f788bd-8585-4c9c-b35f-e83f7255c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de la columna que contiene el id de las muestras \n",
    "data.drop(\"Sample_code_number\", axis=\"columns\", inplace=True)\n",
    "\n",
    "# Modificación de los valores ? que existen en la columna Bare Nuclei (en este caso por el valor -1)\n",
    "data[\"Bare_Nuclei\"] = data['Bare_Nuclei'].replace('?', '-1')\n",
    "\n",
    "# Modificación de las etiquetas para que los valores sean 0 y 1 \n",
    "data[\"Class\"] = data[\"Class\"].map(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Generación de los conjuntos de entrenamiento y test split_handler (en este caso no vamos a generar de validación aqui, lo haremos mas adelante)\n",
    "# split proportion: 0.88 train, 0.12 test\n",
    "train_set, test_set = train_test_split(data, test_size=0.12, random_state=0, stratify=data[\"Class\"])\n",
    "\n",
    "# Transformación del conjunto de entrenamiento en tensores \n",
    "X_train = tf.convert_to_tensor (train_set.iloc[:, :9], np.int32) \n",
    "y_train = tf.convert_to_tensor (train_set.iloc[:, 9:], np.int8)\n",
    "\n",
    "# Transformación del conjunto de test en tensores \n",
    "X_test = tf.convert_to_tensor (test_set.iloc[:, :9], np.float32)\n",
    "y_test = tf.convert_to_tensor (test_set.iloc[:, 9:], np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4c235-48ef-4ec1-8ee5-0b07121acc39",
   "metadata": {},
   "source": [
    "**Transformamos los conjuntos de datos en tensores porque ese es el formato esperado por la red para los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fafce0b-5b86-4631-b92d-6e44556925ab",
   "metadata": {},
   "source": [
    "### 2.4.2 - Construcción de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac91d61-370f-4482-b4ae-3b4db0a112a8",
   "metadata": {},
   "source": [
    "Una vez preparados los datos, podemos construir nuestra red de neuronas. Para ello, vamos a crear una red formada por tres capas mediante Keras:\n",
    "\n",
    "* Una capa de entrada que acepte tensores unidimensionales de tamaño 9. Para ello vamos a usar `keras.layers.Flatten`.\n",
    "* Una capa densa con 18 neuronas cuya función de activación sea una ReLU.\n",
    "* Una capa densa con una sola neurona con una función de activación de tipo sigmoidea, de manera que nos devuelva un valor comprendido entre 0 y 1 que se corresponderá con una de las dos clases que podemos obtener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f91ed58-5b43-4b82-91c5-30282a6a5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Creación de las capas que forman la estructura de la red\n",
    "layers = [keras.layers.Flatten(input_shape=(9,)),\n",
    "          keras.layers.Dense(18, activation=tf.nn.relu),\n",
    "          keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "         ]\n",
    "\n",
    "# Compilación de la red de neuronas, agrupando las diferentas capas de forma secuencial\n",
    "model = keras.Sequential(layers, name=\"binary_classification_model\")\n",
    "\n",
    "# Configuración del algoritmo de optimización y de la función de loss\n",
    "model.compile(optimizer=\"sgd\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc20be8-3f08-43de-ba79-155d1b5731f6",
   "metadata": {},
   "source": [
    "Tras la compilación, podemos comprobar la estructura de nuestra red mediante la función `summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2238403e-b77e-4c2c-82c3-62825bd63563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"binary_classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 18)                180       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d090f-7df9-47ee-93d1-aed808531892",
   "metadata": {},
   "source": [
    "Con respecto a los parámetros observamos lo siguiente:\n",
    "* La capa de entrada `flatten_1` no tiene parámetros ya que simplemente nos sirve para introducir información en la red.\n",
    "* La capa densa `dense_2` está formada por 18 neuronas, cada una de ellas con 9 parámetros de entrada y un parámetro de *bias*, haciendo un total de **180**.\n",
    "* La capa densa `dense_3` está formada por 1 neurona con 18 parámetros de entrada y un parámetro de *bias*, haciendo un total de **19**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f2f65f-fc10-4f53-acc0-dc7afc606e1d",
   "metadata": {},
   "source": [
    "### 2.4.3 - Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daefa3c7-2749-4bcd-8977-dabc755b21a7",
   "metadata": {},
   "source": [
    "Una vez compilada nuestra red de neuronas, podemos abordar el proceso de entrenamiento mediante la función `fit`. En este caso, hemos seleccionado las siguientes opciones:\n",
    "* Número de iteraciones (*epochs*): 25\n",
    "* Tamaño del batch de entrenamiento: 100 ejemplos\n",
    "* Tamaño del conjunto de validación: 8% del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "314f9850-c1a7-49b3-9eee-b8a5faa152ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2462 - accuracy: 0.9416 - val_loss: 0.3524 - val_accuracy: 0.9000\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2442 - accuracy: 0.9416 - val_loss: 0.3539 - val_accuracy: 0.9000\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2429 - accuracy: 0.9451 - val_loss: 0.3503 - val_accuracy: 0.9000\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2420 - accuracy: 0.9451 - val_loss: 0.3528 - val_accuracy: 0.9000\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2411 - accuracy: 0.9398 - val_loss: 0.3525 - val_accuracy: 0.9000\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2397 - accuracy: 0.9434 - val_loss: 0.3562 - val_accuracy: 0.9000\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2388 - accuracy: 0.9469 - val_loss: 0.3534 - val_accuracy: 0.9000\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2375 - accuracy: 0.9469 - val_loss: 0.3507 - val_accuracy: 0.9000\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2368 - accuracy: 0.9469 - val_loss: 0.3485 - val_accuracy: 0.9000\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2367 - accuracy: 0.9451 - val_loss: 0.3487 - val_accuracy: 0.9000\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2350 - accuracy: 0.9434 - val_loss: 0.3516 - val_accuracy: 0.9000\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2340 - accuracy: 0.9434 - val_loss: 0.3595 - val_accuracy: 0.9000\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2332 - accuracy: 0.9469 - val_loss: 0.3494 - val_accuracy: 0.9000\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2326 - accuracy: 0.9469 - val_loss: 0.3524 - val_accuracy: 0.9000\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2322 - accuracy: 0.9469 - val_loss: 0.3381 - val_accuracy: 0.9000\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2304 - accuracy: 0.9469 - val_loss: 0.3451 - val_accuracy: 0.9000\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2291 - accuracy: 0.9469 - val_loss: 0.3405 - val_accuracy: 0.9000\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2283 - accuracy: 0.9469 - val_loss: 0.3437 - val_accuracy: 0.9000\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2278 - accuracy: 0.9504 - val_loss: 0.3343 - val_accuracy: 0.9000\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2274 - accuracy: 0.9469 - val_loss: 0.3355 - val_accuracy: 0.9000\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2257 - accuracy: 0.9487 - val_loss: 0.3326 - val_accuracy: 0.9000\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2255 - accuracy: 0.9451 - val_loss: 0.3372 - val_accuracy: 0.9000\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2245 - accuracy: 0.9469 - val_loss: 0.3372 - val_accuracy: 0.9000\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2230 - accuracy: 0.9469 - val_loss: 0.3347 - val_accuracy: 0.9000\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2222 - accuracy: 0.9487 - val_loss: 0.3402 - val_accuracy: 0.9000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.9286\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Definición de los callback de TF Board\n",
    "tensorboard_callback = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "# Ejecución del proceso de aprendizaje\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=25, # Numero de iteraciones\n",
    "    batch_size=100, # Tamaño de los batches\n",
    "    validation_split=0.08, # Tamaño del conjunto de validación\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Evaluación del modelo mediante el conjunto de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e3848-f30e-4145-b310-1e881d333a2f",
   "metadata": {},
   "source": [
    "### 2.4.4 - Inferencia y visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56245714-e905-4781-bc4e-d7f5e2e7c06b",
   "metadata": {},
   "source": [
    "Una vez finalizado el proceso de aprendizaje, podemos recurrir a TensorBoard para comprobar la evolución del proceso de entrenamiento.\n",
    "\n",
    "**Nota:** Dado el rapido aprendizaje del modelo, TensorBoard se confunde un poco al generar los gráficos ya que está acostumbrado a que se siga un proceso con forma \"logarítmica\". [Para ver un ejemplo más \"común\", podemos ejecutar el siguiente notebook en Google Colab.](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb#scrollTo=ixZlmtWhMyr4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f49a99-2ca5-4949-97ac-46cb3fc11a4c",
   "metadata": {},
   "source": [
    "#### Ejecución en local\n",
    "\n",
    "En caso de que estemos ejecutando el notebook en nuestra máquina local, simplemente tendríamos que situarnos con la terminal en el directorio del notebook y correr el siguiente comando:\n",
    "```\n",
    "tensorboard --logdir logs\n",
    "```\n",
    "Se nos indicará entonces cual es la dirección local a la que tenemos que acceder y mostrará la aplicación de TensorBoard con los logs de la ejecución actual:\n",
    "\n",
    "<img src=\"images_2/tensorboard.png\" width=\"800\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf467b3-83fa-4902-9061-2ba36290bae4",
   "metadata": {},
   "source": [
    "#### Ejecución en Google Colab\n",
    "\n",
    "En caso de que estemos ejecutando este notebook en Google Colab, no podriamos acceder al directorio local y en su lugar deberiamos utilizar una extensiónde que nos permitiría generar TensorBoard dentro de Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0611f-4ef5-4490-ba91-03bf8d1d2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo en Google Colab\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfc5a6-879a-478b-a4e8-d70b3f4f9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962cbbc2-3932-4ea3-a05b-1a8f93c42baf",
   "metadata": {},
   "source": [
    "## 2.5 - Clasificación multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3730622d-bc09-494d-827c-c2abf1994b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03df94f1-03d9-4d24-b38d-600655f0e061",
   "metadata": {},
   "source": [
    "### 2.5.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899cff1-4367-46f9-8edf-e11d3f19e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da2a8396-1921-4087-80e9-c1494fa1d6e1",
   "metadata": {},
   "source": [
    "### 2.5.2 - Construcción de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392de868-b0fe-43ec-a641-fad1abafb38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5a0cf9d-4c4c-438f-ba75-de902c9cbe4d",
   "metadata": {},
   "source": [
    "### 2.5.3 - Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9efc6-e929-4b3d-ac4e-81224080c607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3a00f6c-db89-40e3-b32c-5e0e1646b605",
   "metadata": {},
   "source": [
    "### 2.5.4 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee1ec1-d8ca-47f8-8f2c-d6bc25f63d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2304dc8-41ed-4ad4-9eb5-2143a3759dc9",
   "metadata": {},
   "source": [
    "## 2.6 - Clasificación multietiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532cda12-40f6-45f5-a6aa-e7a5d69dbe7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e52b0bab-8dd4-4d08-bdde-168f5c17763a",
   "metadata": {},
   "source": [
    "### 2.6.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ff02e-5b3e-41fd-bd18-38e263bde658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2630357c-7faa-458e-8208-7ed613de776a",
   "metadata": {},
   "source": [
    "### 2.6.2 - Construcción de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9396d5-b14f-4ae5-a53a-d99d8b3effd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3054ef5b-1518-4f68-9433-761f2be7b988",
   "metadata": {},
   "source": [
    "### 2.6.3 - Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac55073-b68f-4d2f-b4fb-9de057538630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab61cb57-ee78-4c19-bcac-e3765c688224",
   "metadata": {},
   "source": [
    "### 2.6.4 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fde672-0d62-4462-8b08-ded925920212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b3c7f08-10c0-4f7e-83cf-4f27680940d2",
   "metadata": {},
   "source": [
    "## 2.7 - Optimización de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4c477-f5dd-468a-9517-78ce6123d47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22d80990-1c23-4b6d-a706-9c7c014d27c5",
   "metadata": {},
   "source": [
    "### 2.7.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003c30b-4e97-4099-9223-02a2ea0b04cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "022910e8-c562-409a-a8f8-1af53a50164a",
   "metadata": {},
   "source": [
    "### 2.7.2 - Definición de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54932d06-7858-4cc9-b9f2-57ae910b4e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73c0b3c7-9362-495e-9041-f62d688c2b49",
   "metadata": {},
   "source": [
    "### 2.7.3 - Definición del proceso de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8904077-a8df-456e-b31c-9f7d972691d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cb04942-3813-427c-a6e8-04532ebe1a98",
   "metadata": {},
   "source": [
    "### 2.7.4 - Ejecución del proceso de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94524473-5db0-4ffe-b917-3f3bbe8d8a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b95d86f-92c4-4b5e-ab69-47e291d79bec",
   "metadata": {},
   "source": [
    "### 2.7.5 - Selección del la configuración final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15afe89-9706-4903-a34e-7c36a1d72b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
