{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afaf5b26-0145-461b-912e-d2f86ddfc46d",
   "metadata": {},
   "source": [
    "# 2 - Clasificación\n",
    "\n",
    "**Sumario**\n",
    "\n",
    "1. Introducción\n",
    "2. Funciones de pérdida\n",
    "3. Métricas\n",
    "4. Clasificación binaria\n",
    "5. Clasificación multiclase\n",
    "6. Clasificación multietiqueta\n",
    "7. Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cd507-ca85-4d75-9f22-5849325174f1",
   "metadata": {},
   "source": [
    "## 2.1 - Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261fd17-4a73-4db0-ad46-d4992c1e4666",
   "metadata": {},
   "source": [
    "En tareas de clasificación, nuestro objetivo es construir un modelo capaz de **predecir correctamente una o varias etiquetas para cada uno de las instancias de entrada**. \n",
    "\n",
    "En la siguiente figura se presenta uno de los problemas más comunes de clasificación: se quiere construir un modelo capaz de clasificar un conjunto de *emails* cuya clase está formada por dos etiquetas: \n",
    "1. correo válido\n",
    "2. correo spam\n",
    "\n",
    "<img src=\"images_2/email_classification.png\" width=\"500\" data-align=\"center\">\n",
    "\n",
    "El tipo de comportamiento del modelo vendrá definido por la estructura de la clase mediante la que están definidos los diferentes ejemplos. En función del tipo de clase que hayamos definido, podemos diferenciar tres tipos de modelos:\n",
    "* **Clasificación binaria** (una etiqueta, dos clases).\n",
    "* **Clasificación multiclase** (una etiqueta, múltiples clases).\n",
    "* **Clasificación multietiqueta** (múltiples etiquetas, dos clases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ac598-f503-42ea-bdf3-168b029ae134",
   "metadata": {},
   "source": [
    "## 2.2 - Funciones de pérdida (*loss*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb83f8b-84bc-42b9-9673-40320da9a920",
   "metadata": {},
   "source": [
    "A la hora de efectuar un proceso de clasficación, podemos aplicar diferentes funciones de pérdida dependiendo del tipo de salida que queramos obtener. Asi pues:\n",
    "* **Clasificación binaria**\n",
    "    * Binary crossentropy loss\n",
    "* **Clasificación multiclase**\n",
    "    * Multiclass crossentropy loss\n",
    "    * Sparse multiclass crossentropy loss\n",
    "* **Clasificación multietiqueta**\n",
    "    * Binary crossentropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0226872d-19f1-4a0e-aece-4910d6e4d362",
   "metadata": {},
   "source": [
    "### 2.2.1 - Binary crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4867784-0f2f-47fa-88b4-bd882f498546",
   "metadata": {},
   "source": [
    "La **entropía cruzada binaria** (binary crossentropy) es un tipo de función de pérdida utilizada para la construcción de modelos de **clasificación binaria**. Se calcula mediante la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "f(y_{i}, \\hat{y}_{i}) = -\\frac{1}{n} \\sum_{i=1}^{n} y_{i} \\log(\\hat{y}_{i}) + (1 - y_{i}) \\log(1 - \\hat{y}_{i})\n",
    "$$\n",
    "\n",
    "donde\n",
    "* $n$ es el número de instancias de entrenamiento utilizadas para calcular el valor de pérdida.\n",
    "* $y_{i}$ es el valor de salida esperado\n",
    "* $\\hat{y}_{i}$ es el valor de salida real\n",
    "\n",
    "Para poder utilizar este tipo de función de pérdida es necesario recurrir a la **función sigmoidea como función de activación de la última capa de la red**, ya que es la única compatible con esta función de pérdida. Esto se debe a que la función de pérdida debe calcular el logaritmo de $y_{i}$, que solo existe cuando el valor de $\\hat{y}_{i}$ se sitúa entre $0$\n",
    "y $1$.\n",
    "\n",
    "<img src=\"images_2/binary_crossentropy.png\" width=\"700\" data-align=\"center\">\n",
    "\n",
    "**Nota:** La función softmax (con 2 valores) también valdría en este caso ya que al fin y al cabo **la función sigmoidea no es más que una versión binaria de la función softmax**.\n",
    "\n",
    "**Extra:** [**Derivación de la función de pérdida para su aplicación con el descenso por gradiente**](https://www.python-unleashed.com/post/derivation-of-the-binary-cross-entropy-loss-gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0b2be-9126-4951-81bc-1348397b859c",
   "metadata": {},
   "source": [
    "### 2.2.2 - Multiclass crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6a495-9064-4362-a8c1-d9a9f6fc5e65",
   "metadata": {},
   "source": [
    "La **entropía cruzada multiclase o categórica**  (multiclass crossentropy or categorical crossentropy) es un tipo de función de pérdida utilizada para la construcción de modelos de **clasificación multiclase**. Se calcula mediante la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "f(y_{i}, \\hat{y}_{i}) = - \\sum_{i}^{n} y_{i} \\log \\hat{y}_{i}\n",
    "$$\n",
    "\n",
    "donde\n",
    "* $n$ es el número de instancias de entrenamiento utilizadas para calcular el valor de pérdida.\n",
    "* $y_{i}$ es el valor de salida esperado\n",
    "* $\\hat{y}_{i}$ es el valor de salida real\n",
    "\n",
    "Para poder utilizar este tipo de función de pérdida, se recomienda usar la **función softmax como función de activación de la última capa de la red**, pues esta solo **necesita que la salida del modelo sea positiva** (por el logaritmo). Por tanto, la función softmax se adapta perfectamente, ya que efectúa una reescalada de la salida, de manera que todos los valores son expresados entre $0$ y $1$.\n",
    "\n",
    "<img src=\"images_2/multiclass_crossentropy.png\" width=\"700\" data-align=\"center\">\n",
    "\n",
    "**Extra:** [**Derivación de la función de multiclass crossentropy loss para su aplicación con el descenso por gradiente**](https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a85168b-19a3-4513-9ed0-4196098a5ea1",
   "metadata": {},
   "source": [
    "### 2.2.3 - Sparse multiclass crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc10e2-dbb7-4341-8e6e-b28c30b7163e",
   "metadata": {},
   "source": [
    "La **entropía cruzada multiclase dispersa** (sparse multiclass crossentropy) es un tipo de función de pérdida utilizada para la construcción de modelos de **clasificación multiclase cuando el número de clases es muy elevado**. \n",
    "\n",
    "Existen situaciones donde el número posible de clases es muy grande,. or ejemplo, si tenemos que clasificar marcas a partir de una descripción de producto (hay millones de marcas en el mundo). Esta función de pérdida **realiza el mismo cálculo que la función de entropía cruzada multiclase**, pero **sin necesidad de que el vector de entrada sea una codificación de tipo one-hot**. Por tanto, se calcula mediante la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "f(y_{i}, \\hat{y}_{i}) = - \\sum_{i}^{n} y_{i} \\log \\hat{y}_{i}\n",
    "$$\n",
    "\n",
    "\n",
    "<img src=\"images_2/sparse_multiclass_crossentropy.png\" width=\"700\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122688f-51e4-4bb8-abbd-ca5dd5442fe9",
   "metadata": {},
   "source": [
    "## 2.3 - Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c581b-c324-48c5-8e6e-d289653b94d0",
   "metadata": {},
   "source": [
    "Para evaluar los modelos de clasificación, existen diferentes tipos de métricas de \"bondad\".\n",
    "\n",
    "La **matriz de confusión** (confusion matrix) es un procedimiento para extraer la información necesaria y calcular las diferentes métricas de \"bondad\" utilizadas por los algoritmos de clasificación. Consiste en una matriz $n \\times n$, donde $n$ es el número de clases, que describe el rendimiento del modelo a partir de los datos del conjunto de\n",
    "test. Su denominación alude a su finalidad: **identificar dónde está confundiendo las clases el modelo**.\n",
    "\n",
    "En el caso más básico, se aplica a una clasificación binaria una matriz de confusión formada por cuatro características:\n",
    "* **Verdaderos positivos (VP)**. Aquellos ejemplos del conjunto de test cuya clase esperada es 1 (verdadero) y el resultado generado por el modelo de aprendizaje es 1 (verdadero).\n",
    "* **Verdaderos negativos (VN)**. Aquellos ejemplos del conjunto de test cuya clase esperada es 0 (negativo) y el resultado generado por el modelo de aprendizaje es 0 (negativo).\n",
    "* **Falsos positivos (FP)**. Aquellos ejemplos del conjunto de test cuya clase esperada es 0 (falso) y el resultado generado por el modelo de aprendizaje es 1 (verdadero).\n",
    "* **Falsos negativos (FN)**. Aquellos ejemplos del conjunto de test cuya clase esperada es 1 (Verdadero) y el resultado generado por el modelo de aprendizaje es 0 (Falso).\n",
    "\n",
    "A continuación, vamos a definir las diferentes métricas de bondad que se obtienen a través de la matriz de confusión a partir del siguiente ejemplo:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Matriz de confusión binaria</th>\n",
    "        <th>Ejemplo</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images_2/matriz_confusion_1.png\" width=\"500\" data-align=\"center\"></td>\n",
    "        <td><img src=\"images_2/matriz_confusion_3.png\" width=\"500\" data-align=\"center\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**Nota:** Esta representación también se puede aplicar a modelos de clasificación no binaria como, por ejemplo, aquellos que presentan tres clases:\n",
    "\n",
    "<img src=\"images_2/matriz_confusion_2.png\" width=\"500\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2977aa-218f-40cd-84aa-64c62c7ccc46",
   "metadata": {},
   "source": [
    "### 2.3.1 - Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91f0df-f5e2-4f0f-92fb-c4e24fdbcece",
   "metadata": {},
   "source": [
    "La **exactitud** (**accuracy** en inglés) se define como **el grado de concordancia entre el resultado generado por el modelo y el resultado real**. Se obtiene a través de la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "A = \\frac{VN + VP}{VP + VN +FP + FN}\n",
    "$$\n",
    "\n",
    "Con respecto a los datos del ejemplo definido anteriormente, obtendríamos un accuracy de $0.92$:\n",
    "\n",
    "$$\n",
    "A = \\frac{87 + 5}{87 + 5 + 2 + 6} = 0.92\n",
    "$$\n",
    "\n",
    "El accuracy **no es una métrica adecuada para situaciones donde las clases (labels) del conjunto de datos se encuentran desbalanceadas**. En estos casos, resulta mucho más conveniente usar las métricas de precision, recall o F1-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c7f80-b35a-4e0f-b4e5-700c0a58f348",
   "metadata": {},
   "source": [
    "### 2.3.2 - Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52feb24-ae42-4d8a-8b78-b2da7c2bf6f7",
   "metadata": {},
   "source": [
    "La **precisión** (**precision** en ingles) es una medida centrada en el modelo porque nos indica **el grado de precision del modelo cuando predice una determinada clase**. Por ejemplo, en el caso de las imagenes de animales, cuando nuestro modelo que una imagen es un perro, cual es la probabilidad de que sea esto cierto. Se obtiene a través de la siguiente fórmula (ejemplo para 2 clases, centrándonos en la clase \"positivo\"):\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{VP}{VP + FP}\n",
    "$$\n",
    "\n",
    "Con respecto a los datos del ejemplo definido anteriormente, obtendríamos una precision de $0.45$:\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{5}{5 + 6} = 0.45\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94f1e3-4f33-48f7-b919-0e10465166e1",
   "metadata": {},
   "source": [
    "### 2.3.3 - Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba262341-1510-4829-b7fe-4b3480bc41af",
   "metadata": {},
   "source": [
    "La **exhaustividad** (**recall** en inglés) es una medida centrada en los datos porque nos indica **como de bien se predice una clase de los datos**. Por ejemplo, en el caso de las imagenes de animales, cómo de bien identifica nuestro modelo a los perros. Se obtiene a través de la siguiente fórmula ejemplo para 2 clases, centrándonos en la clase \"positivo\"):\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{VP}{VP + FN}\n",
    "$$\n",
    "\n",
    "Con respecto a los datos del ejemplo definido anteriormente, obtendríamos una precision de $0.62$:\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{5}{2 + 6} = 0.62\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fed9bc-4c08-46ce-9041-a87618df8f62",
   "metadata": {},
   "source": [
    "### 2.3.4 - F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e9df6-4cc0-41be-875e-2867989c1002",
   "metadata": {},
   "source": [
    "La **puntuación F1** (**F1-score**) es la **media harmónica de la precisón y de la exhaustividad (recall)**. Así esta métrica es útil ya que nos permite combinar ambas métricas:\n",
    "\n",
    "$$\n",
    "\\text{F1-score} = 2 * \\frac{P * R}{P + R}\n",
    "$$\n",
    "\n",
    "Con respecto a los datos del ejemplo definido anteriormente, obtendríamos una F1-score de $0.52$:\n",
    "\n",
    "$$\n",
    "\\text{F1-score} = 2 * \\frac{0.45 * 0.62}{0.45 + 0.62} = 0.52\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceabea26-266f-4057-b3ea-214a524c4dfe",
   "metadata": {},
   "source": [
    "### 2.3.5 - F$\\beta$ score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af35ac2-2ea1-4503-9d26-a57fe8194063",
   "metadata": {},
   "source": [
    "La puntuación F$\\beta$ (**F$\\beta$ score**) es una métrica que **combina la precisión y la exhaustividad (recall) con un factor de variación** $\\beta$ que permite modificar el grado de importancia que deseamos asigna a cada una de estas métricas. **Cuanto más elevado el valor de $\\beta$, mayor es la importancia que concedemos al *recall***:\n",
    "\n",
    "$$\n",
    "\\text{F1-score} = (1 + \\beta^{2}) * \\frac{P * R}{(\\beta * P) + R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26e327-38c8-4004-bb60-0361084660c4",
   "metadata": {},
   "source": [
    "## 2.4 - Clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03f3af-b920-4133-ac24-d693097c6fc9",
   "metadata": {},
   "source": [
    "A continuación vamos a describir cómo construir una red neuronal para un problema de clasificación binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c540d25-c21a-4da0-8f43-e2bd5800b36e",
   "metadata": {},
   "source": [
    "### 2.4.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971af680-9a51-418f-809c-451037362abc",
   "metadata": {},
   "source": [
    "La primera fase de todo proceso de ML es la preparación de los datos. En este caso, vamos a utilizar **el conjunto de datos sobre pruebas diagnósticas para la detección del cáncer de mama**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b052da20-bd68-4e40-bd22-4bfdab959719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)\n",
    "data.columns = [\n",
    "    \"Sample_code_number\",\n",
    "    \"Clump_Thickness\",\n",
    "    \"Uniformity_of_Cell_Size\",\n",
    "    \"Uniformity_of_Cell_Shape\",\n",
    "    \"Marginal_Adhesion\",\n",
    "    \"Single_Epithelial_Cell_Size\",\n",
    "    \"Bare_Nuclei\",\n",
    "    \"Bland_Chromatin\",\n",
    "    \"Normal_Nucleoli\",\n",
    "    \"Mitoses\",\n",
    "    \"Class\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f9745-3ecc-4485-812d-def7142dd8d9",
   "metadata": {},
   "source": [
    "Una vez realizada la carga de los datos, debemos llevar a cabo una serie de transformaciones y modificaciones en la información del conjunto de datos con el objetivo de adecuarlos y poder construir nuestra red de neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f788bd-8585-4c9c-b35f-e83f7255c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de la columna que contiene el id de las muestras \n",
    "data.drop(\"Sample_code_number\", axis=\"columns\", inplace=True)\n",
    "\n",
    "# Modificación de los valores ? que existen en la columna Bare Nuclei (en este caso por el valor -1)\n",
    "data[\"Bare_Nuclei\"] = data['Bare_Nuclei'].replace('?', '-1')\n",
    "\n",
    "# Modificación de las etiquetas para que los valores sean 0 y 1 \n",
    "data[\"Class\"] = data[\"Class\"].map(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Generación de los conjuntos de entrenamiento y test split_handler (en este caso no vamos a generar de validación aqui, lo haremos mas adelante)\n",
    "# split proportion: 0.88 train, 0.12 test\n",
    "train_set, test_set = train_test_split(data, test_size=0.12, random_state=0, stratify=data[\"Class\"])\n",
    "\n",
    "# Transformación del conjunto de entrenamiento en tensores \n",
    "X_train = tf.convert_to_tensor (train_set.iloc[:, :9], np.int32) \n",
    "y_train = tf.convert_to_tensor (train_set.iloc[:, 9:], np.int8)\n",
    "\n",
    "# Transformación del conjunto de test en tensores \n",
    "X_test = tf.convert_to_tensor (test_set.iloc[:, :9], np.float32)\n",
    "y_test = tf.convert_to_tensor (test_set.iloc[:, 9:], np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4c235-48ef-4ec1-8ee5-0b07121acc39",
   "metadata": {},
   "source": [
    "**Transformamos los conjuntos de datos en tensores porque ese es el formato esperado por la red para los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fafce0b-5b86-4631-b92d-6e44556925ab",
   "metadata": {},
   "source": [
    "### 2.4.2 - Construcción de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac91d61-370f-4482-b4ae-3b4db0a112a8",
   "metadata": {},
   "source": [
    "Una vez preparados los datos, podemos construir nuestra red de neuronas. Para ello, vamos a crear una red formada por tres capas mediante Keras:\n",
    "\n",
    "* Una capa de entrada que acepte tensores unidimensionales de tamaño 9. Para ello vamos a usar `keras.layers.Flatten`.\n",
    "* Una capa densa con 18 neuronas cuya función de activación sea una ReLU.\n",
    "* Una capa densa con una sola neurona con una función de activación de tipo sigmoidea, de manera que nos devuelva un valor comprendido entre 0 y 1 que se corresponderá con una de las dos clases que podemos obtener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f91ed58-5b43-4b82-91c5-30282a6a5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Creación de las capas que forman la estructura de la red\n",
    "layers = [keras.layers.Flatten(input_shape=(9,)),\n",
    "          keras.layers.Dense(18, activation=tf.nn.relu),\n",
    "          keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "         ]\n",
    "\n",
    "# Compilación de la red de neuronas, agrupando las diferentas capas de forma secuencial\n",
    "model = keras.Sequential(layers, name=\"binary_classification_model\")\n",
    "\n",
    "# Configuración del algoritmo de optimización y de la función de loss\n",
    "model.compile(optimizer=\"sgd\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc20be8-3f08-43de-ba79-155d1b5731f6",
   "metadata": {},
   "source": [
    "Tras la compilación, podemos comprobar la estructura de nuestra red mediante la función `summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2238403e-b77e-4c2c-82c3-62825bd63563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"binary_classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 9)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                180       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d090f-7df9-47ee-93d1-aed808531892",
   "metadata": {},
   "source": [
    "Con respecto a los parámetros observamos lo siguiente:\n",
    "* La capa de entrada `flatten_1` no tiene parámetros ya que simplemente nos sirve para introducir información en la red.\n",
    "* La capa densa `dense_2` está formada por 18 neuronas, cada una de ellas con 9 parámetros de entrada y un parámetro de *bias*, haciendo un total de **180**.\n",
    "* La capa densa `dense_3` está formada por 1 neurona con 18 parámetros de entrada y un parámetro de *bias*, haciendo un total de **19**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f2f65f-fc10-4f53-acc0-dc7afc606e1d",
   "metadata": {},
   "source": [
    "### 2.4.3 - Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daefa3c7-2749-4bcd-8977-dabc755b21a7",
   "metadata": {},
   "source": [
    "Una vez compilada nuestra red de neuronas, podemos abordar el proceso de entrenamiento mediante la función `fit`. En este caso, hemos seleccionado las siguientes opciones:\n",
    "* Número de iteraciones (*epochs*): 25\n",
    "* Tamaño del batch de entrenamiento: 100 ejemplos\n",
    "* Tamaño del conjunto de validación: 8% del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314f9850-c1a7-49b3-9eee-b8a5faa152ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 1s 68ms/step - loss: 0.7494 - accuracy: 0.6159 - val_loss: 0.6707 - val_accuracy: 0.6800\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6442 - accuracy: 0.6159 - val_loss: 0.6823 - val_accuracy: 0.6400\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6191 - accuracy: 0.6779 - val_loss: 0.6642 - val_accuracy: 0.6800\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5875 - accuracy: 0.7274 - val_loss: 0.6292 - val_accuracy: 0.8200\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5621 - accuracy: 0.8248 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5430 - accuracy: 0.8442 - val_loss: 0.6245 - val_accuracy: 0.8200\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5242 - accuracy: 0.8407 - val_loss: 0.5810 - val_accuracy: 0.8600\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5059 - accuracy: 0.8761 - val_loss: 0.5735 - val_accuracy: 0.8600\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4901 - accuracy: 0.8832 - val_loss: 0.5730 - val_accuracy: 0.8600\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4774 - accuracy: 0.8814 - val_loss: 0.5567 - val_accuracy: 0.8600\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4644 - accuracy: 0.8920 - val_loss: 0.5568 - val_accuracy: 0.8600\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4542 - accuracy: 0.8832 - val_loss: 0.5356 - val_accuracy: 0.8600\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4438 - accuracy: 0.8920 - val_loss: 0.5340 - val_accuracy: 0.8600\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4330 - accuracy: 0.9009 - val_loss: 0.5365 - val_accuracy: 0.8600\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4223 - accuracy: 0.8920 - val_loss: 0.5145 - val_accuracy: 0.8600\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4126 - accuracy: 0.9044 - val_loss: 0.5435 - val_accuracy: 0.8600\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4050 - accuracy: 0.8956 - val_loss: 0.5104 - val_accuracy: 0.8600\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4017 - accuracy: 0.9009 - val_loss: 0.5217 - val_accuracy: 0.8400\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3925 - accuracy: 0.9027 - val_loss: 0.5202 - val_accuracy: 0.8600\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3853 - accuracy: 0.9097 - val_loss: 0.5077 - val_accuracy: 0.8400\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3803 - accuracy: 0.9062 - val_loss: 0.4945 - val_accuracy: 0.8600\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3752 - accuracy: 0.9080 - val_loss: 0.5016 - val_accuracy: 0.8600\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3662 - accuracy: 0.9115 - val_loss: 0.4952 - val_accuracy: 0.8600\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3609 - accuracy: 0.9062 - val_loss: 0.4826 - val_accuracy: 0.8600\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3574 - accuracy: 0.9097 - val_loss: 0.4955 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182df77b190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Definición de los callback de TF Board\n",
    "tensorboard_callback = TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "# Ejecución del proceso de aprendizaje\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=25, # Numero de iteraciones\n",
    "    batch_size=100, # Tamaño de los batches\n",
    "    validation_split=0.08, # Tamaño del conjunto de validación\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf28da2e-2ba2-422a-983c-8bd20740ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo mediante el conjunto de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e3848-f30e-4145-b310-1e881d333a2f",
   "metadata": {},
   "source": [
    "### 2.4.4 - Inferencia y visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56245714-e905-4781-bc4e-d7f5e2e7c06b",
   "metadata": {},
   "source": [
    "Una vez finalizado el proceso de aprendizaje, podemos recurrir a TensorBoard para comprobar la evolución del proceso de entrenamiento.\n",
    "\n",
    "**Nota:** Dado el rapido aprendizaje del modelo, TensorBoard se confunde un poco al generar los gráficos ya que está acostumbrado a que se siga un proceso con forma \"logarítmica\". [Para ver un ejemplo más \"común\", podemos ejecutar el siguiente notebook en Google Colab.](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb#scrollTo=ixZlmtWhMyr4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f49a99-2ca5-4949-97ac-46cb3fc11a4c",
   "metadata": {},
   "source": [
    "#### Ejecución en local\n",
    "\n",
    "En caso de que estemos ejecutando el notebook en nuestra máquina local, simplemente tendríamos que situarnos con la terminal en el directorio del notebook y correr el siguiente comando:\n",
    "```\n",
    "tensorboard --logdir logs\n",
    "```\n",
    "Se nos indicará entonces cual es la dirección local a la que tenemos que acceder y mostrará la aplicación de TensorBoard con los logs de la ejecución actual:\n",
    "\n",
    "<img src=\"images_2/tensorboard.png\" width=\"800\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf467b3-83fa-4902-9061-2ba36290bae4",
   "metadata": {},
   "source": [
    "#### Ejecución en Google Colab\n",
    "\n",
    "En caso de que estemos ejecutando este notebook en Google Colab, no podriamos acceder al directorio local y en su lugar deberiamos utilizar una extensiónde que nos permitiría generar TensorBoard dentro de Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac0611f-4ef5-4490-ba91-03bf8d1d2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo en Google Colab\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65cfc5a6-879a-478b-a4e8-d70b3f4f9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962cbbc2-3932-4ea3-a05b-1a8f93c42baf",
   "metadata": {},
   "source": [
    "## 2.5 - Clasificación multiclase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8f036-e41d-4382-b5d4-e5eef3cd695a",
   "metadata": {},
   "source": [
    "A continuación vamos a describir cómo construir una red neuronal para un problema de clasificación multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df94f1-03d9-4d24-b38d-600655f0e061",
   "metadata": {},
   "source": [
    "### 2.5.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7631c-b891-4472-a10e-2f11b43c87f8",
   "metadata": {},
   "source": [
    "Como ya sabemos, la primera fase de todo proceso de ML es la preparación de los datos. En este caso, **vamos a utilizar el famoso dataset Iris**, que consiste en clasificar flores en tres variedades según carateristicas del pétalo y el sépalo de la flor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "348c3e39-62ef-4681-845c-6823adcdbcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header=None)\n",
    "data.columns = [\n",
    "    \"sepal_length\",\n",
    "    \"sepal_width\",\n",
    "    \"petal_length\",\n",
    "    \"petal_width\",\n",
    "    \"class\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce336b-8189-4093-9041-f80602933b38",
   "metadata": {},
   "source": [
    "Una vez realizada la carga de los datos, debemos llevar a cabo una serie de transformaciones y modificaciones en la información del conjunto de datos con el objetivo de adecuarlos y poder construir nuestra red de neuronas:\n",
    "* Codificación de las clases en formato de numero entero (índice).\n",
    "* Codificación de la clases en formato *one-hot*.\n",
    "* Codificación numérica de todos los atributos en formato decimal (*float*).\n",
    "* Generación de los splits de entrenamiento y test.\n",
    "* Transformación de los splits a formato *tensor* para poder ser ingeridos por la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a3cef9e-74e7-4fcd-913b-8bfc7718a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Definimos un codificador para transformar las clases en números enteros\n",
    "class_encoder = LabelEncoder()\n",
    "class_encoder.fit (data[\"class\"])\n",
    "integer_class_representation = class_encoder.transform (data[\"class\"])\n",
    "\n",
    "# Definimos un codificador para transformar las clases de formato entero a formato one-hot\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "# Generación de los conjuntos de entrenamiento y test split_handler (en este caso no vamos a generar de validación aqui, lo haremos mas adelante)\n",
    "# split proportion: 0.88 train, 0.12 test\n",
    "train_set, test_set = train_test_split(data, test_size=0.12, random_state=0, stratify=data[\"class\"])\n",
    "\n",
    "# Transformación del conjunto de entrenamiento en tensores \n",
    "X_train = tf.convert_to_tensor(train_set.iloc[:, :4], np.int32)\n",
    "y_train = tf.convert_to_tensor(one_hot_encoder.fit_transform(train_set.iloc[:, 4:]).toarray())\n",
    "\n",
    "# Transformación del conjunto de test en tensores \n",
    "X_test = tf.convert_to_tensor(test_set.iloc[:, :4], np.int32)\n",
    "y_test = tf.convert_to_tensor(one_hot_encoder.fit_transform(test_set.iloc[:, 4:]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610c3b0-ef5e-4bca-b278-e39928b5aec6",
   "metadata": {},
   "source": [
    "En vez de utilizar el one-hot encoder, podemos utilizar la forma entera de las clases con la función de pérdida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6258d42d-0360-4823-b61b-c2aa6fb5b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rofe2001\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Transformación del conjunto de entrenamiento en tensores donde la clase está en formato entero, en vez de en formato one-hot\n",
    "y_train_integer = tf.convert_to_tensor(class_encoder.fit_transform(train_set.iloc[:, 4:])) \n",
    "\n",
    "# Transformación del conjunto de test en tensores donde la clase está en formato entero, en vez de en formato one-hot\n",
    "y_test_integer = tf.convert_to_tensor(class_encoder.fit_transform(test_set.iloc[:, 4:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a8396-1921-4087-80e9-c1494fa1d6e1",
   "metadata": {},
   "source": [
    "### 2.5.2 - Construcción de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccadab18-8486-4141-b1a1-1f515cae4df0",
   "metadata": {},
   "source": [
    "Una vez preparados los datos, podemos construir nuestra red. En este sentido, vamos a crear una red formada por tres capas mediante Keras:\n",
    "* Una capa de de tipo `flatten` que acepte como entrada tensores unidimensionales de dimensión 4.\n",
    "* Una capa densa de 8 neuronas con una función de activación de tipo ReLU.\n",
    "* Una capa densa de 3 neuronas con una función de activación de tipo `softmax` que nos devolverá la probabilidad de que el ejemplo pertenezca a cada una de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d919f2f-0c47-4440-96a7-6e518b539431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multiclass_classification_model_onehot\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Creación de las capas que forman la estructura de la red\n",
    "layers_onehot = [keras.layers.Flatten(input_shape=(4,)),\n",
    "                 keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "                 keras.layers.Dense(3, activation=tf.nn.softmax),\n",
    "                ]\n",
    "\n",
    "# Compilación de la red de neuronas, agrupando las diferentas capas de forma secuencial\n",
    "model_onehot = keras.Sequential(layers_onehot, name=\"multiclass_classification_model_onehot\")\n",
    "\n",
    "# Configuración del algoritmo de optimización y de la función de loss\n",
    "# Nota, en este caso vamos a usar Adam en vez de SGD simplemente para demostrar \n",
    "# como se le llama en Keras\n",
    "model_onehot.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "model_onehot.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cef1ba1-bc5c-4c09-af9a-7b5c564a5780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multiclass_classification_model_integer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers_integer = [keras.layers.Flatten(input_shape=(4,)),\n",
    "                  keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "                  keras.layers.Dense(3, activation=tf.nn.softmax),\n",
    "                 ]\n",
    "\n",
    "# Compilación de la red de neuronas, agrupando las diferentas capas de forma secuencial\n",
    "model_integer = keras.Sequential(layers_integer, name=\"multiclass_classification_model_integer\")\n",
    "\n",
    "# Configuración del algoritmo de optimización y de la función de loss\n",
    "# Nota, en este caso vamos a usar Adam en vez de SGD simplemente para demostrar \n",
    "# como se le llama en Keras\n",
    "model_integer.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "model_integer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d7d0c-6a3e-447a-9078-f61e1fbcdb9d",
   "metadata": {},
   "source": [
    "Con respecto a los parámetros observamos lo siguiente:\n",
    "* La capa de entrada `flatten_3` no tiene parámetros ya que simplemente nos sirve para introducir información en la red.\n",
    "* La capa densa `dense_6` está formada por 8 neuronas, cada una de ellas con 4 parámetros de entrada y un parámetro de *bias*, haciendo un total de **40**.\n",
    "* La capa densa `dense_7` está formada por 3 neuronas con 8 parámetros de entrada y un parámetro de *bias*, haciendo un total de **27**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0cf9d-4c4c-438f-ba75-de902c9cbe4d",
   "metadata": {},
   "source": [
    "### 2.5.3 - Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae5d68-7623-4c18-9fbb-1f1c195e8357",
   "metadata": {},
   "source": [
    "Una vez compilada nuestra red de neuronas, podemos abordar el proceso de entrenamiento mediante la función `fit`. En este caso, hemos seleccionado las siguientes opciones:\n",
    "* Número de iteraciones (*epochs*): 125\n",
    "* Tamaño del batch de entrenamiento: 10 ejemplos\n",
    "* Tamaño del conjunto de validación: 8% del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac7f6e0e-360d-46c6-b1ab-4731adb29ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "13/13 [==============================] - 1s 25ms/step - loss: 2.1820 - accuracy: 0.0000e+00 - val_loss: 2.3769 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9292 - accuracy: 0.0909 - val_loss: 2.0821 - val_accuracy: 0.1818\n",
      "Epoch 3/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7154 - accuracy: 0.2314 - val_loss: 1.8592 - val_accuracy: 0.1818\n",
      "Epoch 4/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5647 - accuracy: 0.3140 - val_loss: 1.6739 - val_accuracy: 0.1818\n",
      "Epoch 5/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4458 - accuracy: 0.3471 - val_loss: 1.5292 - val_accuracy: 0.1818\n",
      "Epoch 6/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3494 - accuracy: 0.3471 - val_loss: 1.4250 - val_accuracy: 0.1818\n",
      "Epoch 7/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2774 - accuracy: 0.3388 - val_loss: 1.3335 - val_accuracy: 0.3636\n",
      "Epoch 8/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2265 - accuracy: 0.4050 - val_loss: 1.2714 - val_accuracy: 0.3636\n",
      "Epoch 9/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1836 - accuracy: 0.4545 - val_loss: 1.2105 - val_accuracy: 0.3636\n",
      "Epoch 10/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1486 - accuracy: 0.4215 - val_loss: 1.1549 - val_accuracy: 0.2727\n",
      "Epoch 11/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1168 - accuracy: 0.3719 - val_loss: 1.1214 - val_accuracy: 0.3636\n",
      "Epoch 12/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0898 - accuracy: 0.3719 - val_loss: 1.0819 - val_accuracy: 0.3636\n",
      "Epoch 13/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0609 - accuracy: 0.3802 - val_loss: 1.0499 - val_accuracy: 0.3636\n",
      "Epoch 14/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0325 - accuracy: 0.4545 - val_loss: 1.0295 - val_accuracy: 0.4545\n",
      "Epoch 15/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0070 - accuracy: 0.4876 - val_loss: 1.0073 - val_accuracy: 0.3636\n",
      "Epoch 16/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9864 - accuracy: 0.4876 - val_loss: 0.9880 - val_accuracy: 0.3636\n",
      "Epoch 17/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9638 - accuracy: 0.4959 - val_loss: 0.9579 - val_accuracy: 0.3636\n",
      "Epoch 18/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9436 - accuracy: 0.6116 - val_loss: 0.9257 - val_accuracy: 0.6364\n",
      "Epoch 19/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9230 - accuracy: 0.6446 - val_loss: 0.8973 - val_accuracy: 0.6364\n",
      "Epoch 20/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9021 - accuracy: 0.6446 - val_loss: 0.8788 - val_accuracy: 0.6364\n",
      "Epoch 21/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8849 - accuracy: 0.6446 - val_loss: 0.8629 - val_accuracy: 0.6364\n",
      "Epoch 22/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8723 - accuracy: 0.6446 - val_loss: 0.8546 - val_accuracy: 0.6364\n",
      "Epoch 23/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8532 - accuracy: 0.7686 - val_loss: 0.8249 - val_accuracy: 0.8182\n",
      "Epoch 24/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8366 - accuracy: 0.7851 - val_loss: 0.7915 - val_accuracy: 0.7273\n",
      "Epoch 25/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8202 - accuracy: 0.7686 - val_loss: 0.7804 - val_accuracy: 0.8182\n",
      "Epoch 26/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8068 - accuracy: 0.8099 - val_loss: 0.7733 - val_accuracy: 0.8182\n",
      "Epoch 27/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7925 - accuracy: 0.8099 - val_loss: 0.7520 - val_accuracy: 0.8182\n",
      "Epoch 28/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7792 - accuracy: 0.8099 - val_loss: 0.7357 - val_accuracy: 0.8182\n",
      "Epoch 29/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7646 - accuracy: 0.8264 - val_loss: 0.7235 - val_accuracy: 0.8182\n",
      "Epoch 30/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7497 - accuracy: 0.8264 - val_loss: 0.7009 - val_accuracy: 0.8182\n",
      "Epoch 31/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7367 - accuracy: 0.8430 - val_loss: 0.6913 - val_accuracy: 0.8182\n",
      "Epoch 32/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7253 - accuracy: 0.8264 - val_loss: 0.6806 - val_accuracy: 0.8182\n",
      "Epoch 33/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7128 - accuracy: 0.8264 - val_loss: 0.6656 - val_accuracy: 0.8182\n",
      "Epoch 34/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7031 - accuracy: 0.8264 - val_loss: 0.6544 - val_accuracy: 0.8182\n",
      "Epoch 35/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6915 - accuracy: 0.8017 - val_loss: 0.6225 - val_accuracy: 0.9091\n",
      "Epoch 36/125\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6792 - accuracy: 0.7934 - val_loss: 0.6169 - val_accuracy: 0.9091\n",
      "Epoch 37/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6684 - accuracy: 0.8099 - val_loss: 0.6057 - val_accuracy: 0.9091\n",
      "Epoch 38/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6570 - accuracy: 0.8017 - val_loss: 0.5892 - val_accuracy: 0.9091\n",
      "Epoch 39/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6484 - accuracy: 0.8017 - val_loss: 0.5720 - val_accuracy: 0.9091\n",
      "Epoch 40/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6374 - accuracy: 0.8017 - val_loss: 0.5681 - val_accuracy: 0.9091\n",
      "Epoch 41/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6301 - accuracy: 0.8264 - val_loss: 0.5654 - val_accuracy: 0.9091\n",
      "Epoch 42/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.8430 - val_loss: 0.5491 - val_accuracy: 0.9091\n",
      "Epoch 43/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.8430 - val_loss: 0.5474 - val_accuracy: 0.9091\n",
      "Epoch 44/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.8430 - val_loss: 0.5458 - val_accuracy: 0.8182\n",
      "Epoch 45/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.8430 - val_loss: 0.5340 - val_accuracy: 0.9091\n",
      "Epoch 46/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5836 - accuracy: 0.8017 - val_loss: 0.5077 - val_accuracy: 0.9091\n",
      "Epoch 47/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5771 - accuracy: 0.8017 - val_loss: 0.5042 - val_accuracy: 0.9091\n",
      "Epoch 48/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.8017 - val_loss: 0.4930 - val_accuracy: 0.9091\n",
      "Epoch 49/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5642 - accuracy: 0.8017 - val_loss: 0.4831 - val_accuracy: 0.9091\n",
      "Epoch 50/125\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5574 - accuracy: 0.8017 - val_loss: 0.4763 - val_accuracy: 0.9091\n",
      "Epoch 51/125\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5484 - accuracy: 0.7934 - val_loss: 0.4810 - val_accuracy: 0.9091\n",
      "Epoch 52/125\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5421 - accuracy: 0.8430 - val_loss: 0.4741 - val_accuracy: 0.9091\n",
      "Epoch 53/125\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5375 - accuracy: 0.8430 - val_loss: 0.4713 - val_accuracy: 0.9091\n",
      "Epoch 54/125\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.5295 - accuracy: 0.8430 - val_loss: 0.4586 - val_accuracy: 0.9091\n",
      "Epoch 55/125\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5237 - accuracy: 0.8430 - val_loss: 0.4583 - val_accuracy: 0.9091\n",
      "Epoch 56/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5201 - accuracy: 0.8430 - val_loss: 0.4603 - val_accuracy: 0.9091\n",
      "Epoch 57/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.8430 - val_loss: 0.4459 - val_accuracy: 0.9091\n",
      "Epoch 58/125\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5057 - accuracy: 0.8430 - val_loss: 0.4352 - val_accuracy: 0.9091\n",
      "Epoch 59/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.8017 - val_loss: 0.4153 - val_accuracy: 0.9091\n",
      "Epoch 60/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4993 - accuracy: 0.8017 - val_loss: 0.4088 - val_accuracy: 0.9091\n",
      "Epoch 61/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.8017 - val_loss: 0.4073 - val_accuracy: 0.9091\n",
      "Epoch 62/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.8099 - val_loss: 0.4101 - val_accuracy: 0.9091\n",
      "Epoch 63/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4843 - accuracy: 0.8430 - val_loss: 0.4191 - val_accuracy: 0.9091\n",
      "Epoch 64/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.8430 - val_loss: 0.4111 - val_accuracy: 0.9091\n",
      "Epoch 65/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.8430 - val_loss: 0.4115 - val_accuracy: 0.9091\n",
      "Epoch 66/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.8678 - val_loss: 0.4131 - val_accuracy: 0.9091\n",
      "Epoch 67/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.8595 - val_loss: 0.4068 - val_accuracy: 0.9091\n",
      "Epoch 68/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.8843 - val_loss: 0.4040 - val_accuracy: 0.9091\n",
      "Epoch 69/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.8430 - val_loss: 0.3932 - val_accuracy: 0.9091\n",
      "Epoch 70/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.8430 - val_loss: 0.3761 - val_accuracy: 0.9091\n",
      "Epoch 71/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.8017 - val_loss: 0.3677 - val_accuracy: 0.9091\n",
      "Epoch 72/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.3668 - val_accuracy: 0.9091\n",
      "Epoch 73/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.8430 - val_loss: 0.3671 - val_accuracy: 0.9091\n",
      "Epoch 74/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8430 - val_loss: 0.3728 - val_accuracy: 0.9091\n",
      "Epoch 75/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.8430 - val_loss: 0.3641 - val_accuracy: 0.9091\n",
      "Epoch 76/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.8430 - val_loss: 0.3519 - val_accuracy: 0.9091\n",
      "Epoch 77/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.3502 - val_accuracy: 0.9091\n",
      "Epoch 78/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8430 - val_loss: 0.3519 - val_accuracy: 0.9091\n",
      "Epoch 79/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8430 - val_loss: 0.3526 - val_accuracy: 0.9091\n",
      "Epoch 80/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8678 - val_loss: 0.3477 - val_accuracy: 0.9091\n",
      "Epoch 81/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8430 - val_loss: 0.3380 - val_accuracy: 0.9091\n",
      "Epoch 82/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8430 - val_loss: 0.3350 - val_accuracy: 0.9091\n",
      "Epoch 83/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8430 - val_loss: 0.3318 - val_accuracy: 0.9091\n",
      "Epoch 84/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8512 - val_loss: 0.3354 - val_accuracy: 0.9091\n",
      "Epoch 85/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8843 - val_loss: 0.3389 - val_accuracy: 0.9091\n",
      "Epoch 86/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8678 - val_loss: 0.3261 - val_accuracy: 0.9091\n",
      "Epoch 87/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8430 - val_loss: 0.3232 - val_accuracy: 0.9091\n",
      "Epoch 88/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8843 - val_loss: 0.3301 - val_accuracy: 0.9091\n",
      "Epoch 89/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8926 - val_loss: 0.3273 - val_accuracy: 0.9091\n",
      "Epoch 90/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8843 - val_loss: 0.3183 - val_accuracy: 0.9091\n",
      "Epoch 91/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8843 - val_loss: 0.3127 - val_accuracy: 0.9091\n",
      "Epoch 92/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8843 - val_loss: 0.3012 - val_accuracy: 0.9091\n",
      "Epoch 93/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8843 - val_loss: 0.3001 - val_accuracy: 0.9091\n",
      "Epoch 94/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8926 - val_loss: 0.3041 - val_accuracy: 0.9091\n",
      "Epoch 95/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8843 - val_loss: 0.2882 - val_accuracy: 0.9091\n",
      "Epoch 96/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8182 - val_loss: 0.2759 - val_accuracy: 1.0000\n",
      "Epoch 97/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8512 - val_loss: 0.2687 - val_accuracy: 1.0000\n",
      "Epoch 98/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.8430 - val_loss: 0.2747 - val_accuracy: 0.9091\n",
      "Epoch 99/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8926 - val_loss: 0.2765 - val_accuracy: 0.9091\n",
      "Epoch 100/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8926 - val_loss: 0.2725 - val_accuracy: 0.9091\n",
      "Epoch 101/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3520 - accuracy: 0.8926 - val_loss: 0.2703 - val_accuracy: 0.9091\n",
      "Epoch 102/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8926 - val_loss: 0.2668 - val_accuracy: 0.9091\n",
      "Epoch 103/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3464 - accuracy: 0.8926 - val_loss: 0.2633 - val_accuracy: 0.9091\n",
      "Epoch 104/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3412 - accuracy: 0.9091 - val_loss: 0.2462 - val_accuracy: 1.0000\n",
      "Epoch 105/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3439 - accuracy: 0.8760 - val_loss: 0.2360 - val_accuracy: 1.0000\n",
      "Epoch 106/125\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3393 - accuracy: 0.8760 - val_loss: 0.2408 - val_accuracy: 1.0000\n",
      "Epoch 107/125\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3399 - accuracy: 0.8760 - val_loss: 0.2551 - val_accuracy: 0.9091\n",
      "Epoch 108/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8926 - val_loss: 0.2453 - val_accuracy: 0.9091\n",
      "Epoch 109/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.9008 - val_loss: 0.2355 - val_accuracy: 1.0000\n",
      "Epoch 110/125\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8843 - val_loss: 0.2311 - val_accuracy: 1.0000\n",
      "Epoch 111/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.9008 - val_loss: 0.2367 - val_accuracy: 0.9091\n",
      "Epoch 112/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3246 - accuracy: 0.9008 - val_loss: 0.2409 - val_accuracy: 0.9091\n",
      "Epoch 113/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3231 - accuracy: 0.8926 - val_loss: 0.2365 - val_accuracy: 0.9091\n",
      "Epoch 114/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8926 - val_loss: 0.2339 - val_accuracy: 0.9091\n",
      "Epoch 115/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3198 - accuracy: 0.8760 - val_loss: 0.2162 - val_accuracy: 1.0000\n",
      "Epoch 116/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3185 - accuracy: 0.8926 - val_loss: 0.2148 - val_accuracy: 1.0000\n",
      "Epoch 117/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3157 - accuracy: 0.8843 - val_loss: 0.2170 - val_accuracy: 1.0000\n",
      "Epoch 118/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3142 - accuracy: 0.8926 - val_loss: 0.2089 - val_accuracy: 1.0000\n",
      "Epoch 119/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3123 - accuracy: 0.8926 - val_loss: 0.2107 - val_accuracy: 1.0000\n",
      "Epoch 120/125\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3108 - accuracy: 0.8926 - val_loss: 0.2061 - val_accuracy: 1.0000\n",
      "Epoch 121/125\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3065 - accuracy: 0.9091 - val_loss: 0.2121 - val_accuracy: 1.0000\n",
      "Epoch 122/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3068 - accuracy: 0.9174 - val_loss: 0.2215 - val_accuracy: 0.9091\n",
      "Epoch 123/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3053 - accuracy: 0.9091 - val_loss: 0.2146 - val_accuracy: 0.9091\n",
      "Epoch 124/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.9091 - val_loss: 0.2103 - val_accuracy: 1.0000\n",
      "Epoch 125/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3014 - accuracy: 0.9339 - val_loss: 0.2004 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182dfaaad10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Definición de los callback de TF Board\n",
    "tensorboard_callback = TensorBoard(log_dir=\"logs_multiclass_onehot\")\n",
    "\n",
    "# Ejecución del proceso de aprendizaje\n",
    "model_onehot.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=125,\n",
    "    batch_size=10,\n",
    "    validation_split=0.08,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b73209e-0af0-4bb1-a85d-cfe117d8382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "13/13 [==============================] - 1s 22ms/step - loss: 1.5460 - accuracy: 0.3306 - val_loss: 1.7557 - val_accuracy: 0.3636\n",
      "Epoch 2/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4141 - accuracy: 0.3306 - val_loss: 1.5975 - val_accuracy: 0.3636\n",
      "Epoch 3/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3018 - accuracy: 0.3306 - val_loss: 1.4537 - val_accuracy: 0.3636\n",
      "Epoch 4/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2021 - accuracy: 0.3306 - val_loss: 1.3372 - val_accuracy: 0.3636\n",
      "Epoch 5/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1177 - accuracy: 0.3884 - val_loss: 1.2155 - val_accuracy: 0.4545\n",
      "Epoch 6/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0376 - accuracy: 0.5372 - val_loss: 1.1101 - val_accuracy: 0.5455\n",
      "Epoch 7/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9700 - accuracy: 0.6777 - val_loss: 1.0248 - val_accuracy: 0.5455\n",
      "Epoch 8/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9108 - accuracy: 0.6529 - val_loss: 0.9393 - val_accuracy: 0.5455\n",
      "Epoch 9/125\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8615 - accuracy: 0.6364 - val_loss: 0.8738 - val_accuracy: 0.5455\n",
      "Epoch 10/125\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.8203 - accuracy: 0.6612 - val_loss: 0.8281 - val_accuracy: 0.5455\n",
      "Epoch 11/125\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.7847 - accuracy: 0.6777 - val_loss: 0.7780 - val_accuracy: 0.5455\n",
      "Epoch 12/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7535 - accuracy: 0.6777 - val_loss: 0.7299 - val_accuracy: 0.5455\n",
      "Epoch 13/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7225 - accuracy: 0.7438 - val_loss: 0.6957 - val_accuracy: 0.7273\n",
      "Epoch 14/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.7769 - val_loss: 0.6557 - val_accuracy: 0.7273\n",
      "Epoch 15/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.7769 - val_loss: 0.6275 - val_accuracy: 0.7273\n",
      "Epoch 16/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.7769 - val_loss: 0.5981 - val_accuracy: 0.7273\n",
      "Epoch 17/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.8017 - val_loss: 0.5711 - val_accuracy: 0.9091\n",
      "Epoch 18/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6079 - accuracy: 0.8347 - val_loss: 0.5578 - val_accuracy: 0.9091\n",
      "Epoch 19/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5899 - accuracy: 0.8843 - val_loss: 0.5354 - val_accuracy: 0.9091\n",
      "Epoch 20/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5729 - accuracy: 0.9174 - val_loss: 0.5102 - val_accuracy: 0.9091\n",
      "Epoch 21/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.9256 - val_loss: 0.5027 - val_accuracy: 0.9091\n",
      "Epoch 22/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5442 - accuracy: 0.9174 - val_loss: 0.4724 - val_accuracy: 1.0000\n",
      "Epoch 23/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.9256 - val_loss: 0.4585 - val_accuracy: 1.0000\n",
      "Epoch 24/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.8347 - val_loss: 0.4420 - val_accuracy: 1.0000\n",
      "Epoch 25/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.8760 - val_loss: 0.4369 - val_accuracy: 1.0000\n",
      "Epoch 26/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.9174 - val_loss: 0.4331 - val_accuracy: 1.0000\n",
      "Epoch 27/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.8926 - val_loss: 0.4052 - val_accuracy: 1.0000\n",
      "Epoch 28/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.8512 - val_loss: 0.3992 - val_accuracy: 1.0000\n",
      "Epoch 29/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.8430 - val_loss: 0.3922 - val_accuracy: 1.0000\n",
      "Epoch 30/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.8430 - val_loss: 0.3828 - val_accuracy: 1.0000\n",
      "Epoch 31/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.8760 - val_loss: 0.3822 - val_accuracy: 1.0000\n",
      "Epoch 32/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.8430 - val_loss: 0.3710 - val_accuracy: 1.0000\n",
      "Epoch 33/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8760 - val_loss: 0.3778 - val_accuracy: 1.0000\n",
      "Epoch 34/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.9256 - val_loss: 0.3831 - val_accuracy: 1.0000\n",
      "Epoch 35/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.9339 - val_loss: 0.3610 - val_accuracy: 1.0000\n",
      "Epoch 36/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8512 - val_loss: 0.3344 - val_accuracy: 1.0000\n",
      "Epoch 37/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8430 - val_loss: 0.3359 - val_accuracy: 1.0000\n",
      "Epoch 38/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8843 - val_loss: 0.3491 - val_accuracy: 1.0000\n",
      "Epoch 39/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.9256 - val_loss: 0.3549 - val_accuracy: 1.0000\n",
      "Epoch 40/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.9339 - val_loss: 0.3452 - val_accuracy: 1.0000\n",
      "Epoch 41/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.9339 - val_loss: 0.3289 - val_accuracy: 1.0000\n",
      "Epoch 42/125\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8595 - val_loss: 0.3158 - val_accuracy: 1.0000\n",
      "Epoch 43/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.9174 - val_loss: 0.3271 - val_accuracy: 1.0000\n",
      "Epoch 44/125\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.9339 - val_loss: 0.3332 - val_accuracy: 1.0000\n",
      "Epoch 45/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.9339 - val_loss: 0.3236 - val_accuracy: 1.0000\n",
      "Epoch 46/125\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.9339 - val_loss: 0.3244 - val_accuracy: 1.0000\n",
      "Epoch 47/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.9339 - val_loss: 0.3204 - val_accuracy: 1.0000\n",
      "Epoch 48/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.9256 - val_loss: 0.2921 - val_accuracy: 1.0000\n",
      "Epoch 49/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8760 - val_loss: 0.2920 - val_accuracy: 1.0000\n",
      "Epoch 50/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8843 - val_loss: 0.2884 - val_accuracy: 1.0000\n",
      "Epoch 51/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.9256 - val_loss: 0.2898 - val_accuracy: 1.0000\n",
      "Epoch 52/125\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.9256 - val_loss: 0.2805 - val_accuracy: 1.0000\n",
      "Epoch 53/125\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8678 - val_loss: 0.2741 - val_accuracy: 1.0000\n",
      "Epoch 54/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8430 - val_loss: 0.2638 - val_accuracy: 1.0000\n",
      "Epoch 55/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3605 - accuracy: 0.8430 - val_loss: 0.2619 - val_accuracy: 1.0000\n",
      "Epoch 56/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8760 - val_loss: 0.2642 - val_accuracy: 1.0000\n",
      "Epoch 57/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8843 - val_loss: 0.2659 - val_accuracy: 1.0000\n",
      "Epoch 58/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.9256 - val_loss: 0.2750 - val_accuracy: 1.0000\n",
      "Epoch 59/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3473 - accuracy: 0.9339 - val_loss: 0.2694 - val_accuracy: 1.0000\n",
      "Epoch 60/125\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.9174 - val_loss: 0.2620 - val_accuracy: 1.0000\n",
      "Epoch 61/125\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.9256 - val_loss: 0.2647 - val_accuracy: 1.0000\n",
      "Epoch 62/125\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3452 - accuracy: 0.9091 - val_loss: 0.2695 - val_accuracy: 0.9091\n",
      "Epoch 63/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3374 - accuracy: 0.9008 - val_loss: 0.2566 - val_accuracy: 1.0000\n",
      "Epoch 64/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.9008 - val_loss: 0.2500 - val_accuracy: 1.0000\n",
      "Epoch 65/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.9091 - val_loss: 0.2519 - val_accuracy: 1.0000\n",
      "Epoch 66/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.9091 - val_loss: 0.2629 - val_accuracy: 0.9091\n",
      "Epoch 67/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.9256 - val_loss: 0.2442 - val_accuracy: 1.0000\n",
      "Epoch 68/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.9091 - val_loss: 0.2534 - val_accuracy: 1.0000\n",
      "Epoch 69/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3253 - accuracy: 0.9256 - val_loss: 0.2504 - val_accuracy: 1.0000\n",
      "Epoch 70/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3243 - accuracy: 0.9256 - val_loss: 0.2373 - val_accuracy: 1.0000\n",
      "Epoch 71/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3215 - accuracy: 0.8926 - val_loss: 0.2297 - val_accuracy: 1.0000\n",
      "Epoch 72/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.9174 - val_loss: 0.2359 - val_accuracy: 1.0000\n",
      "Epoch 73/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3172 - accuracy: 0.9256 - val_loss: 0.2356 - val_accuracy: 1.0000\n",
      "Epoch 74/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3154 - accuracy: 0.9339 - val_loss: 0.2354 - val_accuracy: 1.0000\n",
      "Epoch 75/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.8926 - val_loss: 0.2238 - val_accuracy: 1.0000\n",
      "Epoch 76/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3149 - accuracy: 0.8843 - val_loss: 0.2172 - val_accuracy: 1.0000\n",
      "Epoch 77/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.8926 - val_loss: 0.2162 - val_accuracy: 1.0000\n",
      "Epoch 78/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3114 - accuracy: 0.8926 - val_loss: 0.2170 - val_accuracy: 1.0000\n",
      "Epoch 79/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3092 - accuracy: 0.9256 - val_loss: 0.2184 - val_accuracy: 1.0000\n",
      "Epoch 80/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3061 - accuracy: 0.9339 - val_loss: 0.2251 - val_accuracy: 1.0000\n",
      "Epoch 81/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.9339 - val_loss: 0.2248 - val_accuracy: 1.0000\n",
      "Epoch 82/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.9174 - val_loss: 0.2323 - val_accuracy: 1.0000\n",
      "Epoch 83/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2998 - accuracy: 0.9339 - val_loss: 0.2098 - val_accuracy: 1.0000\n",
      "Epoch 84/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.9174 - val_loss: 0.2149 - val_accuracy: 1.0000\n",
      "Epoch 85/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3015 - accuracy: 0.9339 - val_loss: 0.2287 - val_accuracy: 0.9091\n",
      "Epoch 86/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3018 - accuracy: 0.9091 - val_loss: 0.2287 - val_accuracy: 1.0000\n",
      "Epoch 87/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2990 - accuracy: 0.9339 - val_loss: 0.2151 - val_accuracy: 1.0000\n",
      "Epoch 88/125\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2974 - accuracy: 0.9256 - val_loss: 0.2044 - val_accuracy: 1.0000\n",
      "Epoch 89/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2947 - accuracy: 0.9339 - val_loss: 0.2105 - val_accuracy: 1.0000\n",
      "Epoch 90/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2957 - accuracy: 0.9339 - val_loss: 0.2190 - val_accuracy: 1.0000\n",
      "Epoch 91/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2939 - accuracy: 0.9339 - val_loss: 0.2082 - val_accuracy: 1.0000\n",
      "Epoch 92/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2914 - accuracy: 0.9339 - val_loss: 0.2038 - val_accuracy: 1.0000\n",
      "Epoch 93/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2907 - accuracy: 0.9339 - val_loss: 0.2094 - val_accuracy: 1.0000\n",
      "Epoch 94/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.9339 - val_loss: 0.1988 - val_accuracy: 1.0000\n",
      "Epoch 95/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.9256 - val_loss: 0.1952 - val_accuracy: 1.0000\n",
      "Epoch 96/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2871 - accuracy: 0.9256 - val_loss: 0.1913 - val_accuracy: 1.0000\n",
      "Epoch 97/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2873 - accuracy: 0.9339 - val_loss: 0.1853 - val_accuracy: 1.0000\n",
      "Epoch 98/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2881 - accuracy: 0.9008 - val_loss: 0.1853 - val_accuracy: 1.0000\n",
      "Epoch 99/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2858 - accuracy: 0.9174 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 100/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2814 - accuracy: 0.9339 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 101/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2819 - accuracy: 0.9339 - val_loss: 0.2045 - val_accuracy: 1.0000\n",
      "Epoch 102/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2845 - accuracy: 0.9339 - val_loss: 0.2061 - val_accuracy: 1.0000\n",
      "Epoch 103/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2831 - accuracy: 0.9339 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 104/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2839 - accuracy: 0.9421 - val_loss: 0.1838 - val_accuracy: 1.0000\n",
      "Epoch 105/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2780 - accuracy: 0.9339 - val_loss: 0.1923 - val_accuracy: 1.0000\n",
      "Epoch 106/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2773 - accuracy: 0.9339 - val_loss: 0.1872 - val_accuracy: 1.0000\n",
      "Epoch 107/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2754 - accuracy: 0.9339 - val_loss: 0.1856 - val_accuracy: 1.0000\n",
      "Epoch 108/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2798 - accuracy: 0.9339 - val_loss: 0.1984 - val_accuracy: 1.0000\n",
      "Epoch 109/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2727 - accuracy: 0.9339 - val_loss: 0.1845 - val_accuracy: 1.0000\n",
      "Epoch 110/125\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2724 - accuracy: 0.9339 - val_loss: 0.1820 - val_accuracy: 1.0000\n",
      "Epoch 111/125\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.2713 - accuracy: 0.9421 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 112/125\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.2700 - accuracy: 0.9339 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 113/125\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2720 - accuracy: 0.9339 - val_loss: 0.1882 - val_accuracy: 1.0000\n",
      "Epoch 114/125\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.2688 - accuracy: 0.9339 - val_loss: 0.1803 - val_accuracy: 1.0000\n",
      "Epoch 115/125\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2723 - accuracy: 0.9339 - val_loss: 0.1872 - val_accuracy: 1.0000\n",
      "Epoch 116/125\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.2695 - accuracy: 0.9339 - val_loss: 0.1767 - val_accuracy: 1.0000\n",
      "Epoch 117/125\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2666 - accuracy: 0.9339 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 118/125\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2657 - accuracy: 0.9339 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 119/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2653 - accuracy: 0.9421 - val_loss: 0.1671 - val_accuracy: 1.0000\n",
      "Epoch 120/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2647 - accuracy: 0.9421 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 121/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2631 - accuracy: 0.9339 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 122/125\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2627 - accuracy: 0.9339 - val_loss: 0.1664 - val_accuracy: 1.0000\n",
      "Epoch 123/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2621 - accuracy: 0.9339 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 124/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2631 - accuracy: 0.9339 - val_loss: 0.1811 - val_accuracy: 1.0000\n",
      "Epoch 125/125\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2612 - accuracy: 0.9339 - val_loss: 0.1724 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182e0e313f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Definición de los callback de TF Board\n",
    "tensorboard_callback = TensorBoard(log_dir=\"logs_multiclass_integer\")\n",
    "\n",
    "# Ejecución del proceso de aprendizaje\n",
    "model_integer.fit(\n",
    "    X_train,\n",
    "    y_train_integer,\n",
    "    epochs=125,\n",
    "    batch_size=10,\n",
    "    validation_split=0.08,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743c261b-c607-46ac-9ef7-dbe81ce65132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3662 - accuracy: 0.9444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3225 - accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "# Evaluación de los modelos mediante el conjunto de test\n",
    "test_loss_onehot, test_acc_onehot = model_onehot.evaluate(X_test, y_test)\n",
    "test_loss_integer, test_acc_integer = model_integer.evaluate(X_test, y_test_integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a00f6c-db89-40e3-b32c-5e0e1646b605",
   "metadata": {},
   "source": [
    "### 2.5.4 - Inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f78aa-d419-4a00-bde8-8d13f72f6257",
   "metadata": {},
   "source": [
    "En este caso, en vez de visualizar los resultados obtenidos durante el proceso de entrenamiento, vamos a ver cómo podríamos almacenar el modelo y volver a cargarlo para efecturar predicciones. Así, vamos a almacenar el modelo en el fichero `multiclass_classification_model.h5` y, después, vamos a cargarlo de neuvo para generar las predicciones sobre el conjunto de test comprobando si estas cuadran con el resultado esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2167f22-a9f2-45c6-90de-2c13339fb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_onehot.save(\"multiclass_classification_model.h5\")\n",
    "\n",
    "old_model = keras.models.load_model(\"multiclass_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "632ddd2e-8c2c-44d6-8ef8-30e067963dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Predicción (one-hot): [0.9513948  0.04735072 0.00125445]\n",
      "Predicción (integer): [9.9021727e-01 9.5272548e-03 2.5544650e-04]\n",
      "\n",
      "Real (one-hot): [1. 0. 0.]\n",
      "Real (integer): 0\n",
      "\n",
      "sepal_length            4.6\n",
      "sepal_width             3.2\n",
      "petal_length            1.4\n",
      "petal_width             0.2\n",
      "class           Iris-setosa\n",
      "Name: 47, dtype: object\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "predictions_onehot = model_onehot.predict(X_test)\n",
    "predictions_integer = model_integer.predict(X_test)\n",
    "\n",
    "print(f\"Predicción (one-hot): {predictions_onehot[index]}\")\n",
    "print(f\"Predicción (integer): {predictions_integer[index]}\\n\")\n",
    "print(f\"Real (one-hot): {y_test[index]}\")\n",
    "print(f\"Real (integer): {y_test_integer[index]}\\n\")\n",
    "print(test_set.iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc24033-27dd-499d-9ebe-c88486e53d84",
   "metadata": {},
   "source": [
    "Como se puede observar, el valor real esperado es la primera clase (Iris-setosa), la cual es modelo predice correctamente con una confianza (probabilidad) de mas del 90%. Esta predicción es correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2304dc8-41ed-4ad4-9eb5-2143a3759dc9",
   "metadata": {},
   "source": [
    "## 2.6 - Clasificación multietiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460cc59-2f0b-4f30-a8fd-7cb5ef8e16ea",
   "metadata": {},
   "source": [
    "A continuación, vamos a describir cómo construir una red de neuronas mediante la utilización de **un conjunto de valores artificiales generados con el objetivo de\n",
    "explicar este tipo de técnica**. Más adelante volveremos a este tipo de red en el ámbito de clasificación de imágenes, donde los problemas multietiqueta son comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b0bab-8dd4-4d08-bdde-168f5c17763a",
   "metadata": {},
   "source": [
    "### 2.6.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384681f8-930f-4c15-8327-ff298a8e7f8f",
   "metadata": {},
   "source": [
    "La primera fase de todo proceso de ML es la preparación de los datos. En este caso, vamos a construir un conjunto de datos artificial donde contaremos con 16 atributos por cada instancia y 5 posibles etiquetas. Cada una de las instancias de entrenamiento tendrá asignada, al menos, 2 etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1d11aaf-b523-4cc6-a6d7-16e044deeb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_features = 16\n",
    "n_classes = 5\n",
    "\n",
    "data_x, data_y = make_multilabel_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=n_features,\n",
    "    n_classes=n_classes,\n",
    "    n_labels=2,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae322fb7-b77b-4729-a4dd-5be53503e761",
   "metadata": {},
   "source": [
    "Una vez realizada la carga de los datos, debemos llevar a cabo una serie de transformaciones y modificaciones en la información del conjunto de datos con el objetivo de adecuarlos y poder construir nuestra red neuronal:\n",
    "\n",
    "* Codificación numérica de todos los atributos a formato decimal.\n",
    "* Definición de tensores para representar todas las instancias del dataset.\n",
    "* Generación de los splits de entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21b6a12d-d398-478d-ada5-3db8a383caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de los conjuntos de entrenamiento y test split_handler (en este caso no vamos a generar de validación aqui, lo haremos mas adelante)\n",
    "# split proportion: 0.88 train, 0.12 test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.10, random_state=0)\n",
    "\n",
    "# Transformación del conjunto de entrenamiento en tensores\n",
    "X_train = tf.convert_to_tensor(x_train, np.int32)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "# Transformación del conjunto de test en tensores\n",
    "X_test = tf.convert_to_tensor(x_test, np.int32)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2630357c-7faa-458e-8208-7ed613de776a",
   "metadata": {},
   "source": [
    "### 2.6.2 - Construcción de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad5fa49-5f83-4cc7-972c-ed195ab0d59e",
   "metadata": {},
   "source": [
    "Una vez preparados los datos, podemos construir nuestra red neuronal. Para ello, vamos a crear una red formada por tres capas mediante Keras:\n",
    "\n",
    "* Una capa de de tipo `flatten` que acepte como entrada tensores unidimensionales de dimensión `n_features` (en este caso 16).\n",
    "* Una capa densa de 32 neuronas con una función de activación de tipo ReLU.\n",
    "* Una capa densa de `n_classes` (en este caso 5) neuronas con una función de activación de tipo sigmoidea, que nos devolverá la probabilidad de que el ejemplo pertenezca a cada una de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b1b2f43-d51d-48ac-940d-213b85d4a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multilabel_classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Creación de las capas que forman la estructura de la red\n",
    "layers = [keras.layers.Flatten(input_shape=(n_features,)),\n",
    "                 keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "                 keras.layers.Dense(n_classes, activation=tf.nn.sigmoid),\n",
    "                ]\n",
    "\n",
    "# Compilación de la red de neuronas, agrupando las diferentas capas de forma secuencial\n",
    "model = keras.Sequential(layers, name=\"multilabel_classification_model\")\n",
    "\n",
    "# Configuración del algoritmo de optimización y de la función de loss\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44970d4-b8e7-48f4-b65e-d46a0c9d944b",
   "metadata": {},
   "source": [
    "Con respecto a los parámetros observamos lo siguiente:\n",
    "* La capa de entrada `flatten_4` no tiene parámetros ya que simplemente nos sirve para introducir información en la red.\n",
    "* La capa densa `dense_8` está formada por 32 neuronas, cada una de ellas con 16 parámetros de entrada y un parámetro de *bias*, haciendo un total de **544**.\n",
    "* La capa densa `dense_9` está formada por 5 neuronas con 32 parámetros de entrada y un parámetro de *bias*, haciendo un total de **165**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3054ef5b-1518-4f68-9433-761f2be7b988",
   "metadata": {},
   "source": [
    "### 2.6.3 - Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd995e0-ae34-4a61-a0d7-7e1d639a769e",
   "metadata": {},
   "source": [
    "Una vez compilada nuestra red de neuronas, podremos abordar el proceso de entrenamiento mediante la función `fit()`. En este caso, hemos seleccionado las siguientes opciones:\n",
    "* Numero de epochs: 200\n",
    "* Tamaño del *batch* de entrenamiento: 250 instancias\n",
    "* Tamaño del conjunto de validación: 10% del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aac55073-b68f-4d2f-b4fb-9de057538630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 107ms/step - loss: 5.6853 - accuracy: 0.0593 - val_loss: 5.0186 - val_accuracy: 0.0778\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 5.1625 - accuracy: 0.0716 - val_loss: 4.5595 - val_accuracy: 0.0778\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.7120 - accuracy: 0.0840 - val_loss: 4.1644 - val_accuracy: 0.0778\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 4.3310 - accuracy: 0.0975 - val_loss: 3.8231 - val_accuracy: 0.0889\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4.0015 - accuracy: 0.1136 - val_loss: 3.5338 - val_accuracy: 0.1000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 3.7174 - accuracy: 0.1222 - val_loss: 3.2910 - val_accuracy: 0.1333\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.4864 - accuracy: 0.1407 - val_loss: 3.1001 - val_accuracy: 0.1667\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 3.3048 - accuracy: 0.1580 - val_loss: 2.9569 - val_accuracy: 0.1667\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.1708 - accuracy: 0.1753 - val_loss: 2.8541 - val_accuracy: 0.1778\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 3.0737 - accuracy: 0.1877 - val_loss: 2.7797 - val_accuracy: 0.1889\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 3.0020 - accuracy: 0.2074 - val_loss: 2.7246 - val_accuracy: 0.2000\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.9477 - accuracy: 0.2173 - val_loss: 2.6830 - val_accuracy: 0.2222\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.9069 - accuracy: 0.2309 - val_loss: 2.6510 - val_accuracy: 0.2222\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.8739 - accuracy: 0.2370 - val_loss: 2.6273 - val_accuracy: 0.2111\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.8482 - accuracy: 0.2457 - val_loss: 2.6090 - val_accuracy: 0.2222\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.8275 - accuracy: 0.2519 - val_loss: 2.5937 - val_accuracy: 0.2222\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.8111 - accuracy: 0.2580 - val_loss: 2.5808 - val_accuracy: 0.2556\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.7966 - accuracy: 0.2716 - val_loss: 2.5696 - val_accuracy: 0.2556\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.7838 - accuracy: 0.2765 - val_loss: 2.5593 - val_accuracy: 0.2444\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.7718 - accuracy: 0.2827 - val_loss: 2.5491 - val_accuracy: 0.2667\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.7603 - accuracy: 0.2963 - val_loss: 2.5392 - val_accuracy: 0.2667\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.7497 - accuracy: 0.3000 - val_loss: 2.5293 - val_accuracy: 0.3000\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.7389 - accuracy: 0.3185 - val_loss: 2.5193 - val_accuracy: 0.3111\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.7285 - accuracy: 0.3383 - val_loss: 2.5088 - val_accuracy: 0.3111\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.7171 - accuracy: 0.3580 - val_loss: 2.4973 - val_accuracy: 0.3333\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.7058 - accuracy: 0.3728 - val_loss: 2.4847 - val_accuracy: 0.3889\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.6931 - accuracy: 0.3926 - val_loss: 2.4728 - val_accuracy: 0.3889\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.6804 - accuracy: 0.4148 - val_loss: 2.4609 - val_accuracy: 0.4111\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.6669 - accuracy: 0.4333 - val_loss: 2.4483 - val_accuracy: 0.4222\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.6528 - accuracy: 0.4506 - val_loss: 2.4363 - val_accuracy: 0.4444\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.6382 - accuracy: 0.4654 - val_loss: 2.4248 - val_accuracy: 0.4667\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.6224 - accuracy: 0.4852 - val_loss: 2.4142 - val_accuracy: 0.4667\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.6079 - accuracy: 0.4926 - val_loss: 2.4045 - val_accuracy: 0.4667\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.5925 - accuracy: 0.4926 - val_loss: 2.3953 - val_accuracy: 0.4667\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.5780 - accuracy: 0.4901 - val_loss: 2.3866 - val_accuracy: 0.4667\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.5650 - accuracy: 0.4963 - val_loss: 2.3779 - val_accuracy: 0.4778\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.5522 - accuracy: 0.4988 - val_loss: 2.3689 - val_accuracy: 0.4778\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5412 - accuracy: 0.5062 - val_loss: 2.3590 - val_accuracy: 0.4889\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.5293 - accuracy: 0.5136 - val_loss: 2.3512 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.5186 - accuracy: 0.5173 - val_loss: 2.3443 - val_accuracy: 0.5222\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.5078 - accuracy: 0.5247 - val_loss: 2.3357 - val_accuracy: 0.5222\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.4972 - accuracy: 0.5321 - val_loss: 2.3289 - val_accuracy: 0.5222\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4876 - accuracy: 0.5407 - val_loss: 2.3220 - val_accuracy: 0.5111\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4778 - accuracy: 0.5444 - val_loss: 2.3149 - val_accuracy: 0.5444\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4675 - accuracy: 0.5543 - val_loss: 2.3092 - val_accuracy: 0.5667\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.4588 - accuracy: 0.5617 - val_loss: 2.3020 - val_accuracy: 0.5778\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.4501 - accuracy: 0.5778 - val_loss: 2.2968 - val_accuracy: 0.5889\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.4425 - accuracy: 0.5691 - val_loss: 2.2940 - val_accuracy: 0.5667\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4352 - accuracy: 0.5667 - val_loss: 2.2894 - val_accuracy: 0.5667\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4287 - accuracy: 0.5741 - val_loss: 2.2853 - val_accuracy: 0.5667\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.4218 - accuracy: 0.5790 - val_loss: 2.2808 - val_accuracy: 0.5667\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4166 - accuracy: 0.5778 - val_loss: 2.2770 - val_accuracy: 0.5667\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.4113 - accuracy: 0.5716 - val_loss: 2.2708 - val_accuracy: 0.5778\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4066 - accuracy: 0.5679 - val_loss: 2.2666 - val_accuracy: 0.5778\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4016 - accuracy: 0.5728 - val_loss: 2.2660 - val_accuracy: 0.5778\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3973 - accuracy: 0.5827 - val_loss: 2.2671 - val_accuracy: 0.5667\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.3939 - accuracy: 0.5889 - val_loss: 2.2662 - val_accuracy: 0.5889\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3904 - accuracy: 0.5951 - val_loss: 2.2666 - val_accuracy: 0.5889\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3875 - accuracy: 0.6074 - val_loss: 2.2641 - val_accuracy: 0.6000\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.3840 - accuracy: 0.6000 - val_loss: 2.2583 - val_accuracy: 0.5889\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3808 - accuracy: 0.5815 - val_loss: 2.2550 - val_accuracy: 0.5667\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3775 - accuracy: 0.5716 - val_loss: 2.2543 - val_accuracy: 0.5556\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3748 - accuracy: 0.5778 - val_loss: 2.2553 - val_accuracy: 0.5667\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3731 - accuracy: 0.5864 - val_loss: 2.2559 - val_accuracy: 0.5667\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3704 - accuracy: 0.5852 - val_loss: 2.2523 - val_accuracy: 0.5667\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3685 - accuracy: 0.5753 - val_loss: 2.2486 - val_accuracy: 0.5667\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3665 - accuracy: 0.5704 - val_loss: 2.2476 - val_accuracy: 0.5778\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3646 - accuracy: 0.5827 - val_loss: 2.2471 - val_accuracy: 0.5667\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3622 - accuracy: 0.5741 - val_loss: 2.2476 - val_accuracy: 0.5667\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3606 - accuracy: 0.5753 - val_loss: 2.2489 - val_accuracy: 0.5556\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3591 - accuracy: 0.5753 - val_loss: 2.2508 - val_accuracy: 0.5667\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3577 - accuracy: 0.5765 - val_loss: 2.2500 - val_accuracy: 0.5889\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3554 - accuracy: 0.5667 - val_loss: 2.2444 - val_accuracy: 0.5889\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3545 - accuracy: 0.5580 - val_loss: 2.2417 - val_accuracy: 0.5889\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3528 - accuracy: 0.5605 - val_loss: 2.2452 - val_accuracy: 0.5889\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3512 - accuracy: 0.5716 - val_loss: 2.2484 - val_accuracy: 0.6000\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3496 - accuracy: 0.5765 - val_loss: 2.2478 - val_accuracy: 0.6000\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3485 - accuracy: 0.5741 - val_loss: 2.2476 - val_accuracy: 0.6111\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3483 - accuracy: 0.5704 - val_loss: 2.2498 - val_accuracy: 0.6111\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3461 - accuracy: 0.5741 - val_loss: 2.2474 - val_accuracy: 0.6111\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3443 - accuracy: 0.5716 - val_loss: 2.2463 - val_accuracy: 0.6000\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.3442 - accuracy: 0.5778 - val_loss: 2.2471 - val_accuracy: 0.6111\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3435 - accuracy: 0.5815 - val_loss: 2.2464 - val_accuracy: 0.6000\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.3416 - accuracy: 0.5691 - val_loss: 2.2425 - val_accuracy: 0.5889\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.3399 - accuracy: 0.5580 - val_loss: 2.2402 - val_accuracy: 0.5778\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3390 - accuracy: 0.5543 - val_loss: 2.2398 - val_accuracy: 0.5778\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3376 - accuracy: 0.5667 - val_loss: 2.2449 - val_accuracy: 0.6111\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3363 - accuracy: 0.5790 - val_loss: 2.2479 - val_accuracy: 0.6222\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.3356 - accuracy: 0.5864 - val_loss: 2.2477 - val_accuracy: 0.6222\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3346 - accuracy: 0.5852 - val_loss: 2.2473 - val_accuracy: 0.6111\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3339 - accuracy: 0.5741 - val_loss: 2.2458 - val_accuracy: 0.6000\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3324 - accuracy: 0.5605 - val_loss: 2.2419 - val_accuracy: 0.5889\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3328 - accuracy: 0.5506 - val_loss: 2.2386 - val_accuracy: 0.5778\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3325 - accuracy: 0.5444 - val_loss: 2.2386 - val_accuracy: 0.6000\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3304 - accuracy: 0.5543 - val_loss: 2.2429 - val_accuracy: 0.6111\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.3296 - accuracy: 0.5704 - val_loss: 2.2504 - val_accuracy: 0.6222\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3291 - accuracy: 0.5827 - val_loss: 2.2529 - val_accuracy: 0.6333\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3282 - accuracy: 0.5790 - val_loss: 2.2482 - val_accuracy: 0.6111\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3272 - accuracy: 0.5741 - val_loss: 2.2429 - val_accuracy: 0.6111\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3263 - accuracy: 0.5543 - val_loss: 2.2405 - val_accuracy: 0.6111\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3258 - accuracy: 0.5506 - val_loss: 2.2372 - val_accuracy: 0.6111\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3257 - accuracy: 0.5481 - val_loss: 2.2380 - val_accuracy: 0.6111\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3239 - accuracy: 0.5543 - val_loss: 2.2449 - val_accuracy: 0.6000\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.3232 - accuracy: 0.5593 - val_loss: 2.2496 - val_accuracy: 0.6111\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3234 - accuracy: 0.5543 - val_loss: 2.2465 - val_accuracy: 0.6000\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.3219 - accuracy: 0.5568 - val_loss: 2.2440 - val_accuracy: 0.6111\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3216 - accuracy: 0.5543 - val_loss: 2.2427 - val_accuracy: 0.6111\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3206 - accuracy: 0.5531 - val_loss: 2.2449 - val_accuracy: 0.6111\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3194 - accuracy: 0.5593 - val_loss: 2.2481 - val_accuracy: 0.6111\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3187 - accuracy: 0.5654 - val_loss: 2.2495 - val_accuracy: 0.6111\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3185 - accuracy: 0.5667 - val_loss: 2.2491 - val_accuracy: 0.6111\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3177 - accuracy: 0.5691 - val_loss: 2.2457 - val_accuracy: 0.6111\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3167 - accuracy: 0.5617 - val_loss: 2.2441 - val_accuracy: 0.6111\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3162 - accuracy: 0.5556 - val_loss: 2.2445 - val_accuracy: 0.6111\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3157 - accuracy: 0.5457 - val_loss: 2.2475 - val_accuracy: 0.6111\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3145 - accuracy: 0.5543 - val_loss: 2.2519 - val_accuracy: 0.6111\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3148 - accuracy: 0.5741 - val_loss: 2.2533 - val_accuracy: 0.6222\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3147 - accuracy: 0.5654 - val_loss: 2.2458 - val_accuracy: 0.6111\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3130 - accuracy: 0.5506 - val_loss: 2.2442 - val_accuracy: 0.6111\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3123 - accuracy: 0.5457 - val_loss: 2.2443 - val_accuracy: 0.6111\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.3118 - accuracy: 0.5432 - val_loss: 2.2444 - val_accuracy: 0.6111\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 2.3110 - accuracy: 0.5444 - val_loss: 2.2462 - val_accuracy: 0.6000\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.3105 - accuracy: 0.5444 - val_loss: 2.2442 - val_accuracy: 0.6000\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.3102 - accuracy: 0.5383 - val_loss: 2.2448 - val_accuracy: 0.6000\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.3093 - accuracy: 0.5407 - val_loss: 2.2482 - val_accuracy: 0.6111\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2.3093 - accuracy: 0.5457 - val_loss: 2.2500 - val_accuracy: 0.6111\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.3090 - accuracy: 0.5457 - val_loss: 2.2494 - val_accuracy: 0.6111\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3080 - accuracy: 0.5407 - val_loss: 2.2509 - val_accuracy: 0.6000\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3070 - accuracy: 0.5420 - val_loss: 2.2518 - val_accuracy: 0.6000\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3071 - accuracy: 0.5444 - val_loss: 2.2504 - val_accuracy: 0.6111\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3070 - accuracy: 0.5469 - val_loss: 2.2452 - val_accuracy: 0.6111\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3062 - accuracy: 0.5444 - val_loss: 2.2445 - val_accuracy: 0.6111\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3047 - accuracy: 0.5420 - val_loss: 2.2509 - val_accuracy: 0.6111\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3045 - accuracy: 0.5420 - val_loss: 2.2513 - val_accuracy: 0.6111\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3049 - accuracy: 0.5494 - val_loss: 2.2532 - val_accuracy: 0.6111\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3039 - accuracy: 0.5494 - val_loss: 2.2489 - val_accuracy: 0.6111\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3024 - accuracy: 0.5494 - val_loss: 2.2480 - val_accuracy: 0.6111\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.3027 - accuracy: 0.5469 - val_loss: 2.2488 - val_accuracy: 0.6111\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3021 - accuracy: 0.5457 - val_loss: 2.2500 - val_accuracy: 0.6111\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3014 - accuracy: 0.5420 - val_loss: 2.2517 - val_accuracy: 0.6111\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3008 - accuracy: 0.5370 - val_loss: 2.2501 - val_accuracy: 0.6111\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3005 - accuracy: 0.5420 - val_loss: 2.2501 - val_accuracy: 0.6222\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2995 - accuracy: 0.5481 - val_loss: 2.2483 - val_accuracy: 0.6222\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2992 - accuracy: 0.5531 - val_loss: 2.2497 - val_accuracy: 0.6111\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2986 - accuracy: 0.5494 - val_loss: 2.2523 - val_accuracy: 0.6111\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2982 - accuracy: 0.5420 - val_loss: 2.2501 - val_accuracy: 0.6111\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2974 - accuracy: 0.5420 - val_loss: 2.2466 - val_accuracy: 0.6222\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2974 - accuracy: 0.5321 - val_loss: 2.2444 - val_accuracy: 0.6333\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2972 - accuracy: 0.5420 - val_loss: 2.2482 - val_accuracy: 0.6333\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2965 - accuracy: 0.5481 - val_loss: 2.2484 - val_accuracy: 0.6222\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2959 - accuracy: 0.5420 - val_loss: 2.2465 - val_accuracy: 0.6111\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2948 - accuracy: 0.5284 - val_loss: 2.2434 - val_accuracy: 0.6000\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2956 - accuracy: 0.5284 - val_loss: 2.2421 - val_accuracy: 0.6000\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2956 - accuracy: 0.5309 - val_loss: 2.2421 - val_accuracy: 0.6000\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2942 - accuracy: 0.5309 - val_loss: 2.2446 - val_accuracy: 0.6111\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2932 - accuracy: 0.5407 - val_loss: 2.2443 - val_accuracy: 0.6111\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2928 - accuracy: 0.5407 - val_loss: 2.2441 - val_accuracy: 0.6222\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2924 - accuracy: 0.5358 - val_loss: 2.2458 - val_accuracy: 0.6111\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2919 - accuracy: 0.5333 - val_loss: 2.2466 - val_accuracy: 0.6111\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2915 - accuracy: 0.5358 - val_loss: 2.2460 - val_accuracy: 0.6111\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.2911 - accuracy: 0.5346 - val_loss: 2.2437 - val_accuracy: 0.6111\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.2908 - accuracy: 0.5272 - val_loss: 2.2421 - val_accuracy: 0.6111\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.2904 - accuracy: 0.5259 - val_loss: 2.2416 - val_accuracy: 0.6222\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.2901 - accuracy: 0.5346 - val_loss: 2.2453 - val_accuracy: 0.6111\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2899 - accuracy: 0.5481 - val_loss: 2.2467 - val_accuracy: 0.6111\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.2894 - accuracy: 0.5420 - val_loss: 2.2412 - val_accuracy: 0.6222\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2892 - accuracy: 0.5296 - val_loss: 2.2374 - val_accuracy: 0.6222\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2887 - accuracy: 0.5247 - val_loss: 2.2376 - val_accuracy: 0.6222\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2876 - accuracy: 0.5296 - val_loss: 2.2443 - val_accuracy: 0.6222\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2878 - accuracy: 0.5370 - val_loss: 2.2510 - val_accuracy: 0.6222\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2875 - accuracy: 0.5346 - val_loss: 2.2467 - val_accuracy: 0.6222\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2865 - accuracy: 0.5272 - val_loss: 2.2415 - val_accuracy: 0.6111\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2862 - accuracy: 0.5247 - val_loss: 2.2396 - val_accuracy: 0.6111\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2859 - accuracy: 0.5235 - val_loss: 2.2405 - val_accuracy: 0.6111\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2854 - accuracy: 0.5346 - val_loss: 2.2448 - val_accuracy: 0.6111\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2851 - accuracy: 0.5457 - val_loss: 2.2461 - val_accuracy: 0.6222\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2844 - accuracy: 0.5457 - val_loss: 2.2415 - val_accuracy: 0.6111\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2841 - accuracy: 0.5309 - val_loss: 2.2414 - val_accuracy: 0.6111\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2844 - accuracy: 0.5235 - val_loss: 2.2388 - val_accuracy: 0.6111\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.2840 - accuracy: 0.5222 - val_loss: 2.2403 - val_accuracy: 0.6111\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2833 - accuracy: 0.5235 - val_loss: 2.2441 - val_accuracy: 0.6111\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2837 - accuracy: 0.5370 - val_loss: 2.2506 - val_accuracy: 0.6111\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2824 - accuracy: 0.5457 - val_loss: 2.2460 - val_accuracy: 0.6222\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2819 - accuracy: 0.5358 - val_loss: 2.2426 - val_accuracy: 0.6333\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2819 - accuracy: 0.5395 - val_loss: 2.2363 - val_accuracy: 0.6222\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2816 - accuracy: 0.5370 - val_loss: 2.2396 - val_accuracy: 0.6222\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2810 - accuracy: 0.5432 - val_loss: 2.2474 - val_accuracy: 0.6333\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2804 - accuracy: 0.5519 - val_loss: 2.2455 - val_accuracy: 0.6222\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2799 - accuracy: 0.5358 - val_loss: 2.2382 - val_accuracy: 0.6222\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2791 - accuracy: 0.5296 - val_loss: 2.2369 - val_accuracy: 0.6111\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2790 - accuracy: 0.5247 - val_loss: 2.2403 - val_accuracy: 0.6111\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2788 - accuracy: 0.5259 - val_loss: 2.2449 - val_accuracy: 0.6111\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2789 - accuracy: 0.5370 - val_loss: 2.2493 - val_accuracy: 0.6222\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.2784 - accuracy: 0.5494 - val_loss: 2.2455 - val_accuracy: 0.6333\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2774 - accuracy: 0.5481 - val_loss: 2.2367 - val_accuracy: 0.6222\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2769 - accuracy: 0.5407 - val_loss: 2.2324 - val_accuracy: 0.6222\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2764 - accuracy: 0.5296 - val_loss: 2.2327 - val_accuracy: 0.6111\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2761 - accuracy: 0.5259 - val_loss: 2.2328 - val_accuracy: 0.6111\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2754 - accuracy: 0.5259 - val_loss: 2.2359 - val_accuracy: 0.6222\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2751 - accuracy: 0.5333 - val_loss: 2.2384 - val_accuracy: 0.6222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182e30f8ac0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Definición de los callback de TF Board\n",
    "tensorboard_callback = TensorBoard(log_dir=\"logs_multilabel\")\n",
    "\n",
    "# Ejecución del proceso de aprendizaje\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=200, # Numero de epochs\n",
    "    batch_size=250, # Tamaño de los batches\n",
    "    validation_split=0.10, # Tamaño del conjunto de validación\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81ec0f14-eb9c-4be1-adad-2bf0c35d0b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1761 - accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61cb57-ee78-4c19-bcac-e3765c688224",
   "metadata": {},
   "source": [
    "### 2.6.4 - Inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea885b1-6052-4258-801a-939e84ab25e0",
   "metadata": {},
   "source": [
    "Simplemente vamos a analizar la salida del modelo con el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96fde672-0d62-4462-8b08-ded925920212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "Predicción: [0.75951594 0.7472822  0.00602337 0.712368   0.14843097]\n",
      "Real: [1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "index = 1\n",
    "print(f\"Predicción: {predictions[index]}\")\n",
    "print(f\"Real: {y_test[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c7f08-10c0-4f7e-83cf-4f27680940d2",
   "metadata": {},
   "source": [
    "## 2.7 - Optimización de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb4ab6-96f2-4fbc-945c-80d84c45ab38",
   "metadata": {},
   "source": [
    "Los hiperparámetros son un conjunto especial de parámetros que permiten regir el funcionamiento de la fase de entreanamiento. Se utilizan para definir ciertos elementos del algoritmo o de la fase de entranamiento que son independientes del conjunto de datos utilizado. A continuación, se indican algunos de los hiperparámetros más utilizados:\n",
    "\n",
    "* Tasa de aprendizaje.\n",
    "* Tamaño de *batch*.\n",
    "* Número de capas ocultas.\n",
    "* Número de neuronas de capa oculta.\n",
    "\n",
    "La **optimización de hiperparámetros** se define como el proceso destinado a hallar la configuración de hiperparámetros que permita generar el modelo con el mejor rendimiento. Para este proceso de búsqueda, realizaremos **múltiples ejecuciones de entrenamiento mediante la modificación conjunta de los diferentes hiperparámetros que se han de optmizar**. En este sentido, **haremos unicamente uso de los conjuntos de entrenamiento y valdiación**, no del de test. Finalmente, cuanto mayor sea el número de hiperparámetros, mayor será el numero de combinaciones a evaluar y con ello el tiempo y coste computacional del proceso de optimización.\n",
    "\n",
    "Para seleccionar los mejores valores de los hiperparámetros se utilizan diferentes tipos de algoritmos de búsqueda, siendo los más utilizados los que se desriben a continuación:\n",
    "\n",
    "* **Busqueda aleatoria (Random Search)**, consiste en seleccionar valores para los diferentes hiperparámetros de manera aleatoria dentro del espacio de búsqueda que está formado por los rangos válidos para cada uno de los hiperparámetros.\n",
    "\n",
    "* **Búsqueda en cuadrícula (Grid Search)**, es un proceso de búsqueda donde los diferentes valores de hiperparámetros se combinan para crear una maya (*grid*) en la cual se incluyen todas las posibles combinaciones de hiperparámetros que serán utilizadas para construir el modelo. En ese caso, el proceso de búsqueda consiste en ir seleccionado posibles configuraciones y probar que resultado ofrece en el momento de construir un modelo de razonamiento\n",
    "\n",
    "**En resumen, mientras que la búsqueda en cuadrícula analiza todas las combinaciones posibles de hiperparámetros para encontrar el mejor modelo, la búsqueda aleatoria selecciona y prueba una combinaciones aleatorias de hiperparámetros en vez de realizar una búsqueda exhaustiva.**\n",
    "\n",
    "Si bien éstas son las principales técnicas para la selección de hiperparámetros, en los últimos años se han desarrollado muchas otras, algunas de las cuales se incluyen en los frameworks de Machine Learning y Deep Learning:\n",
    "\n",
    "* [Búsqueda Bayesiana.](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f)\n",
    "* [Búsqueda evolutiva mediante la utilización de algoritmos genéticos.](https://medium.com/cindicator/genetic-algorithms-and-hyperparameters-weekend-of-a-data-scientist-8f069669015e)\n",
    "* [Búsqueda mediante optimización basada en gradientes.](https://en.wikipedia.org/wiki/Hyperparameter_optimization)\n",
    "\n",
    "Independientemente del tipo de algoritmos de búsqueda que utilicemos, el proceso de optimización de hiperparámetros suele estar formado por cuatro fases:\n",
    "\n",
    "<img src=\"images_2/optimizacion_hiperparametros.png\" width=\"800\" data-align=\"center\">\n",
    "\n",
    "* **Definición de hiperparámetros.** Definir los posibles valores que podrán adoptar los diferentes hiperparámetros seleccionados para ser optimizados. Así, por ejemplo, la tasa de aprendizaje solo admitirá valores decimales comprendidos entre 0 y 1, mientras que el número de neuronas de una capa admitirá valores enteros situados entre 1 e infinito.\n",
    "* **Selección del algoritmo de búsqueda.** Definir el algoritmo que será utilizado para buscar en el espacio de hiperparámetros, así como su configuración. Por ejemplo, el número de iteraciones del proceso de búsqueda.\n",
    "* **Búsqueda.** Efectuar el proceso de búsqueda. Esta fase consta, a su vez, de tres etapas:\n",
    "    * Selección. Seleccionar una serie de valores para los hiperparámetros.\n",
    "    * Entrenamiento. El proceso de entrenamiento con el objetivo de generar un modelo y poder evaluar su calidad mediante el conjunto de validación.\n",
    "    * Evaluación. Evaluar el modelo generado con el objetivo de crear un ranking en base a la selección de hiperparámetros.\n",
    "* **Selección de la configuración final.** Evaluar el modelo final con el conjuno de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8e8076c-b5b3-4eeb-81db-014822e26886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d80990-1c23-4b6d-a706-9c7c014d27c5",
   "metadata": {},
   "source": [
    "### 2.7.1 - Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3cf90b-a053-4cc4-b52d-4ca50b7942af",
   "metadata": {},
   "source": [
    "La primera fase de todo proceso de ML es la preparación de los datos. En este caso, vamos a utilizar **el conjunto de datos sobre pruebas diagnósticas para la detección del cáncer de mama**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9816ed26-f933-4368-acdc-867c74e9f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)\n",
    "data.columns = [\n",
    "    \"Sample_code_number\",\n",
    "    \"Clump_Thickness\",\n",
    "    \"Uniformity_of_Cell_Size\",\n",
    "    \"Uniformity_of_Cell_Shape\",\n",
    "    \"Marginal_Adhesion\",\n",
    "    \"Single_Epithelial_Cell_Size\",\n",
    "    \"Bare_Nuclei\",\n",
    "    \"Bland_Chromatin\",\n",
    "    \"Normal_Nucleoli\",\n",
    "    \"Mitoses\",\n",
    "    \"Class\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cabfb31-2f4c-4c7a-9ad2-21169c10e3d0",
   "metadata": {},
   "source": [
    "Una vez realizada la carga de los datos, debemos llevar a cabo una serie de transformaciones y modificaciones en la información del conjunto de datos con el objetivo de adecuarlos y poder construir nuestra red de neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0896dfcc-8034-4d11-a9fe-f30c1ccd1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de la columna que contiene el id de las muestras \n",
    "data.drop(\"Sample_code_number\", axis=\"columns\", inplace=True)\n",
    "\n",
    "# Modificación de los valores ? que existen en la columna Bare Nuclei (en este caso por el valor -1)\n",
    "data[\"Bare_Nuclei\"] = data['Bare_Nuclei'].replace('?', '-1')\n",
    "\n",
    "# Modificación de las etiquetas para que los valores sean 0 y 1 \n",
    "data[\"Class\"] = data[\"Class\"].map(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Generación de los conjuntos de entrenamiento y test split_handler (en este caso no vamos a generar de validación aqui, lo haremos mas adelante)\n",
    "# split proportion: 0.88 train, 0.12 test\n",
    "train_set, test_set = train_test_split(data, test_size=0.12, random_state=0, stratify=data[\"Class\"])\n",
    "\n",
    "# Transformación del conjunto de entrenamiento en tensores \n",
    "X_train = tf.convert_to_tensor (train_set.iloc[:, :9], np.int32) \n",
    "y_train = tf.convert_to_tensor (train_set.iloc[:, 9:], np.int8)\n",
    "\n",
    "# Transformación del conjunto de test en tensores \n",
    "X_test = tf.convert_to_tensor (test_set.iloc[:, :9], np.float32)\n",
    "y_test = tf.convert_to_tensor (test_set.iloc[:, 9:], np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022910e8-c562-409a-a8f8-1af53a50164a",
   "metadata": {},
   "source": [
    "### 2.7.2 - Definición de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864da10-01ff-4220-8571-177c4e7e96d6",
   "metadata": {},
   "source": [
    "Es necesario definir los diferentes hiperparámetros que se han de optimizar. En este sentido, **vamos a utilizar el sistema de optimización de Keras**, que nos permite llevar a cabo dicho definición de manera muy sencilla. Para desarrollar nuestro ejemplo, vamos a optimizar dos parámetros de la capa densa de nuestra red de neuronas:\n",
    "* **Número de neuronas de la capa oculta**.\n",
    "    * Valor mínimo (`min_value`): 9.\n",
    "    * Valor máximo (`max_value`): 27.\n",
    "    * Paso (`step`): variación que se producirá sobre el parámetro en las sucesivas iteraciones del algoritmo de búsqueda y que poseerá un valor de 3.\n",
    "    * Valor inicial (`default`): 12.\n",
    "* **Función de activación**.  El segundo parámetro que se va a optimizar será la función de activación de la capa oculta. Para ello **permitiremos que esta pruebe dos posibles funciones de activación: ReLU y tangente hiperbólica**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d65f4e22-da3f-4c2b-8bca-7be5b5840dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "class FFNNHyperModel(HyperModel):\n",
    "    \n",
    "    def build(self, hp):\n",
    "        \n",
    "        hp_units = hp.Int(\n",
    "            \"dense_1_units\",\n",
    "            min_value=9,\n",
    "            max_value=27,\n",
    "            step=3,\n",
    "            default=12\n",
    "        )\n",
    "        \n",
    "        hp_function = hp.Choice(\n",
    "            \"dense_1_activation\",\n",
    "            values=[\"relu\", \"tanh\"],\n",
    "            default=\"relu\"\n",
    "        )\n",
    "        \n",
    "        layers = [\n",
    "            keras.layers.Flatten(name=\"input\", input_shape=(9,)),\n",
    "            keras.layers.Dense(\n",
    "                name=\"hidden\",\n",
    "                units=hp_units,\n",
    "                activation=hp_function\n",
    "            ),\n",
    "            keras.layers.Dense(\n",
    "                name=\"output\",\n",
    "                units=1,\n",
    "                activation=tf.nn.sigmoid\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        model = keras.Sequential(layers, name=\"binary_classification\")\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=\"sgd\",\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0b3c7-9362-495e-9041-f62d688c2b49",
   "metadata": {},
   "source": [
    "### 2.7.3 - Definición del proceso de búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e413b109-545a-44a5-9119-99d125fa1a97",
   "metadata": {},
   "source": [
    "En este caso, vamos a definir:\n",
    "* **El algoritmo de búsqueda**, en este caso haremos uso del más simple, es decir, la búsqueda aleatoria. \n",
    "    * Definiremos junto a ella una semilla (*seed*) para poder reproducir el proceso de búsqueda de nuevo\n",
    "* **Número de intentos que se realizarán**.\n",
    "* **Numero de ejecuciones en cada intento**. Número de modelos que se generarán para conjunto de hiperparámetros. Podemos considerar un número más o menos alto para intentar reducir la variabilidad de aprendizaje, principalmente para evitar descartar modelos que \"tuvieron mala suerte\" durante el aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcb876b1-656c-406d-9226-516af6e8807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from random_search\\tokio_tema_3\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 2\n",
      "dense_1_units (Int)\n",
      "{'default': 12, 'conditions': [], 'min_value': 9, 'max_value': 27, 'step': 3, 'sampling': 'linear'}\n",
      "dense_1_activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "MAX_TRIALS = 25\n",
    "EXECUTIONS_PER_TRIAL = 2\n",
    "SEED = 0\n",
    "\n",
    "hypermodel = FFNNHyperModel()\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    seed=SEED,\n",
    "    max_trials=MAX_TRIALS,\n",
    "    executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "    directory=\"random_search\",\n",
    "    project_name=\"tokio_tema_3\"\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6579edf-27ff-40cb-8c7d-b8668808fee0",
   "metadata": {},
   "source": [
    "Aqui podemos ver un resumen tanto del modelo inicial como del proceso de búsqueda que se va a ejecutar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb04942-3813-427c-a6e8-04532ebe1a98",
   "metadata": {},
   "source": [
    "### 2.7.4 - Ejecución del proceso de búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a88455-a4ab-431f-a971-4f17a4194666",
   "metadata": {},
   "source": [
    "En este caso debemos definir los parámetros de configuracion relativos a la ejecución:\n",
    "* El número de epochs para cada ejecución (vamos a usar el valor que vimos en la sección 2.4)\n",
    "* El tamaño del conjunto de validación (vamos a usar el valor que vimos en la sección 2.4)\n",
    "\n",
    "----\n",
    "\n",
    "**Nota:** Simplemente como reflexión, podriamos también realizar un proceso de optimización (de más alto nivel) sobre los hiperparámetros del propio proceso de optimización. En ese caso estariamos en el campo de **meta-aprendizaje**. Una heurística para seleccionar valores aqui es tener una idea de experimentos pasados, ya sean propios o de la literatura.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "880e7920-cbd7-48e3-bb44-ae0103591bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 Complete [00h 00m 18s]\n",
      "val_accuracy: 0.9391891658306122\n",
      "\n",
      "Best val_accuracy So Far: 0.9391891658306122\n",
      "Total elapsed time: 00h 03m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH_SEARCH = 125\n",
    "\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=N_EPOCH_SEARCH,\n",
    "    validation_split=0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95d86f-92c4-4b5e-ab69-47e291d79bec",
   "metadata": {},
   "source": [
    "### 2.7.5 - Selección del la configuración final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e15afe89-9706-4903-a34e-7c36a1d72b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in random_search\\tokio_tema_3\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x00000182E326DE40>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 15\n",
      "dense_1_activation: tanh\n",
      "Score: 0.9391891658306122\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 27\n",
      "dense_1_activation: tanh\n",
      "Score: 0.9391891658306122\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 21\n",
      "dense_1_activation: relu\n",
      "Score: 0.9324324131011963\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 24\n",
      "dense_1_activation: tanh\n",
      "Score: 0.9256756603717804\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 9\n",
      "dense_1_activation: relu\n",
      "Score: 0.9256756603717804\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 18\n",
      "dense_1_activation: relu\n",
      "Score: 0.9256756603717804\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 24\n",
      "dense_1_activation: relu\n",
      "Score: 0.9256756603717804\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 27\n",
      "dense_1_activation: relu\n",
      "Score: 0.9256756603717804\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 18\n",
      "dense_1_activation: tanh\n",
      "Score: 0.9189189076423645\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_1_units: 15\n",
      "dense_1_activation: relu\n",
      "Score: 0.9189189076423645\n",
      "Model: \"binary_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (Flatten)             (None, 9)                 0         \n",
      "                                                                 \n",
      " hidden (Dense)              (None, 15)                150       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166\n",
      "Trainable params: 166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.9405\n",
      "0.20193295180797577\n",
      "0.9404761791229248\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
