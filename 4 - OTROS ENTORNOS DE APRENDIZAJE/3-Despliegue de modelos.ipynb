{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7dccb78-7f08-4998-9ee9-e7ac92acf2dd",
   "metadata": {},
   "source": [
    "# 3 - Despliegue de modelos\n",
    "\n",
    "**Sumario**\n",
    "\n",
    "1. Introducción\n",
    "2. Despliegue de modelos mediante una API\n",
    "3. Despliegue de modelos mediante operaciones\n",
    "4. Despliegue de modelos en dispositivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a75b65a9-94cb-429b-aba6-6dd3ad1388a2",
   "metadata": {},
   "source": [
    "## 3.1 - Introducción"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9ff54ef-368d-4dcf-96b1-ab4361789617",
   "metadata": {},
   "source": [
    "El proceso de construcción de modelos de razonamiento basados en Machine Learning (ML) o en Deep Learning (DL) está dirigido a construir modelos que puedan ser utilizados en diferentes tipos de entornos mediante el proceso de inferencia. Este proceso de uso se conoce como **despliegue de modelos** y, en el caso de que estos sean desplegados en un entorno de tipo productivo, se suele denominar **productivización de modelos**.\n",
    "\n",
    "Como ya hemos estudiado, el ciclo de vida de los modelos consta de dos fases:\n",
    "1. **Fase de entrenamiento**.\n",
    "2. **Fase de inferencia**.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/fases.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "A la hora de definir el proceso de puesta en producción de los modelos, hay que considerar dos factores que\n",
    "pueden influir significativamente en cómo se concreta tanto la fase de entrenamiento como la fase de inferencia:\n",
    "1. El **modo de puesta en producción** que se va a realizar.\n",
    "2. El **entorno donde se va a productivizar**.\n",
    "\n",
    "El **modo de puesta en producción o despliegue** se suele llevar a cabo de dos maneras:\n",
    "\n",
    "* **Productivización o despliegue manual**. Consiste en poner en funcionamiento un modelo mediante la realización manual de todo el proceso. En la mayoría de los casos, los mismos equipos de ingeniería que desarrollan los modelos son los encargados de desplegarlos, lo que garantiza un proceso de despliegue manual preciso.\n",
    "\n",
    "* **Productivización automática**. Consiste poner en funcionamiento un modelo a través de la automatización de varias operaciones. Esto permite que el modelo pueda entrenarse y desplegarse en producción de manera completamente automática, sin la intervención de ningún ingeniero o ingeniera fuera del proceso de diseño, desarrollo y automatización de las operaciones.\n",
    "\n",
    "Una vez definido el modo de productivización, es importante identificar dónde se va a desplegar nuestro modelo. se pueden utilizar tres tipos de entornos de despliegue diferentes:\n",
    "\n",
    "* **Entorno *cloud* público.** Suele ser el entorno más común y consiste en desplegar los modelos mediante los diferentes sistemas de computación disponibles, que van desde la utilización de instancias de ejecución tradicionales -que se corresponden con un sistema operativo donde ejecutamos algún tipo de servidor que nos permite solicitar predicciones a nuestro modelos- hasta el empleo de clústeres de Kubernetes, donde podemos desplegar contenedores que permiten realizar predicciones.\n",
    "    * [Amazon Web Services (AWS).](https://aws.amazon.com/es/)\n",
    "    * [Microsoft Azure.](https://azure.microsoft.com/es-es)\n",
    "    * [Google Cloud Plataform (GCP).](https://cloud.google.com/?hl=es)\n",
    "    * [IBM Cloud](https://www.ibm.com/es-es/cloud)\n",
    "\n",
    "* **Entorno *cloud* privado.** Es similar al entorno público, pero ofrece un menor número de herramientas para la productivización de modelos a nivel automático, ya que muchas de las nuevas herramientas de automatización solo están implementadas en ciertos entornos de tipo cloud público a nivel nativo.\n",
    "    * [OpenStack.](https://www.openstack.org/)\n",
    "    * [Azure Stack.](https://azure.microsoft.com/es-es/products/azure-stack)\n",
    "    * [Red Hat OpenShift.](https://www.redhat.com/en/technologies/cloud-computing/openshift)\n",
    "\n",
    "* **Entorno *edge*.** Modelo híbrido donde la mayor parte de la computación y el almacenamiento se realiza de forma local o muy cercana al lugar de aplicación. Surgen principalmente por consideraciones de seguridad y por la alta capacidad de computación de los dispositivos actuales. Aplicaciones:\n",
    "    * Internet of Things.\n",
    "    * Industria 4.0.\n",
    "    * Vehículos autónomos.\n",
    "    \n",
    "A lo largo de esta unidad, nos ocuparemos de aquellos conceptos básicos asociados a los procesos de productivización de modelos, tanto a nivel manual como a nivel automático. Además, describiremos las diferentes herramientas disponibles para el despliegue de los modelos, tanto en entornos cloud como en entornos de tipo *edge*. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01b9bafb-01ef-40c0-a90d-95874de3f04d",
   "metadata": {},
   "source": [
    "## 3.2 - Despliegue de modelos mediante una API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b4e53c2-7a63-4f6b-96a2-2770fc001245",
   "metadata": {},
   "source": [
    "El término API es una abreviatura de **Application Programming Interfaces**, que en español significa \"interfaz de\n",
    "programación de aplicaciones\". Las API son un conjunto de \"reglas\" destinadas a permitir la comunicación entre dos o más aplicaciones de software independientes a través de un protocolo de comunicaciones (e.g., HTTP).\n",
    "\n",
    "La productivización de modelos mediante las API se trata, probablemente, de la forma más extendida de utilizar\n",
    "modelos **con independencia del tipo de *framework* de desarrollo que empleemos para su entrenamiento**.\n",
    "\n",
    "En algunos casos, los propios frameworks de ML/DL ofrecen funcionalidades para la construcción automática de estos servicios, como es el caso de TensorFlow, que proporciona ciertas funcionalidades para el servicio de modelos; sin embargo, en otras ocasiones, **resulta más sencillo crear una API de tipo genérico destinada a productivizar modelos de cualquier tipo**.\n",
    "\n",
    "La utilización de las API permite la creación de servicios independientes para acceder a las diferentes funcionalidades que ofrecen los modelos, tanto en lo relativo a la predicción como a la inserción de nuevos ejemplos de entrenamiento que puedan llegar a desencadenar nuevos procesos.\n",
    "\n",
    "Actualmente, los modelos de API mas utilizados son:\n",
    "\n",
    "* REST\n",
    "* GraphQL\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/api_models.jpg\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "A continuación, describiremos cómo funcionan diferentes tipos de API y cómo podemos utilizarlas para productivizar\n",
    "los modelos de razonamiento basados en aprendizaje profundo que hemos construido en los anteriores capítulos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c830ff7f-60e7-461b-be50-bb9c4f8ce5ff",
   "metadata": {},
   "source": [
    "### 3.2.1 - REST\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34d9f4b4-d9cb-43dd-bbe2-597766414f3f",
   "metadata": {},
   "source": [
    "El término REST (Representational State Transfer) fue definido en el año 2000 por Roy Fielding, uno de los creadores de la especificación HTTP. **Un servicio REST es un conjunto de reglas que sirven para crear aplicaciones web mediante el protocolo HTTP**.\n",
    "\n",
    "Las principales características de un servicio REST son:\n",
    "\n",
    "* **Bajo acomplamiento entre cliente y servidor.** El cliente no tiene que saber los detalles de implementación del servidor y viceversa.\n",
    "\n",
    "* **Sin estado.** Cualquier petición que reciba el servidor debe ser independiente, esto es, no es necesario mantener ningún tipo de sesión con respecto a la petición, aunque es posible definir una sesión para controlar el acceso a los diferentes recursos.\n",
    "\n",
    "* **Interfaz uniforme.** Cada recurso del servicio REST debe contar con una única dirección mediante una “URI”.\n",
    "\n",
    "* **Cacheable.** Los recursos pueden ser cacheados de tal forma que las sucesivas peticiones a un mismo recurso no generen exceso de computación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "520b59d1-79c4-4d7a-8c01-e3ca5618cdc1",
   "metadata": {},
   "source": [
    "#### Funcionamiento\n",
    "\n",
    "[**Ejemplo de API REST**](https://reqres.in/)\n",
    "\n",
    "Para entender el funcionamiento de una API de tipo REST sobre el protocolo HTTP, vamos a describir cómo\n",
    "funcionaría una API que ofreciera información sobre los usuarios de una red social de manera que pudiera acceder a tres conjuntos de datos:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Información de los usuarios</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/rest_users.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Información sobre las publicaciones de cada usuario</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/rest_posts.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Información sobre los seguidores de cada usuario</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/rest_followers.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a47ec07-880f-46d8-a6e6-c6c62e59c96d",
   "metadata": {},
   "source": [
    "#### Definición de las URI (nombrado)\n",
    "\n",
    "Las **URI** (Uniform Resource Identifier) son **cadenas de caracteres que identifican los recursos forma\n",
    "unívoca**. \n",
    "\n",
    "Las URL (Uniform Resource Locator) son un tipo especifico de URI que se utiliza para localizar y acceder a un recurso en particular a través de una red, como internet. La URL proporciona la ubicación exacta del recurso y el protocolo utilizado para acceder a él, como HTTP, HTTPS, FTP, etc. \n",
    "\n",
    "Existe un conjunto de reglas básicas para definir el nombrado a la URI de un recurso:\n",
    "* Los nombres de las URI no deben implicar una acción; por lo tanto, debemos evitar usar verbos en ellos.\n",
    "* Han de ser únicas, esto es, no debemos disponer de más de una URI para identificar un mismo recurso.\n",
    "* Deben ser independientes de formato.\n",
    "* Deben mantener una jerarquía lógica.\n",
    "* No deben implicar acciones.\n",
    "* Los filtrados de información de un recurso no se hacen en la URI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d81fdd1-cab0-4668-8fb4-5a81a6ca3102",
   "metadata": {},
   "source": [
    "#### Protocolo de comunicaciones (métodos)\n",
    "\n",
    "El protocolo de comunicaciones HTTP soporta el funcionamiento de las API REST. Para las diferentes funcionalidades\n",
    "que puede ofrecer un recurso, se basa en los métodos disponibles del protocolo HTTP:\n",
    "\n",
    "* **GET** para consultar y obtener información de los usuarios y las usuarias.\n",
    "* **POST** para crear un nuevo usuario o una nueva usuaria.\n",
    "* **PUT** para editar o actualizar usuarios y usuarias.\n",
    "* **DELETE** para eliminar usuarios y usuarias.\n",
    "* **PATCH** para editar partes de un recurso como, por ejemplo, un conjunto de atributos.\n",
    "\n",
    "Así, por ejemplo, para crear un recurso basado en el ejemplo anterior, dispondríamos de las siguientes acciones:\n",
    "* `GET /users`, que nos permite obtener al listado de usuarios y usuarias.\n",
    "* `GET / users /1`, que nos permite obtener la información del usuario o usuaria con identificador 1.\n",
    "* `POST /users /?id=1`, que nos permite crear un nuevo usuario o usuaria con identificador (id) 1.\n",
    "* `DELETE /users /1`, que nos permite eliminar al usuario o usuaria con identificador (id) 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39b57e80-7ccc-437b-8e94-f0daab27e3c2",
   "metadata": {},
   "source": [
    "#### Gestión de códigos de estado (definición)\n",
    "\n",
    "Existen diferentes maneras de definir los códigos de estado en un sistema REST. El régimen general se basa en los del protocolo HTTP. [**Lista de códigos de estado HTTP.**](https://es.wikipedia.org/wiki/Anexo:C%C3%B3digos_de_estado_HTTP)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82e26dff-4fa6-4ded-a78e-6e28952e4666",
   "metadata": {},
   "source": [
    "###  3.2.2 - GraphQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5802b84-452f-4f59-83fd-8ab7dab19b56",
   "metadata": {},
   "source": [
    "[**GraphQL**](https://graphql.org/) es un lenguaje de consultas (Query Language) similar a [PL-SQL](https://www.oracle.com/es/database/technologies/appdev/plsql.html) que permite la generación de consultas\n",
    "específicas sobre los datos.\n",
    "\n",
    "**Este sistema está basado en consultas complejas que no siguen un patrón definido por recursos**. \n",
    "\n",
    "La creación de las API mediante GraphQL ofrece acceso a la descripción de los datos, permitiendo realizar consultas específicas sobre estos y, por tanto, minimizar la cantidad de información superflua en las consultas. De este modo, se facilita el acceso a los datos al proporcionar una mayor capacidad a los desarrolladores y las desarrolladoras.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/graphql.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Este sistema de construcción de las API no es tan común a la hora de desplegar modelos, pero **podría ser una\n",
    "alternativa en caso de contar con múltiples modelos similares**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8be6f123-119a-4d62-9750-baf9da21cfb8",
   "metadata": {},
   "source": [
    "### 3.2.3 - Construyendo una API de tipo REST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9150aa59-d795-4fd3-abb1-ec68dcf8bc69",
   "metadata": {},
   "source": [
    "Para poder entender por completo cual es el funcionamiento de una API de tipo REST, vamos a crear una muy sencilla mediante el [***framework* Flask**](https://flask.palletsprojects.com/en/2.3.x/)y la [**extensión Swagger 3.0**](https://swagger.io/docs/specification/about/) mediante el paquete [**Connexion**](https://connexion.readthedocs.io/en/latest/index.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2291c70d",
   "metadata": {},
   "source": [
    "#### Aprendizaje del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a19f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)\n",
    "data.columns = [\n",
    "    \"Sample_code_number\",\n",
    "    \"Clump_Thickness\",\n",
    "    \"Uniformity_of_Cell_Size\",\n",
    "    \"Uniformity_of_Cell_Shape\",\n",
    "    \"Marginal_Adhesion\",\n",
    "    \"Single_Epithelial_Cell_Size\",\n",
    "    \"Bare_Nuclei\",\n",
    "    \"Bland_Chromatin\",\n",
    "    \"Normal_Nucleoli\",\n",
    "    \"Mitoses\",\n",
    "    \"Class\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef94cd2b",
   "metadata": {},
   "source": [
    "Una vez realizada la carga de los datos, debemos llevar a cabo una serie de transformaciones y modificaciones en la información del conjunto de datos con el objetivo de adecuarlos y poder construir nuestra red de neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672f77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de la columna que contiene el id de las muestras \n",
    "data.drop(\"Sample_code_number\", axis=\"columns\", inplace=True)\n",
    "\n",
    "# Modificación de los valores ? que existen en la columna Bare Nuclei (en este caso por el valor -1)\n",
    "data[\"Bare_Nuclei\"] = data['Bare_Nuclei'].replace('?', '-1').astype(int)\n",
    "\n",
    "# Modificación de las etiquetas para que los valores sean 0 y 1 \n",
    "data[\"Class\"] = data[\"Class\"].map(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Generación de los conjuntos de entrenamiento y test split_handler (en este caso no vamos a generar de validación aqui, lo haremos mas adelante)\n",
    "# split proportion: 0.88 train, 0.12 test\n",
    "train_set, test_set = train_test_split(data, test_size=0.12, random_state=0, stratify=data[\"Class\"])\n",
    "\n",
    "# Transformación del conjunto de entrenamiento en tensores \n",
    "X_train = tf.convert_to_tensor(train_set.iloc[:, :9], np.int32) \n",
    "y_train = tf.convert_to_tensor(train_set.iloc[:, 9:], np.int8)\n",
    "\n",
    "# Transformación del conjunto de test en tensores \n",
    "X_test = tf.convert_to_tensor(test_set.iloc[:, :9], np.float32)\n",
    "y_test = tf.convert_to_tensor(test_set.iloc[:, 9:], np.int8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09a6d16c",
   "metadata": {},
   "source": [
    "Una vez preparados los datos, podemos construir nuestra red de neuronas. Para ello, vamos a crear una red formada por tres capas mediante Keras:\n",
    "\n",
    "* Una capa de entrada que acepte tensores unidimensionales de tamaño 9. Para ello vamos a usar `keras.layers.Flatten`.\n",
    "* Una capa densa con 18 neuronas cuya función de activación sea una ReLU.\n",
    "* Una capa densa con una sola neurona con una función de activación de tipo sigmoidea, de manera que nos devuelva un valor comprendido entre 0 y 1 que se corresponderá con una de las dos clases que podemos obtener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8c4bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"binary_classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 9)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                180       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Creación de las capas que forman la estructura de la red\n",
    "layers = [keras.layers.Flatten(input_shape=(9,)),\n",
    "          keras.layers.Dense(18, activation=tf.nn.relu),\n",
    "          keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "         ]\n",
    "\n",
    "# Compilación de la red de neuronas, agrupando las diferentas capas de forma secuencial\n",
    "model = keras.Sequential(layers, name=\"binary_classification_model\")\n",
    "\n",
    "# Configuración del algoritmo de optimización y de la función de loss\n",
    "model.compile(optimizer=\"sgd\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61506128",
   "metadata": {},
   "source": [
    "Una vez compilada nuestra red de neuronas, podemos abordar el proceso de entrenamiento mediante la función `fit`. En este caso, hemos seleccionado las siguientes opciones:\n",
    "* Número de iteraciones (*epochs*): 25\n",
    "* Tamaño del batch de entrenamiento: 100 ejemplos\n",
    "* Tamaño del conjunto de validación: 8% del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c981ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 3s 124ms/step - loss: 1.2619 - accuracy: 0.2796 - val_loss: 1.1756 - val_accuracy: 0.2200\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9652 - accuracy: 0.3257 - val_loss: 0.9888 - val_accuracy: 0.2600\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.8052 - accuracy: 0.3770 - val_loss: 0.8548 - val_accuracy: 0.2800\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.7046 - accuracy: 0.4301 - val_loss: 0.7859 - val_accuracy: 0.3600\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6318 - accuracy: 0.5575 - val_loss: 0.6983 - val_accuracy: 0.6600\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.5807 - accuracy: 0.7681 - val_loss: 0.6547 - val_accuracy: 0.7600\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5391 - accuracy: 0.8142 - val_loss: 0.6294 - val_accuracy: 0.7600\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.5034 - accuracy: 0.8265 - val_loss: 0.6300 - val_accuracy: 0.7200\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4798 - accuracy: 0.8602 - val_loss: 0.5884 - val_accuracy: 0.7600\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.4534 - accuracy: 0.8832 - val_loss: 0.5520 - val_accuracy: 0.7800\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.4373 - accuracy: 0.8796 - val_loss: 0.5584 - val_accuracy: 0.7600\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.4213 - accuracy: 0.8903 - val_loss: 0.5350 - val_accuracy: 0.8200\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.4094 - accuracy: 0.9044 - val_loss: 0.5118 - val_accuracy: 0.8400\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3954 - accuracy: 0.9027 - val_loss: 0.5257 - val_accuracy: 0.8200\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.3868 - accuracy: 0.9009 - val_loss: 0.5071 - val_accuracy: 0.8200\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.3785 - accuracy: 0.9027 - val_loss: 0.5227 - val_accuracy: 0.8200\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.3690 - accuracy: 0.9115 - val_loss: 0.4865 - val_accuracy: 0.8400\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.3614 - accuracy: 0.9080 - val_loss: 0.4952 - val_accuracy: 0.8400\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.3544 - accuracy: 0.9168 - val_loss: 0.4862 - val_accuracy: 0.8400\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3488 - accuracy: 0.9186 - val_loss: 0.4712 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2223e8b6f40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Definición de los callback de TF Board\n",
    "tensorboard_callback = TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "# Ejecución del proceso de aprendizaje\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20, # Numero de iteraciones\n",
    "    batch_size=50, # Tamaño de los batches\n",
    "    validation_split=0.08, # Tamaño del conjunto de validación\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b08436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 20ms/step - loss: 0.3584 - accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo mediante el conjunto de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a72eba1e",
   "metadata": {},
   "source": [
    "Una vez hemos aprendido nuestro modelo y estamos satisfechos con nuestro resultado, lo exportamos para poder posteriormente desplegarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9817a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"bcw_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "795f59e9",
   "metadata": {},
   "source": [
    "Si queremos cargar este modelo, seria tan simple como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f993399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "bcw_model = keras.models.load_model(\"bcw_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9feee59",
   "metadata": {},
   "source": [
    "Ahora podemos usarlo para inferencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d97f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                2\n",
      "Uniformity_of_Cell_Size        1\n",
      "Uniformity_of_Cell_Shape       1\n",
      "Marginal_Adhesion              1\n",
      "Single_Epithelial_Cell_Size    2\n",
      "Bare_Nuclei                    1\n",
      "Bland_Chromatin                2\n",
      "Normal_Nucleoli                1\n",
      "Mitoses                        1\n",
      "Class                          0\n",
      "Name: 429, dtype: int64\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Predicción: [0.22428124]\n",
      "Real: [0]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "print(test_set.iloc[index])\n",
    "\n",
    "predictions = bcw_model.predict(X_test)\n",
    "print(f\"\\nPredicción: {predictions[index]}\")\n",
    "print(f\"Real: {y_test[index]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fdfa6ff",
   "metadata": {},
   "source": [
    "#### Programación de la API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a160a788",
   "metadata": {},
   "source": [
    "Una vez aprendido nuestro modelo, podemos crear una pequeña aplicación Flask con una API REST que llame al modelo para generar predicciones. Como resultado tendriamos:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/app_home.PNG\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/swagger_api_ui.PNG\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bdb418f-dcc6-4f8d-be80-afd7f0f91a35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.3 - Despliegue de modelos mediante operaciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3c74577-71eb-48f8-9150-42190d95ee19",
   "metadata": {},
   "source": [
    "El proceso de productivización de modelos es más complejo de lo que comúnmente se cree. Para poder productivizar un modelo, es decir, para ponerlo\n",
    "en producción de cara a su uso, resulta necesario desplegar un amplio número de sistemas y servicios entre los cuales el proceso de entrenamiento suele ser el más sencillo (desde un punto de vista de ingenieria).\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/mlops_1.jpg\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Los sistemas basados en Machine Learning o Deep Learning poseen la denominada **“deuda técnica oculta”** derivada\n",
    "del elevado número de componentes que se requieren para ponerlos en producción de manera correcta. De este modo, el proceso de automatización de la productivización de modelos de razonamiento resulta aún más complicado dada la **gran cantidad de sistemas que deben ser orquestados y los diferentes componentes que han de ejecutarse para entrenar y desplegar los modelos.**\n",
    "\n",
    "Para poder automatizar todos los procesos u operaciones que forman parte del ciclo de vida de los modelos,\n",
    "surgieron las denominadas ***Machine Learning Operations* (MLOps)**, que intentaban paliar las deficiencias que\n",
    "presentaban dichos procesos en el software tradicional basado en el modelo **DevOps**, donde se automatiza\n",
    "todo el proceso de compilación, evaluación y despliegue de manera automática:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/mlops_2.jpg\" width=\"400\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Este proceso de automatización del ciclo de vida de las aplicaciones tradicionales no era suficiente para cubrir\n",
    "las necesidades del ciclo de vida de las aplicaciones basadas en Machine Learning, ya que **no incluían los procesos relacionados con los datos que se utilizaban para construir y evaluar los modelos de razonamiento o con los propios modelos**. Además, era necesario automatizar tanto el código del software para el procesamiento y la\n",
    "transformación de los datos como el código para el entrenamiento, el despliegue y la monitorización de los modelos.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/mlops_3.jpg\" width=\"420\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Las aplicaciones software basadas en Machine Learning poseen tres componentes básicos (código, datos y modelos). En consecuencia, es necesario incluir operaciones relacionadas con los siguientes procesos:\n",
    "\n",
    "* Datos (preparación, análisis y tratamiento).\n",
    "* Validación de datos.\n",
    "* Entrenamiento.\n",
    "* Validación del modelo.\n",
    "* Empaquetado del modelo.\n",
    "* Entrega (despliegue) del modelo.\n",
    "* Monitorización del modelo.\n",
    "\n",
    "Para poder incluir estas nuevas operaciones, fue necesario añadir un nuevo ciclo dentro del ciclo de DevOps,\n",
    "dando lugar a lo que se conoce como el **ciclo MLOps**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/mlops_4.jpg\" width=\"550\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "En este nuevo ciclo, además de las operaciones tradicionales del ciclo DevOps, se incluyen cinco nuevas operaciones relacionadas con los procesos de ML:\n",
    "\n",
    "* **Entrenamiento**. Esta fase se corresponde con todas las operaciones de extracción (preparación de datos), transformación, limpieza y ejecución del proceso de entrenamiento de manera reproducible. \n",
    "\n",
    "* **Empaquetado**. Se corresponde con la creación de un paquete desplegable para llevar a cabo el proceso de inferencia. Este paquete debe incorporar todo el software necesario para la correcta ejecución del modelo.\n",
    "\n",
    "* **Evaluación**. Esta fase se corresponde con la evaluación del funcionamiento del modelo (inferencia) utilizando el conjunto de test a nivel funcional y de acceso.\n",
    "\n",
    "* **Despliegue (inferencia)**. Se corresponde con el despliegue del paquete en el entorno de ejecución (cloud, edge) para su uso en tiempo real, en streaming o en batch (inferencia). \n",
    "\n",
    "* **Monitorización**. Se corresponde con el despliegue y con el proceso de monitorización de toda la información del modelo a nivel de comportamiento y negocio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d7f37cb-15d5-4f6e-9b4e-d2a91c4d2b83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.3.1 - Niveles de automatización"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c26b482a-f13e-4881-a0a5-bf89073c9e2e",
   "metadata": {},
   "source": [
    "Un sistema puede estar mas o menos automatizado **dependiendo del nivel automatización de las diferentes operaciones descritas anteriormente en base a tres características principales**:\n",
    "\n",
    "* **Integración continua (IC)**. Este proceso implica la comprobación de todos los componentes involucrados en el proceso de entrenamiento y despliegue del modelo:\n",
    "    - Comprobar y validar el código fuente y los componentes.\n",
    "    - Comprobar y validar los datos utilizados durante el proceso de entrenamiento.\n",
    "    - Comprobar y validar los modelos.\n",
    "<br></br>\n",
    "* **Entrega continua (EC)**. El proceso de entrega es mucho más complejo que en los sistemas de generación de software tradicionales, donde solo se debe entregar un paquete de software, pues, en este caso, han de entregarse diferentes elementos:\n",
    "    - Modelo que se genera a través de una canalización de entrenamiento.\n",
    "    - Servicio que debe desplegar el modelo mediante un sistema de entrega fiable.\n",
    "<br></br>\n",
    "* **Entrenamiento incremental (EI)**. Se trata del proceso de mejora continua del modelo basado en aprendizaje automático. Las aplicaciones software fundamentadas en ML deben permitir mejorar de manera incremental los modelos creados previamente ejecutando de nuevo procesos de entrenamiento con información parcial y manteniendo todo lo aprendido en las iteraciones previas.\n",
    "\n",
    "**Dependiendo de cómo se apliquen estas tres características sobre las diferentes operaciones del ciclo de vida\n",
    "de los modelos, podremos identificar diferentes niveles de automatización.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e76465e4-cd19-45d8-afbe-4d83caa5bbcf",
   "metadata": {},
   "source": [
    "#### Nivel de automatización 0\n",
    "\n",
    "El nivel de automatización 0, el más básico de todos, **constituye un proceso manual, interactivo y controlado\n",
    "por medio de secuencias de comandos** ejecutadas por el equipo científico de datos o por el de ingeniería de\n",
    "aprendizaje automático.\n",
    "\n",
    "Cada parte del proceso se ejecuta de forma manual, de manera que el equipo de ingeniería que ejecuta la fase de entrenamiento (preparación, entrenamiento y evaluación) entrega manualmente el modelo al equipo de ingeniería de operaciones, que se encarga de realizar el despliegue, generalmente también de manera manual.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/auto_1.png\" width=\"800\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Se pueden identificar las siguientes características del nivel:\n",
    "* Ejecución manual de cada paso (operación).\n",
    "* Desconexión entre las fases de entrenamiento y despliegue.\n",
    "* Bajo nivel de actualización (no hay versionado de modelos).\n",
    "* No existe integración continua (IC).\n",
    "* No existe entrega continua (EC).\n",
    "* Registro de modelos (no suele existir).\n",
    "* No existe monitorización.\n",
    "* No se almacenan metadatos.\n",
    "\n",
    "En ocasiones, en este nivel existen pequeños procesos de automatización dentro de algunos de los procesos, pero estos últimos son ejecutados de manera manual. **Este nivel de automatización es el más extendido actualmente a nivel comercial e industrial.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8b5bfb6-e8bd-4a19-9acf-bfa7f738fdf7",
   "metadata": {},
   "source": [
    "#### Nivel de automatización 1\n",
    "\n",
    "El nivel de automatización 1 es el primer nivel en el que **se incluyen automatizaciones parciales o totales de algunas de las operaciones del ciclo de vida de los modelos en la fase de aprendizaje**. Así, se produce un proceso de definición y orquestación del pipeline de aprendizaje, lo que facilita la ejecución de múltiples procesos de aprendizaje con el objetivo de generar diferentes versiones de los modelos.\n",
    "\n",
    "Por tanto, en este nivel de automatización se realiza un **entrenamiento incremental** (EI) del modelo mediante la automatización del pipeline de aprendizaje automático, de manera que **se automatizan los procesos de construcción y entrega del modelo** introduciendo nuevos componentes:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/auto_2.jpg\" width=\"900\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Se pueden identificar las siguientes características del nivel:\n",
    "\n",
    "* Ejecución automática del proceso de entrenamiento.\n",
    "* Simetría experimental-operacional.\n",
    "* Código modularizado para componentes y pipelines.\n",
    "* No existe integración continua (IC).\n",
    "* Existe entrega continua (EC) de modelos.\n",
    "* Existe entrenamiento incremental (EI) de modelos.\n",
    "* Registro de modelos (versionado).\n",
    "* Existe monitorización a nivel de entrenamiento.\n",
    "* Se pueden almacenar metadatos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "438b71eb-31ba-4040-ae56-4ce5693d296f",
   "metadata": {},
   "source": [
    "#### Nivel de automatización 2\n",
    "\n",
    "El nivel de automatización 2 es el nivel de mayor automatización, pues se produce una automatización absoluta de todas las operaciones del ciclo de vida de los modelos y se incluyen las tres características básicas de la automatización sobre todos los componentes en los que se pueden aplicar.\n",
    "\n",
    "Por tanto, **se trata de un proceso completamente automatizado de la gestión del código de todos los pipelines (datos, entrenamiento y despliegue), así como del proceso de entrenamiento y del posterior despliegue de modelos**.\n",
    "\n",
    "La inclusión de este grado de automatización implica la incorporación de nuevos componentes relacionados con la compilación y el testeo del código fuente, así como el despliegue de los modelos de ML o DL:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/auto_3.jpg\" width=\"900\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Se pueden identificar las siguientes características del nivel:\n",
    "* Ejecución automática del proceso de compilación, entrenamiento y despliegue.\n",
    "* Simetría experimental-operacional.\n",
    "* Código modularizado para componentes y pipelines.\n",
    "* Integración continua (IC) para el código a nivel general y para pipelines (datos, entrenamiento y despliegue).\n",
    "* Entrega continua (EC) de modelos y de código.\n",
    "* Entrenamiento incremental (EI) de modelos.\n",
    "* Registro de modelos (versionado).\n",
    "* Monitorización a nivel de entrenamiento y despliegue.\n",
    "* Almacenamiento y gestión de metadatos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7032f23f-a2ef-466e-8c51-a383cac63e49",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3.2 - Tecnologías\n",
    "\n",
    "Existen diferentes tecnologías para aplicar los procesos de automatización del ciclo de vida de los modelos. Éstas se suelen dividir en dos grandes grupos:\n",
    "\n",
    "* **Tecnologías de entorno *cloud***. Se despliegan en un entorno cloud de tipo público y ofrecen tecnología nativa para la automatización de todas las posibles operaciones que se lleven a cabo durante el ciclo de vida de los modelos. Las más comunes son las correspondientes a cada una de las tres grandes nubes públicas ([TensorFlow Extender](https://www.tensorflow.org/tfx), [Amazon SageMaker](https://aws.amazon.com/es/sagemaker/) y [Azure Machine Learning](https://azure.microsoft.com/es-es/products/machine-learning)). En ocasiones, estos frameworks se pueden combinar con otras herramientas capaces de automatizar y/o ejecutar algunas de las operaciones como, por ejemplo, [Seldon](https://www.seldon.io/), que permite la automatización del proceso de despliegue de los modelos sobre Kubernetes u OpenShift.\n",
    "\n",
    "* **Tecnologías entorno *On-Premise***. Permiten automatizar parcial o completamente algunas de las operaciones del ciclo de vida de los modelos en entornos de tipo cloud privados o híbridos. Si bien en algunos casos se pueden desplegar en entornos de cloud público, esto no es lo más común. Muchos de estos frameworks no disponen de tecnología nativa de MLOps y deben utilizar componentes externos como [MLFlow](https://mlflow.org/) o [Seldon](https://www.seldon.io/).\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/entornos_mlops.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43ff3d8c-7d7e-4815-bd82-be1c1be66d0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.4 - Despliegue de modelos en dispositivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc0d1e3c-280e-4e9d-b68b-94e6f80afe51",
   "metadata": {},
   "source": [
    "Nuevos entornos de despliegue han surgido como consecuencia de la proliferación exponencial de dispositivos relacionados con la IoT (Internet of Things) que, actualmente, utilizamos para realizar diferentes tipos de tareas de carácter automático o semiautomático. Por ejemplo: \n",
    "\n",
    "* La recogida de información a través de sensores\n",
    "* Los electrodomésticos inteligentes como las lavadoras o las aspiradoras\n",
    "* Los futuros robots asistenciales\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/dispositivos.jpg\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Estos dispositivos suelen tener capacidades computacioneles limitadas que hace que muchas veces solo sera posible desplegar la fase inferencia. Sin embargo tienen ciertas características muy importantes:\n",
    "\n",
    "* **Disminución de la latencia en las peticiones de predicción**. Ahora, el modelo se ejecuta de manera nativa en el propio dispositivo, es decir, ya no es necesario que realice peticiones al entorno *cloud* para obtener una predicción. \n",
    "\n",
    "* **Incremento de la privacidad y la seguridad**. Los datos recogidos por los dispositivos no son enviados y almacenados en el *cloud*, solo se recogen y se utilizan para ejecutar el proceso local de inferencia, por lo que posteriormente son destruidos o sobreescritos. Este aspecto es muy relevante sobretodo cuando se utilizan aplicaciones basadas en visión por computador, en cuyas imágenes se recoge información del tipo personal que permitiría identificar personas o, incluso, patrones de actuación.\n",
    "\n",
    "Podemos distinguir dos tipos de entornos específicos que entran dentro de este espectro:\n",
    "* **Entorno *edge* (borde)**. Se trata del entorno propio de los dispositivos, de manera que las aplicaciones se ejecutan sin ningun tipo de uso de las capacidades computacionales de la nube. Se suele utilizar principalmente para inferencia.\n",
    "\n",
    "* **Entorno *fog* (niebla)**. Se situa entre los dispositivos y el entorno *cloud*, tratándose, por tanto, de un entorno intermedio, normalmente privado, donde se conectan los dispositivos para acceder a los recursos del propio entorno y en algunos caso de la nube. Se pueden utilizar los diferentes servidores del entorno para realizar el entrenamiento de modelos en caso de que no pueda llevarse a cabo en los dispositivos.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/entornos_dispositivos.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "El despliegue de modelos en entornos edge está resultando tan útil que incluso se han desarrollado diferentes dispositivos de bajo coste, como los que se muestra en la Figura , que pueden conectarse de manera sencilla a otros dispositivos y sensores y ejecutar la fase de inferencia, permitiendo así que los dispositivos con bajas capacidades computacionales funcionen como dispositivos inteligentes capaces de ejecutar modelos de razonamiento de manera “nativa”, es decir, sin recurrir al cloud.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/edge_examples.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "[**Repositorio con enlaces informativos sobre edge computing**](https://github.com/Bisonai/awesome-edge-machine-learning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3586580d-a771-4f15-9a3f-fa82dd4ac3db",
   "metadata": {},
   "source": [
    "### 3.4.1 - Construcción de modelos Lite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fd14bf8-2af4-4fde-9366-de5b724f2b61",
   "metadata": {},
   "source": [
    "Con el objetivo de minimizar el coste computacional de la ejecución de los modelos y que esta pueda realizarse en dispositivos móviles o de IoT (como los descritos anteriormente), Google diseñó una variante de su libreria para la **representación de modelos de menor tamaño** llamado [TFLite (i.e., TensorFlow Lite)](https://www.tensorflow.org/lite). Mediante TFLite, podemos construir modelos cuyo proceso de inferencia puede ejecutarse en dispositivos de baja capacidad como smartphones. Ejemplos:\n",
    "\n",
    "* [Clasificación de imágenes](https://www.tensorflow.org/lite/examples/image_classification/overview)\n",
    "* [Detección de objetos](https://www.tensorflow.org/lite/examples/object_detection/overview)\n",
    "* [Recuperación de información sobre documentos](https://www.tensorflow.org/lite/examples/bert_qa/overview)\n",
    "\n",
    "El conjunto de herramientas disponibles en TFLite se divide en dos componentes principales:\n",
    "* **El intérprete de TFLite**, que permite la ejecución de modelos especialmente optimizados en varios tipos de *hardware*, entre los que se incluyen:\n",
    "    * Smartphones\n",
    "    * Dispositivos embebidos\n",
    "    * Microcontroladores\n",
    "<br></br>    \n",
    "* **El conversor de TFLite**, que permite convertir  los modelos de TensorFlow tradicional a un formato eficiente para que pueda usarlos el intérprete. Además, puede implementar optimizaciones para mejorar el tamaño y el rendimiento de los objetos binarios.\n",
    "\n",
    "La construcción de los modelos en formato comprimido o *Lite* se denomina **cuantización** y reduce la precisión de las operaciones del modelo (por ejemplo, utilizando una precisión de 8 bits en lugar de una precisión de 32 bits flotantes). **Este proceso puede reducir el tamaño de los modelos en más de cuatro veces**, dependiendo de la precisión deseada.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/tflite_process.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n",
    "Los modelos comprimidos (TFLite) pueden ejecutarse en dispositivos móviles y en los aceleradores de tipo EdgeTPU y NNapi. Sin embargo, este proceso no asegura una compresión completa, pues existen ciertas operaciones que, actualmente, no pueden ser “comprimidas”. Por consiguiente, parte de las operaciones del modelo deben ejecutarse en un CPU.\n",
    "\n",
    "El proceso de compresión organiza las operaciones en dos grupos:\n",
    "1. Las **operaciones compatibles con TensorFlow Lite**\n",
    "2. Las **operaciones no compatibles**.\n",
    "\n",
    "De este modo, cuando se comprime un modelo, se agrupan las operaciones de manera secuencial de forma que todas aquellas que puedan ser ejecutadas en\n",
    "una secuencia lineal completa en la TPU se agruparán para ser ejecutadas en esta, mientras que el resto de las operaciones se ejecutarán en la CPU.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3/operaciones_compatibles_tflite.png\" width=\"600\" data-align=\"center\"></td>\n",
    "    </tr> \n",
    "</table>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
